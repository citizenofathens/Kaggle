{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\jupyter', 'C:\\\\Users\\\\tjdal\\\\PycharmProjects\\\\Kaggle', 'C:\\\\Users\\\\tjdal\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\python38.zip', 'C:\\\\Users\\\\tjdal\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\DLLs', 'C:\\\\Users\\\\tjdal\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib', 'C:\\\\Users\\\\tjdal\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38', 'c:\\\\users\\\\tjdal\\\\pycharmprojects\\\\kaggle\\\\venv', '', 'c:\\\\users\\\\tjdal\\\\pycharmprojects\\\\kaggle\\\\venv\\\\lib\\\\site-packages', 'c:\\\\users\\\\tjdal\\\\pycharmprojects\\\\kaggle\\\\venv\\\\lib\\\\site-packages\\\\win32', 'c:\\\\users\\\\tjdal\\\\pycharmprojects\\\\kaggle\\\\venv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\users\\\\tjdal\\\\pycharmprojects\\\\kaggle\\\\venv\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\users\\\\tjdal\\\\pycharmprojects\\\\kaggle\\\\venv\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\tjdal\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.path)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "# 상대경로 모르면 절대 경로"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "UserName          int64\nScreenName        int64\nLocation         object\nTweetAt          object\nOriginalTweet    object\nSentiment        object\ndtype: object"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\tjdal\\\\PycharmProjects\\\\Kaggle\\\\Corona_NLP_train.csv', encoding='latin1')\n",
    "\n",
    "# EDA\n",
    "data.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0        @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n1        advice Talk to your neighbours family to excha...\n2        Coronavirus Australia: Woolworths to give elde...\n3        My food stock is not the only one which is emp...\n4        Me, ready to go at supermarket during the #COV...\n                               ...                        \n41152    Airline pilots offering to stock supermarket s...\n41153    Response to complaint not provided citing COVI...\n41154    You know itÂs getting tough when @KameronWild...\n41155    Is it wrong that the smell of hand sanitizer i...\n41156    @TartiiCat Well new/used Rift S are going for ...\nName: OriginalTweet, Length: 41157, dtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalTweet = data['OriginalTweet']\n",
    "originalTweet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%=\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 다른 사람 (kaggle) 풀이 참고\n",
    "# 이제와서 새삼 EDA 단어 분포\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize': (11,4)})\n",
    "sns.countplot(data['Sentiment'])\n",
    "\n",
    "# 감정을 3가지로 줄여보겠다는 idea\n",
    "#\n",
    "# def change_sen(sentiment):\n",
    "#     if sentiment == \"Extremely Positive\":\n",
    "#         return 'positive'\n",
    "#     elif sentiment == \"Extremely Negative\":\n",
    "#         return 'negative'\n",
    "#     elif sentiment == \"Positive\":\n",
    "#         return 'positive'\n",
    "#     elif sentiment == \"Negative\":\n",
    "#         return 'negative'\n",
    "#     else:\n",
    "#         return 'netural'\n",
    "\n",
    "#Cleaning the tweet\n",
    "#\n",
    "# def clean(text):\n",
    "#     #     remove urls\n",
    "#     text = re.sub(r'http\\S+', \" \", text)\n",
    "#     #     remove mentions\n",
    "#     text = re.sub(r'@\\w+',' ',text)\n",
    "#     #     remove hastags\n",
    "#     text = re.sub(r'#\\w+', ' ', text)\n",
    "#     #     remove digits\n",
    "#     text = re.sub(r'\\d+', ' ', text)\n",
    "#     #     remove html tags\n",
    "#     text = re.sub('r<.*?>',' ', text)\n",
    "#     #     remove stop words\n",
    "#     text = text.split()\n",
    "#     text = \" \".join([word for word in text if not word in stop_word])\n",
    "#\n",
    "#     return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'mesdaf'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "stopwords = ['@', 'https://',':']\n",
    "def apply_stopwords(text):\n",
    "    for i in range(len(stopwords)):\n",
    "        if stopwords[i] in text:\n",
    "            text = text.replace(stopwords[i],'')\n",
    "    return text\n",
    "apply_stopwords('@mesdaf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 위의 특수문자 제거\n",
    "data['OriginalTweet'] = data['OriginalTweet'].apply(lambda x: apply_stopwords(x))\n",
    "#preprocessing\n",
    "data['OriginalTweet'] =  data['OriginalTweet'].apply(lambda x: x.split(' '))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "       UserName  ScreenName                      Location     TweetAt  \\\n0          3799       48751                        London  16-03-2020   \n1          3800       48752                            UK  16-03-2020   \n2          3801       48753                     Vagabonds  16-03-2020   \n3          3802       48754                           NaN  16-03-2020   \n4          3803       48755                           NaN  16-03-2020   \n...         ...         ...                           ...         ...   \n41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n41153     44952       89904                           NaN  14-04-2020   \n41154     44953       89905                           NaN  14-04-2020   \n41155     44954       89906                           NaN  14-04-2020   \n41156     44955       89907  i love you so much || he/him  14-04-2020   \n\n                                           OriginalTweet           Sentiment  \n0      [MeNyrbie, Phil_Gahan, Chrisitv, t.co/iFz9FAn2...             Neutral  \n1      [advice, Talk, to, your, neighbours, family, t...            Positive  \n2      [Coronavirus, Australia, Woolworths, to, give,...            Positive  \n3      [My, food, stock, is, not, the, only, one, whi...            Positive  \n4      [Me,, ready, to, go, at, supermarket, during, ...  Extremely Negative  \n...                                                  ...                 ...  \n41152  [Airline, pilots, offering, to, stock, superma...             Neutral  \n41153  [Response, to, complaint, not, provided, citin...  Extremely Negative  \n41154  [You, know, itÂs, getting, tough, when, Kamer...            Positive  \n41155  [Is, it, wrong, that, the, smell, of, hand, sa...             Neutral  \n41156  [TartiiCat, Well, new/used, Rift, S, are, goin...            Negative  \n\n[41157 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>[MeNyrbie, Phil_Gahan, Chrisitv, t.co/iFz9FAn2...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>[Coronavirus, Australia, Woolworths, to, give,...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>[Me,, ready, to, go, at, supermarket, during, ...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41152</th>\n      <td>44951</td>\n      <td>89903</td>\n      <td>Wellington City, New Zealand</td>\n      <td>14-04-2020</td>\n      <td>[Airline, pilots, offering, to, stock, superma...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>41153</th>\n      <td>44952</td>\n      <td>89904</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>[Response, to, complaint, not, provided, citin...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>41154</th>\n      <td>44953</td>\n      <td>89905</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>[You, know, itÂs, getting, tough, when, Kamer...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>41155</th>\n      <td>44954</td>\n      <td>89906</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>[Is, it, wrong, that, the, smell, of, hand, sa...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>41156</th>\n      <td>44955</td>\n      <td>89907</td>\n      <td>i love you so much || he/him</td>\n      <td>14-04-2020</td>\n      <td>[TartiiCat, Well, new/used, Rift, S, are, goin...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>41157 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 잠재 디리클레 '할당'\n",
    "data\n",
    "nf = 20\n",
    "detokenizng =  data['OriginalTweet'].apply(lambda x: ' '.join(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 행렬 분해 벡터라이즈\n",
    "data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unique user name check\n",
    "print('origin userName :{}'.format(len(data['UserName'])))\n",
    "print('unique userName :{}'.format(len(data['UserName'].unique())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "l      sss       a          \"\n",
    "l     s         a a         \"\n",
    "l      sss     aaaaa        \"\n",
    "l         s   a     a       \"\n",
    "l___   sss   a       a      \"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english',max_df=5, smooth_idf=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 행렬분해\n",
    "\"\"\" Topic modeling \"\"\"\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=100,random_state=122)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['OriginalTweet']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "originalTweet = np.array(data['OriginalTweet'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "\n",
    "originalTweet\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(originalTweet)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svd_model.fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.shape(svd_model.components_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 트레이닝 하면서 단어집합이 저장됨\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "components_ = svd_model.components_\n",
    "\n",
    "# topic의 수 x 단어의 수\n",
    "components_.shape\n",
    "\n",
    "def get_topics(components_, feature_names, n=5):\n",
    "    for idx ,topic in enumerate(components_):\n",
    "        print(\"Topic %d : \" % (idx+1) , [(feature_names[i],topic[i].round(5)) for i in topic.argsort()[:-n-1:-1]])\n",
    "\n",
    "get_topics(components_,terms)\n",
    "# 그다지 서로 비슷한 토픽이 없는 듯 하다\n",
    "\n",
    "\n",
    "\n",
    "# 감성분류가 필요할 듯 한\n",
    "\n",
    "\n",
    "\n",
    "# lsa 차원 축소를 통해 비슷한 단어가 포함된 문서 분류 -> tfidvectorizer 는 lsa 였네\n",
    "\n",
    "# lda  문서-주제-단어 관계로 문서에 포함된 주제별 확률과 주제별 단어가 있는 확률을 나타낸다\n",
    "# 둘 중 하나를 적용하기 위해 tf-idf 행렬 만들기\n",
    "\n",
    "\n",
    "# feature_extraction\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "l     dddd      a          \"\n",
    "l     s   d     a a         \"\n",
    "l     d    d   aaaaa        \"\n",
    "l     d   d   a     a       \"\n",
    "l___  dddd   a       a      \"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "data['OriginalTweet']\n",
    "\n",
    "\n",
    "data['OriginalTweet'] = data['OriginalTweet'].apply(lambda x: apply_stopwords(x))\n",
    "#preprocessing\n",
    "data['OriginalTweet'] =  data['OriginalTweet'].apply(lambda x: x.split(' '))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['OriginalTweet']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# i wouldn't install gensim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create dictionary\n",
    "\"\"\"\n",
    "\n",
    "dict = {}\n",
    "\n",
    "word_list = data['OriginalTweet'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "word_list  =np.array(word_list)\n",
    "word_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['OriginalTweet'] =  data['OriginalTweet'].apply(lambda x: x.split(' '))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% tokenizing\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_list = data['OriginalTweet']\n",
    "\n",
    "# fail code\n",
    "# word_list.reshape(,-1) ?\n",
    "# 2-dimension to 1-dim\n",
    "#word_list = sum(word_list, [])  ultimate loop\n",
    "#import itertools\n",
    "#word_list_1dim = list(itertools.chain(*word_list)) 한글자씩 나뉜다\n",
    "word_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2-dimension to 1-dim maybe success\n",
    "word_list_1dim = np.concatenate(word_list).tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_list_1dim\n",
    "\n",
    "\n",
    "\n",
    "word_dict = {}\n",
    "idx = 0\n",
    "for i in range(len(word_list_1dim)):\n",
    "    if word_list_1dim[i] not in word_dict.keys():\n",
    "        word_dict[word_list_1dim[i]] = idx\n",
    "        idx +=1\n",
    "    else:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### 감성 분류 ########\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## find category\n",
    "\n",
    "sentiment = le.fit(data['Sentiment'])\n",
    "\n",
    "le.transform(sentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(word_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fail code\n",
    "# word_cnt_dict={}\n",
    "# for i in range(len(word_list_1dim)):\n",
    "#     if word_list_1dim[i] in word_cnt_dict.keys():\n",
    "#         word_cnt_dict[word_list_1dim[i]] +=1\n",
    "#     else:\n",
    "#         word_cnt_dict[word_list_1dim[i]] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% word count 고 이거는 ..\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "originalTweet = np.array(data['OriginalTweet'])\n",
    "\n",
    "\n",
    "data[['OriginalTweet','Sentiment']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "data['OriginalTweet'] =  data['OriginalTweet'].apply(lambda x: x.split(' '))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "# 문장 토큰화"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\tjdal\\\\PycharmProjects\\\\Kaggle\\\\Corona_NLP_train.csv', encoding='latin1')\n",
    "\n",
    "#pre processing\n",
    "data['OriginalTweet'] = data['OriginalTweet'].apply(lambda x: re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '',x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "       UserName  ScreenName                      Location     TweetAt  \\\n0          3799       48751                        London  16-03-2020   \n1          3800       48752                            UK  16-03-2020   \n2          3801       48753                     Vagabonds  16-03-2020   \n3          3802       48754                           NaN  16-03-2020   \n4          3803       48755                           NaN  16-03-2020   \n...         ...         ...                           ...         ...   \n41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n41153     44952       89904                           NaN  14-04-2020   \n41154     44953       89905                           NaN  14-04-2020   \n41155     44954       89906                           NaN  14-04-2020   \n41156     44955       89907  i love you so much || he/him  14-04-2020   \n\n                                           OriginalTweet           Sentiment  \n0      MeNyrbie Phil_Gahan Chrisitv httpstcoiFz9FAn2P...             Neutral  \n1      advice Talk to your neighbours family to excha...            Positive  \n2      Coronavirus Australia Woolworths to give elder...            Positive  \n3      My food stock is not the only one which is emp...            Positive  \n4      Me ready to go at supermarket during the COVID...  Extremely Negative  \n...                                                  ...                 ...  \n41152  Airline pilots offering to stock supermarket s...             Neutral  \n41153  Response to complaint not provided citing COVI...  Extremely Negative  \n41154  You know itÂs getting tough when KameronWilds...            Positive  \n41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n41156  TartiiCat Well newused Rift S are going for 70...            Negative  \n\n[41157 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>MeNyrbie Phil_Gahan Chrisitv httpstcoiFz9FAn2P...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia Woolworths to give elder...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me ready to go at supermarket during the COVID...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41152</th>\n      <td>44951</td>\n      <td>89903</td>\n      <td>Wellington City, New Zealand</td>\n      <td>14-04-2020</td>\n      <td>Airline pilots offering to stock supermarket s...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>41153</th>\n      <td>44952</td>\n      <td>89904</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>Response to complaint not provided citing COVI...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>41154</th>\n      <td>44953</td>\n      <td>89905</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>You know itÂs getting tough when KameronWilds...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>41155</th>\n      <td>44954</td>\n      <td>89906</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>Is it wrong that the smell of hand sanitizer i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>41156</th>\n      <td>44955</td>\n      <td>89907</td>\n      <td>i love you so much || he/him</td>\n      <td>14-04-2020</td>\n      <td>TartiiCat Well newused Rift S are going for 70...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>41157 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment']\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# 단어 빈도수로 사전을 우선 만든다 이후 상위 n개의 단어를 추출해서 사용할 수 있기 때문에\n",
    "le = LabelEncoder ()\n",
    "# find category\n",
    "le.fit(data['Sentiment'])\n",
    "label_encoded= le.transform(data['Sentiment'])\n",
    "\n",
    "data['Sentiment'] = label_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "['MeNyrbie Phil_Gahan Chrisitv httpstcoiFz9FAn2Pa and httpstcoxX6ghGFzCC and httpstcoI2NlzdxNo8']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sent_tokenize(data['OriginalTweet'][i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                 [1, 1, 1, 1, 1, 1, 1, 1]\n1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n2               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n                               ...                        \n41152    Airline pilots offering to stock supermarket s...\n41153    Response to complaint not provided citing COVI...\n41154    You know itÂs getting tough when KameronWilds...\n41155    Is it wrong that the smell of hand sanitizer i...\n41156    TartiiCat Well newused Rift S are going for 70...\nName: OriginalTweet, Length: 41157, dtype: object"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "word_dict  = {}\n",
    "for i in range(len(data['OriginalTweet'][:100])):\n",
    "    text = sent_tokenize(data['OriginalTweet'][i])\n",
    "\n",
    "    for j in range(len(text)):\n",
    "        sentence = word_tokenize(text[j])\n",
    "        for word in sentence:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = 0\n",
    "            else:\n",
    "                word_dict[word] +=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "['MeNyrbie Phil_Gahan Chrisitv httpstcoiFz9FAn2Pa and httpstcoxX6ghGFzCC and httpstcoI2NlzdxNo8']"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent_tokenize(data['OriginalTweet'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8844/2074010336.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msentence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mword_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001B[0m in \u001B[0;36mword_tokenize\u001B[1;34m(text, language, preserve_line)\u001B[0m\n\u001B[0;32m    128\u001B[0m     \u001B[1;33m:\u001B[0m\u001B[0mtype\u001B[0m \u001B[0mpreserve_line\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m     \"\"\"\n\u001B[1;32m--> 130\u001B[1;33m     \u001B[0msentences\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mpreserve_line\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0msent_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    131\u001B[0m     return [\n\u001B[0;32m    132\u001B[0m         \u001B[0mtoken\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msentences\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[1;32min\u001B[0m \u001B[0m_treebank_word_tokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001B[0m in \u001B[0;36msent_tokenize\u001B[1;34m(text, language)\u001B[0m\n\u001B[0;32m    106\u001B[0m     \"\"\"\n\u001B[0;32m    107\u001B[0m     \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"tokenizers/punkt/{0}.pickle\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlanguage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36mtokenize\u001B[1;34m(self, text, realign_boundaries)\u001B[0m\n\u001B[0;32m   1272\u001B[0m         \u001B[0mGiven\u001B[0m \u001B[0ma\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0msentences\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1273\u001B[0m         \"\"\"\n\u001B[1;32m-> 1274\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentences_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1275\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1276\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdebug_decisions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36msentences_from_text\u001B[1;34m(self, text, realign_boundaries)\u001B[0m\n\u001B[0;32m   1326\u001B[0m         \u001B[0mfollows\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mperiod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1327\u001B[0m         \"\"\"\n\u001B[1;32m-> 1328\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspan_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1329\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1330\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_slices_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1326\u001B[0m         \u001B[0mfollows\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mperiod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1327\u001B[0m         \"\"\"\n\u001B[1;32m-> 1328\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspan_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1329\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1330\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_slices_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36mspan_tokenize\u001B[1;34m(self, text, realign_boundaries)\u001B[0m\n\u001B[0;32m   1316\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1317\u001B[0m             \u001B[0mslices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_realign_boundaries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mslices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1318\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0msl\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mslices\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1319\u001B[0m             \u001B[1;32myield\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0msl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1320\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m_realign_boundaries\u001B[1;34m(self, text, slices)\u001B[0m\n\u001B[0;32m   1357\u001B[0m         \"\"\"\n\u001B[0;32m   1358\u001B[0m         \u001B[0mrealign\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1359\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0msl1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msl2\u001B[0m \u001B[1;32min\u001B[0m \u001B[0m_pair_iter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mslices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1360\u001B[0m             \u001B[0msl1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mslice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msl1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mrealign\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msl1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1361\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msl2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m_pair_iter\u001B[1;34m(it)\u001B[0m\n\u001B[0;32m    314\u001B[0m     \u001B[0mit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mit\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 316\u001B[1;33m         \u001B[0mprev\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mit\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    317\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    318\u001B[0m         \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m_slices_from_text\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m   1330\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_slices_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1331\u001B[0m         \u001B[0mlast_break\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1332\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mmatch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lang_vars\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mperiod_context_re\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfinditer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1333\u001B[0m             \u001B[0mcontext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"after_tok\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1334\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext_contains_sentbreak\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#sentence = word_tokenize(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "vocab_sorted =sorted(word_dict.items(),key=lambda x: x[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "word_to_index  ={}\n",
    "\n",
    "for i, v in enumerate(vocab_sorted):\n",
    "\n",
    "    word_to_index[v[0]] = i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "{'the': 0,\n 'to': 1,\n 'and': 2,\n 'of': 3,\n 'a': 4,\n 'in': 5,\n 'COVID19': 6,\n 'for': 7,\n 'is': 8,\n 'I': 9,\n 'coronavirus': 10,\n 'food': 11,\n 'on': 12,\n 'are': 13,\n 'you': 14,\n 'shopping': 15,\n 'store': 16,\n 'this': 17,\n 'people': 18,\n 'will': 19,\n 'be': 20,\n 'with': 21,\n 'or': 22,\n ';': 23,\n 'that': 24,\n 'online': 25,\n 'panic': 26,\n 'at': 27,\n 'our': 28,\n 'as': 29,\n 'more': 30,\n 'we': 31,\n 'have': 32,\n 'but': 33,\n 'not': 34,\n 'up': 35,\n 'do': 36,\n 'supermarket': 37,\n 'The': 38,\n 'out': 39,\n 'retail': 40,\n 'can': 41,\n 'Coronavirus': 42,\n 'so': 43,\n 'We': 44,\n 'all': 45,\n 'COVID2019': 46,\n 'your': 47,\n 'need': 48,\n 'grocery': 49,\n 'buy': 50,\n 'from': 51,\n 'their': 52,\n 'who': 53,\n 'stock': 54,\n 'demand': 55,\n 'being': 56,\n 'due': 57,\n 'CoronavirusOutbreak': 58,\n 'like': 59,\n 'over': 60,\n 'dont': 61,\n 'go': 62,\n 'my': 63,\n 'about': 64,\n 'spread': 65,\n '19': 66,\n 'Covid19': 67,\n 'has': 68,\n 'consumer': 69,\n 'safe': 70,\n 'during': 71,\n 'toilet': 72,\n 'paper': 73,\n 'what': 74,\n 'home': 75,\n 'time': 76,\n 'been': 77,\n 'they': 78,\n 'impact': 79,\n 'those': 80,\n 'buying': 81,\n 'here': 82,\n 'no': 83,\n 'get': 84,\n 'if': 85,\n 'empty': 86,\n 'stay': 87,\n 'because': 88,\n 'open': 89,\n 'help': 90,\n 'just': 91,\n 'Consumer': 92,\n 'pandemic': 93,\n 'This': 94,\n 'No': 95,\n 'into': 96,\n 'amp': 97,\n 'think': 98,\n 'an': 99,\n 'it': 100,\n 'gt': 101,\n 'hours': 102,\n 'outbreak': 103,\n 'one': 104,\n 'Stay': 105,\n 'please': 106,\n 'news': 107,\n 'stores': 108,\n 'was': 109,\n 'today': 110,\n 'For': 111,\n 'should': 112,\n 'use': 113,\n 'there': 114,\n 'everyone': 115,\n 'these': 116,\n 'Just': 117,\n 'months': 118,\n 'positive': 119,\n 'virus': 120,\n 'how': 121,\n 'see': 122,\n 'could': 123,\n 'They': 124,\n 'etc': 125,\n 'some': 126,\n 'sick': 127,\n 'work': 128,\n 'me': 129,\n 'prices': 130,\n 'If': 131,\n 'still': 132,\n 'group': 133,\n 'really': 134,\n 'would': 135,\n 'kroger': 136,\n 'leave': 137,\n 'family': 138,\n 'phone': 139,\n 'supplies': 140,\n 'My': 141,\n 'FOR': 142,\n 'Im': 143,\n 'It': 144,\n 'As': 145,\n 'case': 146,\n 'purchase': 147,\n 'other': 148,\n 'goods': 149,\n 'his': 150,\n 'Covid_19': 151,\n 'weeks': 152,\n 'March': 153,\n 'orders': 154,\n 'All': 155,\n 'now': 156,\n 'situation': 157,\n 'increased': 158,\n 'products': 159,\n 'may': 160,\n 'community': 161,\n 'after': 162,\n 'healthy': 163,\n 'Amazon': 164,\n 'Travel': 165,\n 'covid19': 166,\n 'seen': 167,\n 'increase': 168,\n 'new': 169,\n 'And': 170,\n 'Adult': 171,\n 'staff': 172,\n 'In': 173,\n 'keep': 174,\n 'them': 175,\n 'shelves': 176,\n 'via': 177,\n 'say': 178,\n 'cause': 179,\n 'parents': 180,\n 'needs': 181,\n 'money': 182,\n 'her': 183,\n 'were': 184,\n 'provide': 185,\n 'customers': 186,\n 'coronapocolypse': 187,\n 'Please': 188,\n '65': 189,\n '2': 190,\n 'while': 191,\n 'closed': 192,\n 'days': 193,\n 'emergency': 194,\n 'workers': 195,\n 'great': 196,\n 'important': 197,\n 'many': 198,\n 'making': 199,\n 'itÂ\\x92s': 200,\n 'when': 201,\n 'test': 202,\n 'support': 203,\n 'delivery': 204,\n 'under': 205,\n 'crisis': 206,\n 'paid': 207,\n 'advice': 208,\n 'neighbours': 209,\n 'numbers': 210,\n 'schools': 211,\n 'set': 212,\n 'order': 213,\n 'elderly': 214,\n 'amid': 215,\n 'only': 216,\n 'which': 217,\n 'PLEASE': 218,\n 'take': 219,\n 'than': 220,\n 'calm': 221,\n 'COVID_19': 222,\n 'confinement': 223,\n 'Me': 224,\n 'Not': 225,\n 'shortage': 226,\n 'first': 227,\n 'came': 228,\n 'County': 229,\n 'last': 230,\n 'week': 231,\n 'hand': 232,\n 'sharing': 233,\n 'To': 234,\n 'he': 235,\n 'know': 236,\n 'covid_19': 237,\n 'Due': 238,\n 'business': 239,\n 'next': 240,\n 'two': 241,\n '16': 242,\n 'Thank': 243,\n 'corona': 244,\n 'stop': 245,\n 'things': 246,\n 'Its': 247,\n 'COVID': 248,\n 'supermarkets': 249,\n 'restaurants': 250,\n 'closing': 251,\n 'same': 252,\n 'lockdown': 253,\n 'wait': 254,\n 'particularly': 255,\n 'thank': 256,\n 'ensure': 257,\n 'doors': 258,\n 'isolation': 259,\n 'symptoms': 260,\n 'Brands': 261,\n '_': 262,\n 'where': 263,\n 'Foods': 264,\n 'Grocery': 265,\n 'struggling': 266,\n 'nonprofit': 267,\n 'services': 268,\n 'impacts': 269,\n 'jobs': 270,\n 'way': 271,\n 'life': 272,\n '100': 273,\n 'covid': 274,\n 'world': 275,\n 'must': 276,\n 'china': 277,\n 'decisions': 278,\n 'AMAZING': 279,\n 'CHEAP': 280,\n 'DEALS': 281,\n 'THE': 282,\n 'going': 283,\n 'Trials': 284,\n 'Monthly': 285,\n 'Yearly': 286,\n 'Resonable': 287,\n 'Prices': 288,\n 'Subscriptions': 289,\n 'DM': 290,\n 'US': 291,\n 'bestiptv': 292,\n 'iptv': 293,\n 'Service': 294,\n 'Iptv': 295,\n 'iptvdeals': 296,\n 'Cheap': 297,\n 'ipTV': 298,\n 'Football': 299,\n 'HD': 300,\n 'Movies': 301,\n 'Cinema': 302,\n 'hotmovies': 303,\n '10DowningStreet': 304,\n 'left': 305,\n 'actions': 306,\n 'selfish': 307,\n 'UK': 308,\n 'expect': 309,\n '12': 310,\n 'full': 311,\n 'morning': 312,\n 'tested': 313,\n 'far': 314,\n 'doing': 315,\n 'Do': 316,\n 'NYC': 317,\n 'file': 318,\n 'complaint': 319,\n 'United': 320,\n 'States': 321,\n 'Breaking': 322,\n 'fact': 323,\n 'Were': 324,\n 'health': 325,\n 'any': 326,\n 'Went': 327,\n 'yesterday': 328,\n 'Corona': 329,\n 'Yes': 330,\n 'But': 331,\n 'posting': 332,\n 'photos': 333,\n 'stuff': 334,\n 'themselves': 335,\n 'everything': 336,\n 'Worried': 337,\n 'current': 338,\n 'times': 339,\n 'works': 340,\n 'saying': 341,\n 'deep': 342,\n 'clean': 343,\n 'gon': 344,\n 'na': 345,\n 'without': 346,\n 'Online': 347,\n 'placed': 348,\n 'unable': 349,\n 'too': 350,\n 'economy': 351,\n 'clothes': 352,\n 'QuarantineLife': 353,\n 'line': 354,\n 'basic': 355,\n 'issues': 356,\n 'offering': 357,\n 'deliveries': 358,\n 'People': 359,\n 'completely': 360,\n 'come': 361,\n 'back': 362,\n 'restrictions': 363,\n 'run': 364,\n 'cannabis': 365,\n 'yet': 366,\n 'stocking': 367,\n 'coming': 368,\n 'before': 369,\n 'remain': 370,\n 'water': 371,\n 'companies': 372,\n 'close': 373,\n 'canÂ\\x92t': 374,\n 'Ive': 375,\n 'staying': 376,\n 'markets': 377,\n 'Of': 378,\n 'why': 379,\n 'Malaysia': 380,\n 'facing': 381,\n 'surprise': 382,\n 'called': 383,\n 'So': 384,\n 'care': 385,\n 'house': 386,\n 'Sadly': 387,\n 'necessary': 388,\n 'mean': 389,\n 'word': 390,\n 'donÂ\\x92t': 391,\n 'seafood': 392,\n 'student': 393,\n 'loan': 394,\n 'stopping': 395,\n 'economic': 396,\n 'though': 397,\n 'BorisJohnson': 398,\n 'government': 399,\n 'pressure': 400,\n 'omnichannel': 401,\n 'idea': 402,\n 'wont': 403,\n 'DO': 404,\n 'older': 405,\n 'plan': 406,\n 'IÂ\\x92ve': 407,\n 'public': 408,\n 'events': 409,\n 'hoard': 410,\n 'supply': 411,\n 'chain': 412,\n 'stocked': 413,\n 'by': 414,\n 'You': 415,\n 'employees': 416,\n 'potatoes': 417,\n 'MeNyrbie': 418,\n 'Phil_Gahan': 419,\n 'Chrisitv': 420,\n 'httpstcoiFz9FAn2Pa': 421,\n 'httpstcoxX6ghGFzCC': 422,\n 'httpstcoI2NlzdxNo8': 423,\n 'Talk': 424,\n 'exchange': 425,\n 'create': 426,\n 'contact': 427,\n 'list': 428,\n 'employer': 429,\n 'chemist': 430,\n 'GP': 431,\n 'accounts': 432,\n 'poss': 433,\n 'adequate': 434,\n 'regular': 435,\n 'meds': 436,\n 'Australia': 437,\n 'Woolworths': 438,\n 'give': 439,\n 'disabled': 440,\n 'dedicated': 441,\n 'httpstcobInCA9Vp8P': 442,\n 'THERE': 443,\n 'WILL': 444,\n 'BE': 445,\n 'ENOUGH': 446,\n 'FOOD': 447,\n 'EVERYONE': 448,\n 'COVID19france': 449,\n 'Confinementotal': 450,\n 'ConfinementGeneral': 451,\n 'httpstcozrlG0Z520j': 452,\n 'ready': 453,\n 'paranoid': 454,\n 'litteraly': 455,\n 'serious': 456,\n 'thing': 457,\n 'causes': 458,\n 'CoronavirusFrance': 459,\n 'restezchezvous': 460,\n 'StayAtHome': 461,\n 'httpstcousmuaLq72n': 462,\n 'regionÂ\\x92s': 463,\n 'confirmed': 464,\n 'Sullivan': 465,\n 'flocked': 466,\n 'area': 467,\n 'cleaning': 468,\n 'sanitizer': 469,\n 'Tim_Dodson': 470,\n 'reports': 471,\n 'httpstcocfXch7a2lU': 472,\n 'Cashier': 473,\n 'insights': 474,\n 'prove': 475,\n 'credibility': 476,\n 'commented': 477,\n 'Civics': 478,\n 'class': 479,\n 'talking': 480,\n 'httpstcoieFDNeHgDO': 481,\n 'Was': 482,\n 'Didnt': 483,\n 'Rebel': 484,\n 'toiletpapercrisis': 485,\n 'httpstcoeVXkQLIdAZ': 486,\n 'classroom': 487,\n 'Atlanta': 488,\n 'walkin': 489,\n 'classes': 490,\n 'beginning': 491,\n 'Monday': 492,\n 'continue': 493,\n 'process': 494,\n 'normal': 495,\n 'understanding': 496,\n 'httpstcokw91zJ5O5i': 497,\n 'preventionwe': 498,\n 'cash': 499,\n 'payment': 500,\n 'methods': 501,\n 'through': 502,\n 'notes': 503,\n 'Also': 504,\n 'prefer': 505,\n 'fight': 506,\n 'against': 507,\n 'govindia': 508,\n 'IndiaFightsCorona': 509,\n 'month': 510,\n 'hasnt': 511,\n 'crowding': 512,\n 'however': 513,\n 'reducing': 514,\n 'malls': 515,\n 'means': 516,\n 'using': 517,\n 'entrance': 518,\n 'dependent': 519,\n 'single': 520,\n 'manila': 521,\n 'covid2019': 522,\n 'Philippines': 523,\n 'httpstcoHxWs9LAnF9': 524,\n 'longer': 525,\n 'beef': 526,\n 'share': 527,\n 'freezer': 528,\n 'packs': 529,\n 'patience': 530,\n 'horningsea': 531,\n 'caring': 532,\n 'LetÂ\\x92s': 533,\n 'ALL': 534,\n 'look': 535,\n 'less': 536,\n 'capable': 537,\n 'village': 538,\n 'Bringing': 539,\n 'self': 540,\n 'exposed': 541,\n 'somebody': 542,\n 'httpstcolsGrXXhjhh': 543,\n 'Ill': 544,\n 'deliver': 545,\n 'whatever': 546,\n 'CoronaVirus': 547,\n 'httpstco8YWaKFjExC': 548,\n 'ADARA': 549,\n 'Releases': 550,\n 'Resource': 551,\n 'Center': 552,\n 'Insights': 553,\n 'Help': 554,\n 'UpToDate': 555,\n 'Behavior': 556,\n 'Trends': 557,\n 'httpstcoPnA797jDKV': 558,\n 'httpstcodQox6uSihz': 559,\n 'Lines': 560,\n 'unpredictable': 561,\n 'eating': 562,\n 'alternative': 563,\n 'Find': 564,\n 'whether': 565,\n 'avoiding': 566,\n 'right': 567,\n 'httpstco9idZSis5oQ': 568,\n 'httpstcoZHbh898lf6': 569,\n '13': 570,\n 'httpstco51bL8P6vZh': 571,\n 'eyeonthearctic': 572,\n '16MAR20': 573,\n 'Russia': 574,\n 'surveillance': 575,\n 'watchdog': 576,\n 'reported': 577,\n 'high': 578,\n 'Arctic': 579,\n 'man': 580,\n 'traveled': 581,\n 'Iran': 582,\n '101': 583,\n 'observed': 584,\n 'httpstco4WnrrK9oKC': 585,\n 'httpstcold05k5Eyns': 586,\n 'Glitch': 587,\n 'Stymies': 588,\n 'Whole': 589,\n 'Fresh': 590,\n 'Deliveries': 591,\n 'Â\\x93As': 592,\n 'weÂ\\x92ve': 593,\n 'significant': 594,\n 'groceriesÂ\\x94': 595,\n 'spokeswoman': 596,\n 'said': 597,\n 'statement': 598,\n 'Â\\x93Today': 599,\n 'resulted': 600,\n 'systems': 601,\n 'affecting': 602,\n 'httpstcoTbzZ2MC3b3': 603,\n 'arent': 604,\n 'consider': 605,\n 'donating': 606,\n 'bank': 607,\n 'peoples': 608,\n 'nations': 609,\n 'inficted': 610,\n 'play': 611,\n 'fair': 612,\n 'goverments': 613,\n 'adopts': 614,\n 'guilde': 615,\n 'lines': 616,\n 'safty': 617,\n 'chinese': 618,\n 'goverment': 619,\n 'guilty': 620,\n 'irosponcible': 621,\n 'global': 622,\n 'scale': 623,\n 'httpstcoAVKrR9syff': 624,\n 'impacting': 625,\n 'behavior': 626,\n 'sales': 627,\n 'according': 628,\n 'First': 629,\n 'Insight': 630,\n 'study': 631,\n 'iptvnew': 632,\n 'iptv2020': 633,\n 'ipTv': 634,\n 'IPTVLinks': 635,\n '18Movies': 636,\n 'grantshapps': 637,\n 'done': 638,\n 'essential': 639,\n 'restocked': 640,\n 'actively': 641,\n 'discouraged': 642,\n 'checkout': 643,\n 'police': 644,\n 'profiteer': 645,\n 'poll': 646,\n 'indicates': 647,\n 'majority': 648,\n 'covid19s': 649,\n '412': 650,\n 'tracker': 651,\n 'See': 652,\n 'results': 653,\n 'RetailX': 654,\n 'Confidence': 655,\n 'Tracker': 656,\n 'httpstcoK3uJlcjqDB': 657,\n 'httpstco9G3kgqIXJ8': 658,\n 'preparation': 659,\n 'higher': 660,\n 'potential': 661,\n 'Hunger': 662,\n 'Coalition': 663,\n 'purchased': 664,\n '10': 665,\n 'percent': 666,\n 'implemented': 667,\n 'protocols': 668,\n 'httpstco5CecYtLnYn': 669,\n 'Covid': 670,\n 'feel': 671,\n 'ok': 672,\n 'isolated': 673,\n 'since': 674,\n 'found': 675,\n 'possible': 676,\n 'exposure': 677,\n 'pragmatic': 678,\n 'updated': 679,\n 'IÂ\\x92m': 680,\n 'httpstcoLg7HVMZglZ': 681,\n 'malicious': 682,\n 'price': 683,\n 'increases': 684,\n 'Department': 685,\n 'Worker': 686,\n 'Protection': 687,\n 'DCWP': 688,\n 'page': 689,\n 'digitally': 690,\n 'Click': 691,\n 'httpstcooEx6Y8mm2K': 692,\n 'wordOvercharge': 693,\n 'httpstcoMdMmoBttOP': 694,\n 'CovidNYC': 695,\n '7SealsOfTheEnd': 696,\n 'Soon': 697,\n 'dwindling': 698,\n 'unlawful': 699,\n 'Panicky': 700,\n 'breaking': 701,\n 'Closed': 702,\n 'Stores': 703,\n 'Supermarkets': 704,\n 'Raid': 705,\n 'normally': 706,\n 'Crisis': 707,\n 'massive': 708,\n 'StockUpamp': 709,\n 'LockUp': 710,\n 'There': 711,\n 'Is': 712,\n 'Country': 713,\n 'ensues': 714,\n 'Hole': 715,\n 'images': 716,\n 'nicest': 717,\n 'richest': 718,\n 'neighborhoods': 719,\n 'httpstcoWnQSoMtkVI': 720,\n 'BreakingNews': 721,\n 'Collapse': 722,\n 'Retail': 723,\n 'closures': 724,\n 'explode': 725,\n 'CNBC': 726,\n 'BrickAndMortar': 727,\n 'httpstcohQrYRNXFhv': 728,\n 'httpstcog5UZn06gb6': 729,\n 'fun': 730,\n 'cough': 731,\n 'whole': 732,\n 'aisle': 733,\n 'yourself': 734,\n 'pretty': 735,\n 'quickly': 736,\n 'sorry': 737,\n 'FinFabUK': 738,\n 'event': 739,\n 'cancelled': 740,\n 'wellbeing': 741,\n 'attendees': 742,\n 'speakers': 743,\n 'top': 744,\n 'priority': 745,\n 'Apologies': 746,\n 'disappointment': 747,\n 'FAQs': 748,\n 'answered': 749,\n 'link': 750,\n 'below': 751,\n 'httpstcoGDDPTudCvj': 752,\n 'gone': 753,\n 'Has': 754,\n 'anything': 755,\n 'whats': 756,\n 'point': 757,\n 'load': 758,\n 'kids': 759,\n 'siblings': 760,\n 'cant': 761,\n 'viral': 762,\n 'alr': 763,\n 'finances': 764,\n 'WeÂ\\x92ve': 765,\n 'published': 766,\n 'tips': 767,\n 'manage': 768,\n 'challenging': 769,\n 'httpstco3jKK3CqXfQ': 770,\n 'httpstcoEbEnURmmJS': 771,\n 'wife': 772,\n 'retailamp': 773,\n 'customer': 774,\n 'coughing': 775,\n 'everywhere': 776,\n 'CoVid19': 777,\n 'requested': 778,\n 'company': 779,\n 'objected': 780,\n 'cost': 781,\n 'recommending': 782,\n 'team': 783,\n 'spray': 784,\n 'disinfectantamp': 785,\n 'dieget': 786,\n 'capitalism': 787,\n 'Now': 788,\n 'judged': 789,\n 'httpstcokrTCGiUHQS': 790,\n 'experience': 791,\n 'environment': 792,\n 'associates': 793,\n 'httpstcodCSXHUj3U0': 794,\n 'jlmco': 795,\n 'jlmcobrand': 796,\n 'shoponline': 797,\n 'httpstcoriNKwskeRS': 798,\n 'Curious': 799,\n 'shoppers': 800,\n 'lot': 801,\n 'bc': 802,\n 'theyre': 803,\n 'spooked': 804,\n 'extra': 805,\n 'pair': 806,\n 'shoes': 807,\n 'onlineshopping': 808,\n 'stayhome': 809,\n 'CHECK': 810,\n 'VIDEO': 811,\n 'httpstco1ksn9Brl02': 812,\n 'USA': 813,\n 'market': 814,\n 'die': 815,\n 'starvation': 816,\n 'houston': 817,\n 'nofood': 818,\n 'Notoiletpaper': 819,\n 'NoHandShakes': 820,\n 'nohandsanitizer': 821,\n 'totallockdown': 822,\n 'COVID2019usa': 823,\n 'walmart': 824,\n 'httpstcoztN3iMkgpD': 825,\n 'Story': 826,\n 'rises': 827,\n 'find': 828,\n 'mysterious': 829,\n 'white': 830,\n 'patches': 831,\n 'forming': 832,\n 'IMadeThisUp': 833,\n 'FakeNews': 834,\n 'httpstco5Z24hptT9M': 835,\n 'outside': 836,\n 'Target': 837,\n 'South': 838,\n 'Africans': 839,\n 'hits': 840,\n 'httpstco6nGNFJmy89': 841,\n 'CoronaVirusSA': 842,\n 'httpstcopzirO10avf': 843,\n 'Share': 844,\n 'Know': 845,\n 'someone': 846,\n 's': 847,\n 'Living': 848,\n 'own': 849,\n 'local': 850,\n 'around': 851,\n 're': 852,\n 'FREE': 853,\n 'soups': 854,\n 'NATIONWIDE': 855,\n 'anyone': 856,\n 'Plus': 857,\n 'freezable': 858,\n 'half': 859,\n 'calling': 860,\n 'dumb': 861,\n 'idiots': 862,\n 'lol': 863,\n 'Never': 864,\n 'thought': 865,\n 'Id': 866,\n '2019': 867,\n 'Will': 868,\n 'peoplearelosingtheirminds': 869,\n 'StopTheMadness': 870,\n 'stoppanicbuying': 871,\n 'sparking': 872,\n 'Theyre': 873,\n 'Customers': 874,\n 'weekend': 875,\n 'preparing': 876,\n 'httpstcoWMqR8QWoiG': 877,\n 'Everything': 878,\n 'weÂ\\x92re': 879,\n 'seeing': 880,\n 'previous': 881,\n 'epidemics': 882,\n 'pandemics': 883,\n 'rise': 884,\n 'fear': 885,\n 'racism': 886,\n 'medicines': 887,\n 'conspiracy': 888,\n 'theories': 889,\n 'proliferation': 890,\n 'quack': 891,\n 'cures': 892,\n 'httpstcoPr8NpKX41A': 893,\n 'Everyone': 894,\n 'socialdistancing': 895,\n 'httpstcoWtB0B1AMON': 896,\n 'Why': 897,\n 'utility': 898,\n 'shut': 899,\n 'off': 900,\n 'middle': 901,\n 'thier': 902,\n 'lose': 903,\n 'kid': 904,\n 'afford': 905,\n 'worth': 906,\n 'SenatorRomney': 907,\n 'httpstco0CV0793olS': 908,\n 'Dear': 909,\n 'following': 910,\n 'social': 911,\n 'distancing': 912,\n 'rules': 913,\n 'prevent': 914,\n 'However': 915,\n 'spent': 916,\n 'alarming': 917,\n 'amount': 918,\n 'Where': 919,\n 'submit': 920,\n 'expenses': 921,\n 'reimbursement': 922,\n 'Let': 923,\n 'Global': 924,\n 'intensified': 925,\n 'across': 926,\n 'several': 927,\n 'geographies': 928,\n 'further': 929,\n 'downward': 930,\n 'pressures': 931,\n 'continued': 932,\n 'well': 933,\n 'supplied': 934,\n 'negative': 935,\n 'resulting': 936,\n 'Morning': 937,\n 'day': 938,\n 'StopPanicBuying': 939,\n 'BeKind': 940,\n 'mufc': 941,\n 'MUFC_Family': 942,\n 'youre': 943,\n 'afraid': 944,\n 'worst': 945,\n 'scenario': 946,\n 'wash': 947,\n 'tub': 948,\n 'Yall': 949,\n 'crazy': 950,\n 'THANK': 951,\n 'YOUR': 952,\n 'GROCERY': 953,\n 'CLERK': 954,\n 'looked': 955,\n 'weary': 956,\n 'eyes': 957,\n 'clerk': 958,\n 'thanked': 959,\n 'realized': 960,\n 'she': 961,\n 'thrust': 962,\n 'front': 963,\n 'panick': 964,\n 'A': 965,\n 'breed': 966,\n 'responders': 967,\n 'working': 968,\n 'hard': 969,\n 'serve': 970,\n 'communities': 971,\n 'With': 972,\n 'entire': 973,\n 'shops': 974,\n 'challenges': 975,\n 'near': 976,\n 'future': 977,\n 'lost': 978,\n 'Malaysia2020': 979,\n 'thoughts': 980,\n 'httpstcobPodDdPRcE': 981,\n 'Corner': 982,\n 'Scammers': 983,\n 'Taking': 984,\n 'Advantage': 985,\n 'Fears': 986,\n 'cdc': 987,\n 'flu': 988,\n 'trends': 989,\n 'alert': 990,\n 'httpstcosk9qCJsnYl': 991,\n 'httpstcoT7qejP3hys': 992,\n '4': 993,\n 'Both': 994,\n 'masks': 995,\n 'made': 996,\n 'medical': 997,\n 'personnel': 998,\n 'require': 999,\n ...}"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "\n",
    "index_to_word ={}\n",
    "for k,v in enumerate(word_to_index):\n",
    "    index_to_word[k] = v\n",
    "#data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "word_to_index['OOV'] = len(word_to_index) +1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% out of word\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeNyrbie\n",
      "Phil_Gahan\n",
      "Chrisitv\n",
      "httpstcoiFz9FAn2Pa\n",
      "and\n",
      "httpstcoxX6ghGFzCC\n",
      "and\n",
      "httpstcoI2NlzdxNo8\n",
      "advice\n",
      "Talk\n",
      "to\n",
      "your\n",
      "neighbours\n",
      "family\n",
      "to\n",
      "exchange\n",
      "phone\n",
      "numbers\n",
      "create\n",
      "contact\n",
      "list\n",
      "with\n",
      "phone\n",
      "numbers\n",
      "of\n",
      "neighbours\n",
      "schools\n",
      "employer\n",
      "chemist\n",
      "GP\n",
      "set\n",
      "up\n",
      "online\n",
      "shopping\n",
      "accounts\n",
      "if\n",
      "poss\n",
      "adequate\n",
      "supplies\n",
      "of\n",
      "regular\n",
      "meds\n",
      "but\n",
      "not\n",
      "over\n",
      "order\n",
      "Coronavirus\n",
      "Australia\n",
      "Woolworths\n",
      "to\n",
      "give\n",
      "elderly\n",
      "disabled\n",
      "dedicated\n",
      "shopping\n",
      "hours\n",
      "amid\n",
      "COVID19\n",
      "outbreak\n",
      "httpstcobInCA9Vp8P\n",
      "My\n",
      "food\n",
      "stock\n",
      "is\n",
      "not\n",
      "the\n",
      "only\n",
      "one\n",
      "which\n",
      "is\n",
      "empty\r\n",
      "\r\n",
      "PLEASE\n",
      "dont\n",
      "panic\n",
      "THERE\n",
      "WILL\n",
      "BE\n",
      "ENOUGH\n",
      "FOOD\n",
      "FOR\n",
      "EVERYONE\n",
      "if\n",
      "you\n",
      "do\n",
      "not\n",
      "take\n",
      "more\n",
      "than\n",
      "you\n",
      "need\n",
      "\r\n",
      "Stay\n",
      "calm\n",
      "stay\n",
      "safe\r\n",
      "\r\n",
      "COVID19france\n",
      "COVID_19\n",
      "COVID19\n",
      "coronavirus\n",
      "confinement\n",
      "Confinementotal\n",
      "ConfinementGeneral\n",
      "httpstcozrlG0Z520j\n",
      "Me\n",
      "ready\n",
      "to\n",
      "go\n",
      "at\n",
      "supermarket\n",
      "during\n",
      "the\n",
      "COVID19\n",
      "outbreak\r\n",
      "\r\n",
      "Not\n",
      "because\n",
      "Im\n",
      "paranoid\n",
      "but\n",
      "because\n",
      "my\n",
      "food\n",
      "stock\n",
      "is\n",
      "litteraly\n",
      "empty\n",
      "The\n",
      "coronavirus\n",
      "is\n",
      "a\n",
      "serious\n",
      "thing\n",
      "but\n",
      "please\n",
      "dont\n",
      "panic\n",
      "It\n",
      "causes\n",
      "shortage\r\n",
      "\r\n",
      "CoronavirusFrance\n",
      "restezchezvous\n",
      "StayAtHome\n",
      "confinement\n",
      "httpstcousmuaLq72n\n",
      "As\n",
      "news\n",
      "of\n",
      "the\n",
      "regionÂs\n",
      "first\n",
      "confirmed\n",
      "COVID19\n",
      "case\n",
      "came\n",
      "out\n",
      "of\n",
      "Sullivan\n",
      "County\n",
      "last\n",
      "week\n",
      "people\n",
      "flocked\n",
      "to\n",
      "area\n",
      "stores\n",
      "to\n",
      "purchase\n",
      "cleaning\n",
      "supplies\n",
      "hand\n",
      "sanitizer\n",
      "food\n",
      "toilet\n",
      "paper\n",
      "and\n",
      "other\n",
      "goods\n",
      "Tim_Dodson\n",
      "reports\n",
      "httpstcocfXch7a2lU\n",
      "Cashier\n",
      "at\n",
      "grocery\n",
      "store\n",
      "was\n",
      "sharing\n",
      "his\n",
      "insights\n",
      "on\n",
      "Covid_19\n",
      "To\n",
      "prove\n",
      "his\n",
      "credibility\n",
      "he\n",
      "commented\n",
      "Im\n",
      "in\n",
      "Civics\n",
      "class\n",
      "so\n",
      "I\n",
      "know\n",
      "what\n",
      "Im\n",
      "talking\n",
      "about\n",
      "httpstcoieFDNeHgDO\n",
      "Was\n",
      "at\n",
      "the\n",
      "supermarket\n",
      "today\n",
      "Didnt\n",
      "buy\n",
      "toilet\n",
      "paper\n",
      "Rebel\r\n",
      "\r\n",
      "toiletpapercrisis\n",
      "covid_19\n",
      "httpstcoeVXkQLIdAZ\n",
      "Due\n",
      "to\n",
      "COVID19\n",
      "our\n",
      "retail\n",
      "store\n",
      "and\n",
      "classroom\n",
      "in\n",
      "Atlanta\n",
      "will\n",
      "not\n",
      "be\n",
      "open\n",
      "for\n",
      "walkin\n",
      "business\n",
      "or\n",
      "classes\n",
      "for\n",
      "the\n",
      "next\n",
      "two\n",
      "weeks\n",
      "beginning\n",
      "Monday\n",
      "March\n",
      "16\n",
      "\n",
      "We\n",
      "will\n",
      "continue\n",
      "to\n",
      "process\n",
      "online\n",
      "and\n",
      "phone\n",
      "orders\n",
      "as\n",
      "normal\n",
      "Thank\n",
      "you\n",
      "for\n",
      "your\n",
      "understanding\n",
      "httpstcokw91zJ5O5i\n",
      "For\n",
      "corona\n",
      "preventionwe\n",
      "should\n",
      "stop\n",
      "to\n",
      "buy\n",
      "things\n",
      "with\n",
      "the\n",
      "cash\n",
      "and\n",
      "should\n",
      "use\n",
      "online\n",
      "payment\n",
      "methods\n",
      "because\n",
      "corona\n",
      "can\n",
      "spread\n",
      "through\n",
      "the\n",
      "notes\n",
      "Also\n",
      "we\n",
      "should\n",
      "prefer\n",
      "online\n",
      "shopping\n",
      "from\n",
      "our\n",
      "home\n",
      "Its\n",
      "time\n",
      "to\n",
      "fight\n",
      "against\n",
      "COVID\n",
      "19\n",
      "govindia\n",
      "IndiaFightsCorona\n",
      "All\n",
      "month\n",
      "there\n",
      "hasnt\n",
      "been\n",
      "crowding\n",
      "in\n",
      "the\n",
      "supermarkets\n",
      "or\n",
      "restaurants\n",
      "however\n",
      "reducing\n",
      "all\n",
      "the\n",
      "hours\n",
      "and\n",
      "closing\n",
      "the\n",
      "malls\n",
      "means\n",
      "everyone\n",
      "is\n",
      "now\n",
      "using\n",
      "the\n",
      "same\n",
      "entrance\n",
      "and\n",
      "dependent\n",
      "on\n",
      "a\n",
      "single\n",
      "supermarket\n",
      "manila\n",
      "lockdown\n",
      "covid2019\n",
      "Philippines\n",
      "httpstcoHxWs9LAnF9\n",
      "Due\n",
      "to\n",
      "the\n",
      "Covid19\n",
      "situation\n",
      "we\n",
      "have\n",
      "increased\n",
      "demand\n",
      "for\n",
      "all\n",
      "food\n",
      "products\n",
      "\r\n",
      "\r\n",
      "The\n",
      "wait\n",
      "time\n",
      "may\n",
      "be\n",
      "longer\n",
      "for\n",
      "all\n",
      "online\n",
      "orders\n",
      "particularly\n",
      "beef\n",
      "share\n",
      "and\n",
      "freezer\n",
      "packs\n",
      "\r\n",
      "\r\n",
      "We\n",
      "thank\n",
      "you\n",
      "for\n",
      "your\n",
      "patience\n",
      "during\n",
      "this\n",
      "time\n",
      "horningsea\n",
      "is\n",
      "a\n",
      "caring\n",
      "community\n",
      "LetÂs\n",
      "ALL\n",
      "look\n",
      "after\n",
      "the\n",
      "less\n",
      "capable\n",
      "in\n",
      "our\n",
      "village\n",
      "and\n",
      "ensure\n",
      "they\n",
      "stay\n",
      "healthy\n",
      "Bringing\n",
      "shopping\n",
      "to\n",
      "their\n",
      "doors\n",
      "help\n",
      "with\n",
      "online\n",
      "shopping\n",
      "and\n",
      "self\n",
      "isolation\n",
      "if\n",
      "you\n",
      "have\n",
      "symptoms\n",
      "or\n",
      "been\n",
      "exposed\n",
      "to\n",
      "somebody\n",
      "who\n",
      "has\n",
      "httpstcolsGrXXhjhh\n",
      "Me\n",
      "I\n",
      "dont\n",
      "need\n",
      "to\n",
      "stock\n",
      "up\n",
      "on\n",
      "food\n",
      "Ill\n",
      "just\n",
      "have\n",
      "Amazon\n",
      "deliver\n",
      "whatever\n",
      "I\n",
      "need\n",
      "CoronaVirus\r\n",
      "\r\n",
      "Amazon\n",
      "httpstco8YWaKFjExC\n",
      "ADARA\n",
      "Releases\n",
      "COVID19\n",
      "Resource\n",
      "Center\n",
      "for\n",
      "Travel\n",
      "Brands\n",
      "Insights\n",
      "Help\n",
      "Travel\n",
      "Brands\n",
      "Stay\n",
      "UpToDate\n",
      "on\n",
      "Consumer\n",
      "Travel\n",
      "Behavior\n",
      "Trends\n",
      "httpstcoPnA797jDKV\n",
      "httpstcodQox6uSihz\n",
      "Lines\n",
      "at\n",
      "the\n",
      "grocery\n",
      "store\n",
      "have\n",
      "been\n",
      "unpredictable\n",
      "but\n",
      "is\n",
      "eating\n",
      "out\n",
      "a\n",
      "safe\n",
      "alternative\n",
      "\r\n",
      "\r\n",
      "Find\n",
      "out\n",
      "more\n",
      "about\n",
      "whether\n",
      "you\n",
      "should\n",
      "be\n",
      "avoiding\n",
      "restaurants\n",
      "right\n",
      "now\n",
      "\n",
      "httpstco9idZSis5oQ\r\n",
      "\r\n",
      "coronavirus\n",
      "covid19\n",
      "httpstcoZHbh898lf6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "_\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "_\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpstco51bL8P6vZh\n",
      "eyeonthearctic\n",
      "16MAR20\n",
      "Russia\n",
      "consumer\n",
      "surveillance\n",
      "watchdog\n",
      "reported\n",
      "case\n",
      "in\n",
      "high\n",
      "Arctic\n",
      "where\n",
      "a\n",
      "man\n",
      "who\n",
      "traveled\n",
      "to\n",
      "Iran\n",
      "has\n",
      "COVID19\n",
      "and\n",
      "101\n",
      "are\n",
      "observed\r\n",
      "httpstco4WnrrK9oKC\n",
      "httpstcold05k5Eyns\n",
      "Amazon\n",
      "Glitch\n",
      "Stymies\n",
      "Whole\n",
      "Foods\n",
      "Fresh\n",
      "Grocery\n",
      "Deliveries\r\n",
      "ÂAs\n",
      "COVID19\n",
      "has\n",
      "spread\n",
      "weÂve\n",
      "seen\n",
      "a\n",
      "significant\n",
      "increase\n",
      "in\n",
      "people\n",
      "shopping\n",
      "online\n",
      "for\n",
      "groceriesÂ\n",
      "a\n",
      "spokeswoman\n",
      "said\n",
      "in\n",
      "a\n",
      "statement\n",
      "ÂToday\n",
      "this\n",
      "resulted\n",
      "in\n",
      "a\n",
      "systems\n",
      "impact\n",
      "affecting\n",
      "our\n",
      "\r\n",
      "\n",
      "httpstcoTbzZ2MC3b3\n",
      "For\n",
      "those\n",
      "who\n",
      "arent\n",
      "struggling\n",
      "please\n",
      "consider\n",
      "donating\n",
      "to\n",
      "a\n",
      "food\n",
      "bank\n",
      "or\n",
      "a\n",
      "nonprofit\n",
      "The\n",
      "demand\n",
      "for\n",
      "these\n",
      "services\n",
      "will\n",
      "increase\n",
      "as\n",
      "COVID19\n",
      "impacts\n",
      "jobs\n",
      "and\n",
      "peoples\n",
      "way\n",
      "of\n",
      "life\n",
      "with\n",
      "100\n",
      "\n",
      "nations\n",
      "inficted\n",
      "with\n",
      "\n",
      "covid\n",
      "\n",
      "19\n",
      "\n",
      "the\n",
      "world\n",
      "must\n",
      "\n",
      "not\n",
      "\n",
      "play\n",
      "fair\n",
      "with\n",
      "china\n",
      "\n",
      "100\n",
      "goverments\n",
      "must\n",
      "demand\n",
      "\n",
      "china\n",
      "\n",
      "adopts\n",
      "new\n",
      "guilde\n",
      "\n",
      "lines\n",
      "on\n",
      "food\n",
      "safty\n",
      "\n",
      "the\n",
      "\n",
      "chinese\n",
      "\n",
      "goverment\n",
      "\n",
      "is\n",
      "guilty\n",
      "of\n",
      "\n",
      "being\n",
      "\n",
      "irosponcible\n",
      "\n",
      "\n",
      "with\n",
      "life\n",
      "\n",
      "on\n",
      "a\n",
      "global\n",
      "scale\n",
      "httpstcoAVKrR9syff\r\n",
      "\r\n",
      "The\n",
      "COVID19\n",
      "coronavirus\n",
      "pandemic\n",
      "is\n",
      "impacting\n",
      "consumer\n",
      "shopping\n",
      "behavior\n",
      "purchase\n",
      "decisions\n",
      "and\n",
      "retail\n",
      "sales\n",
      "according\n",
      "to\n",
      "a\n",
      "First\n",
      "Insight\n",
      "study\n",
      "We\n",
      "have\n",
      "AMAZING\n",
      "CHEAP\n",
      "DEALS\n",
      "FOR\n",
      "THE\n",
      "COVID2019\n",
      "going\n",
      "on\n",
      "to\n",
      "help\n",
      "you\r\n",
      "Trials\r\n",
      "Monthly\r\n",
      "Yearly\n",
      "\r\n",
      "And\n",
      "Resonable\n",
      "Prices\n",
      "\n",
      "Subscriptions\r\n",
      "Just\n",
      "DM\n",
      "US\n",
      "bestiptv\n",
      "iptv\n",
      "Service\n",
      "Iptv\n",
      "iptvdeals\n",
      "Cheap\n",
      "ipTV\n",
      "Football\n",
      "HD\n",
      "Movies\n",
      "Adult\n",
      "Cinema\n",
      "hotmovies\n",
      "iptvnew\n",
      "iptv2020\n",
      "Adult\n",
      "We\n",
      "have\n",
      "AMAZING\n",
      "CHEAP\n",
      "DEALS\n",
      "FOR\n",
      "THE\n",
      "COVID2019\n",
      "going\n",
      "on\n",
      "to\n",
      "help\n",
      "you\r\n",
      "Trials\r\n",
      "Monthly\r\n",
      "Yearly\n",
      "\r\n",
      "And\n",
      "Resonable\n",
      "Prices\n",
      "\n",
      "Subscriptions\r\n",
      "Just\n",
      "DM\n",
      "US\n",
      "bestiptv\n",
      "iptv\n",
      "Service\n",
      "Iptv\n",
      "iptvdeals\n",
      "Cheap\n",
      "ipTV\n",
      "Football\n",
      "HD\n",
      "Movies\n",
      "Adult\n",
      "Cinema\n",
      "hotmovies\n",
      "ipTv\n",
      "IPTVLinks\n",
      "18Movies\n",
      "10DowningStreet\n",
      "grantshapps\n",
      "what\n",
      "is\n",
      "being\n",
      "done\n",
      "to\n",
      "ensure\n",
      "food\n",
      "and\n",
      "other\n",
      "essential\n",
      "products\n",
      "are\n",
      "being\n",
      "restocked\n",
      "at\n",
      "supermarkets\n",
      "and\n",
      "panic\n",
      "buying\n",
      "actively\n",
      "discouraged\n",
      "It\n",
      "cannot\n",
      "be\n",
      "left\n",
      "to\n",
      "checkout\n",
      "staff\n",
      "to\n",
      "police\n",
      "the\n",
      "actions\n",
      "of\n",
      "the\n",
      "selfish\n",
      "and\n",
      "profiteer\n",
      "UK\n",
      "consumer\n",
      "poll\n",
      "indicates\n",
      "the\n",
      "majority\n",
      "expect\n",
      "covid19s\n",
      "impact\n",
      "to\n",
      "last\n",
      "412\n",
      "months\n",
      "at\n",
      "12\n",
      "March\n",
      "We\n",
      "expect\n",
      "this\n",
      "to\n",
      "increase\n",
      "at\n",
      "the\n",
      "next\n",
      "tracker\n",
      "See\n",
      "full\n",
      "results\n",
      "of\n",
      "the\n",
      "RetailX\n",
      "Coronavirus\n",
      "Consumer\n",
      "Confidence\n",
      "Tracker\n",
      "here\n",
      "httpstcoK3uJlcjqDB\n",
      "httpstco9G3kgqIXJ8\n",
      "In\n",
      "preparation\n",
      "for\n",
      "higher\n",
      "demand\n",
      "and\n",
      "a\n",
      "potential\n",
      "food\n",
      "shortage\n",
      "The\n",
      "Hunger\n",
      "Coalition\n",
      "purchased\n",
      "10\n",
      "percent\n",
      "more\n",
      "food\n",
      "and\n",
      "implemented\n",
      "new\n",
      "protocols\n",
      "due\n",
      "to\n",
      "the\n",
      "COVID19\n",
      "coronavirus\n",
      "httpstco5CecYtLnYn\n",
      "This\n",
      "morning\n",
      "I\n",
      "tested\n",
      "positive\n",
      "for\n",
      "Covid\n",
      "19\n",
      "I\n",
      "feel\n",
      "ok\n",
      "I\n",
      "have\n",
      "no\n",
      "symptoms\n",
      "so\n",
      "far\n",
      "but\n",
      "have\n",
      "been\n",
      "isolated\n",
      "since\n",
      "I\n",
      "found\n",
      "out\n",
      "about\n",
      "my\n",
      "possible\n",
      "exposure\n",
      "to\n",
      "the\n",
      "virus\n",
      "\n",
      "Stay\n",
      "home\n",
      "people\n",
      "and\n",
      "be\n",
      "pragmatic\n",
      "I\n",
      "will\n",
      "keep\n",
      "you\n",
      "updated\n",
      "on\n",
      "how\n",
      "IÂm\n",
      "doing\n",
      "\n",
      "No\n",
      "panic\n",
      "httpstcoLg7HVMZglZ\n",
      "Do\n",
      "you\n",
      "see\n",
      "malicious\n",
      "price\n",
      "increases\n",
      "in\n",
      "NYC\n",
      "The\n",
      "NYC\n",
      "Department\n",
      "of\n",
      "Consumer\n",
      "and\n",
      "Worker\n",
      "Protection\n",
      "DCWP\n",
      "has\n",
      "set\n",
      "up\n",
      "a\n",
      "page\n",
      "to\n",
      "digitally\n",
      "file\n",
      "a\n",
      "complaint\n",
      "Click\n",
      "here\n",
      "httpstcooEx6Y8mm2K\r\n",
      "\r\n",
      "To\n",
      "file\n",
      "a\n",
      "complaint\n",
      "use\n",
      "the\n",
      "wordOvercharge\n",
      "httpstcoMdMmoBttOP\r\n",
      "COVID19\n",
      "CovidNYC\n",
      "7SealsOfTheEnd\n",
      "Soon\n",
      "with\n",
      "dwindling\n",
      "supplies\n",
      "unlawful\n",
      "Panicky\n",
      "people\n",
      "will\n",
      "be\n",
      "breaking\n",
      "into\n",
      "Closed\n",
      "Stores\n",
      "amp;\n",
      "Supermarkets\n",
      "to\n",
      "Raid\n",
      "them\n",
      "as\n",
      "they\n",
      "normally\n",
      "do\n",
      "during\n",
      "a\n",
      "Crisis\n",
      "so\n",
      "massive\n",
      "as\n",
      "the\n",
      "Coronavirus\r\n",
      "\r\n",
      "StockUpamp;LockUp\n",
      "There\n",
      "Is\n",
      "of\n",
      "in\n",
      "the\n",
      "Country\n",
      "\n",
      "The\n",
      "more\n",
      "empty\n",
      "shelves\n",
      "people\n",
      "see\n",
      "the\n",
      "more\n",
      "buying\n",
      "ensues\n",
      "the\n",
      "more\n",
      "food\n",
      "is\n",
      "out\n",
      "of\n",
      "stock\n",
      "Hole\n",
      "Foods\r\n",
      "\r\n",
      "images\n",
      "from\n",
      "the\n",
      "nicest\n",
      "grocery\n",
      "store\n",
      "in\n",
      "one\n",
      "of\n",
      "the\n",
      "richest\n",
      "neighborhoods\n",
      "in\n",
      "the\n",
      "United\n",
      "States\r\n",
      "\r\n",
      "httpstcoWnQSoMtkVI\r\n",
      "\r\n",
      "BreakingNews\n",
      "Breaking\n",
      "Coronavirus\n",
      "CoronavirusOutbreak\n",
      "COVID19\n",
      "COVID19\n",
      "COVID_19\n",
      "COVID2019\n",
      "Collapse\n",
      "Retail\n",
      "store\n",
      "closures\n",
      "could\n",
      "explode\n",
      "because\n",
      "of\n",
      "the\n",
      "coronavirus\n",
      "via\n",
      "CNBC\n",
      "BrickAndMortar\r\n",
      "\r\n",
      "httpstcohQrYRNXFhv\n",
      "httpstcog5UZn06gb6\n",
      "Coronavirus\n",
      "fun\n",
      "fact\n",
      "if\n",
      "you\n",
      "cough\n",
      "at\n",
      "the\n",
      "grocery\n",
      "store\n",
      "you\n",
      "get\n",
      "the\n",
      "whole\n",
      "aisle\n",
      "to\n",
      "yourself\n",
      "pretty\n",
      "quickly\r\n",
      "CoronavirusOutbreak\n",
      "coronavirus\n",
      "COVID2019\n",
      "Were\n",
      "sorry\n",
      "to\n",
      "say\n",
      "that\n",
      "our\n",
      "FinFabUK\n",
      "event\n",
      "is\n",
      "being\n",
      "cancelled\n",
      "due\n",
      "to\n",
      "Covid19\n",
      "The\n",
      "health\n",
      "and\n",
      "wellbeing\n",
      "of\n",
      "our\n",
      "attendees\n",
      "speakers\n",
      "and\n",
      "staff\n",
      "is\n",
      "our\n",
      "top\n",
      "priority\n",
      "Apologies\n",
      "for\n",
      "any\n",
      "disappointment\n",
      "this\n",
      "may\n",
      "cause\n",
      "All\n",
      "FAQs\n",
      "are\n",
      "answered\n",
      "in\n",
      "the\n",
      "link\n",
      "below\r\n",
      "httpstcoGDDPTudCvj\n",
      "Went\n",
      "to\n",
      "the\n",
      "supermarket\n",
      "yesterday\n",
      "and\n",
      "the\n",
      "toilet\n",
      "paper\n",
      "was\n",
      "gone\n",
      "Has\n",
      "this\n",
      "anything\n",
      "to\n",
      "do\n",
      "with\n",
      "the\n",
      "Corona\n",
      "virus\n",
      "COVID2019\n",
      "Yes\n",
      "buy\n",
      "only\n",
      "what\n",
      "you\n",
      "need\r\n",
      "\r\n",
      "But\n",
      "whats\n",
      "the\n",
      "point\n",
      "of\n",
      "posting\n",
      "photos\n",
      "of\n",
      "those\n",
      "people\n",
      "in\n",
      "the\n",
      "supermarket\n",
      "with\n",
      "a\n",
      "load\n",
      "of\n",
      "stuff\n",
      "They\n",
      "could\n",
      "be\n",
      "buying\n",
      "for\n",
      "all\n",
      "their\n",
      "elderly\n",
      "parents\n",
      "kids\n",
      "siblings\n",
      "etc\n",
      "who\n",
      "cant\n",
      "buy\n",
      "for\n",
      "themselves\r\n",
      "\r\n",
      "Not\n",
      "everything\n",
      "needs\n",
      "to\n",
      "be\n",
      "viral\n",
      "Covid19\n",
      "alr\n",
      "is\n",
      "Worried\n",
      "about\n",
      "the\n",
      "impact\n",
      "of\n",
      "the\n",
      "current\n",
      "COVID19\n",
      "pandemic\n",
      "on\n",
      "your\n",
      "finances\n",
      "WeÂve\n",
      "just\n",
      "published\n",
      "some\n",
      "tips\n",
      "to\n",
      "help\n",
      "you\n",
      "manage\n",
      "your\n",
      "money\n",
      "during\n",
      "these\n",
      "challenging\n",
      "times\n",
      "COVID19\n",
      "httpstco3jKK3CqXfQ\n",
      "httpstcoEbEnURmmJS\n",
      "my\n",
      "wife\n",
      "works\n",
      "retailamp;a\n",
      "customer\n",
      "came\n",
      "in\n",
      "yesterday\n",
      "coughing\n",
      "everywhere\n",
      "saying\n",
      "they\n",
      "have\n",
      "CoVid19\n",
      "They\n",
      "requested\n",
      "a\n",
      "deep\n",
      "clean\n",
      "of\n",
      "the\n",
      "store\n",
      "\n",
      "her\n",
      "company\n",
      "objected\n",
      "to\n",
      "due\n",
      "to\n",
      "cost\n",
      "recommending\n",
      "the\n",
      "team\n",
      "spray\n",
      "disinfectantamp;clean\n",
      "themselves\n",
      "were\n",
      "gonna\n",
      "dieget\n",
      "sick\n",
      "due\n",
      "to\n",
      "capitalism\n",
      "Now\n",
      "I\n",
      "can\n",
      "go\n",
      "to\n",
      "the\n",
      "supermarket\n",
      "like\n",
      "this\n",
      "without\n",
      "being\n",
      "judged\n",
      "\n",
      "CoronavirusOutbreak\n",
      "COVID2019\n",
      "httpstcokrTCGiUHQS\n",
      "Were\n",
      "here\n",
      "to\n",
      "provide\n",
      "a\n",
      "safe\n",
      "shopping\n",
      "experience\n",
      "for\n",
      "our\n",
      "customers\n",
      "and\n",
      "a\n",
      "healthy\n",
      "environment\n",
      "for\n",
      "our\n",
      "associates\n",
      "and\n",
      "community\r\n",
      "Online\n",
      "orders\n",
      "can\n",
      "be\n",
      "placed\n",
      "here\n",
      "httpstcodCSXHUj3U0\r\n",
      "\r\n",
      "jlmco\n",
      "jlmcobrand\n",
      "coronapocolypse\n",
      "coronavirus\n",
      "CoronavirusOutbreak\n",
      "\n",
      "COVID19\n",
      "shoponline\n",
      "httpstcoriNKwskeRS\n",
      "Curious\n",
      "\n",
      "do\n",
      "we\n",
      "think\n",
      "retail\n",
      "shoppers\n",
      "will\n",
      "do\n",
      "a\n",
      "lot\n",
      "of\n",
      "online\n",
      "shopping\n",
      "bc\n",
      "theyre\n",
      "home\n",
      "and\n",
      "unable\n",
      "to\n",
      "go\n",
      "out\n",
      "or\n",
      "do\n",
      "we\n",
      "think\n",
      "everyone\n",
      "is\n",
      "too\n",
      "spooked\n",
      "to\n",
      "get\n",
      "that\n",
      "extra\n",
      "pair\n",
      "of\n",
      "shoes\n",
      "economy\n",
      "onlineshopping\n",
      "coronavirus\n",
      "covid19\n",
      "stayhome\n",
      "CHECK\n",
      "VIDEO\n",
      "\n",
      "httpstco1ksn9Brl02\n",
      "No\n",
      "food\n",
      "\n",
      "in\n",
      "USA\n",
      "market\n",
      "due\n",
      "to\n",
      "coronavirus\n",
      "panic\n",
      "we\n",
      "gonna\n",
      "die\n",
      "from\n",
      "starvation\n",
      "CoronavirusOutbreak\n",
      "coronavirus\n",
      "houston\n",
      "nofood\n",
      "Notoiletpaper\n",
      "NoHandShakes\n",
      "nohandsanitizer\n",
      "COVID19\n",
      "pandemic\n",
      "totallockdown\n",
      "COVID2019usa\n",
      "walmart\n",
      "httpstcoztN3iMkgpD\n",
      "Breaking\n",
      "Story\n",
      "Online\n",
      "clothes\n",
      "shopping\n",
      "rises\n",
      "as\n",
      "people\n",
      "find\n",
      "mysterious\n",
      "white\n",
      "patches\n",
      "forming\n",
      "on\n",
      "clothes\n",
      "QuarantineLife\n",
      "CoronavirusOutbreak\n",
      "coronavirus\n",
      "IMadeThisUp\n",
      "FakeNews\n",
      "httpstco5Z24hptT9M\n",
      "This\n",
      "is\n",
      "the\n",
      "line\n",
      "outside\n",
      "\n",
      "Target\n",
      "\n",
      "in\n",
      "as\n",
      "customers\n",
      "wait\n",
      "for\n",
      "the\n",
      "store\n",
      "to\n",
      "open\n",
      "this\n",
      "morning\n",
      "South\n",
      "Africans\n",
      "stock\n",
      "up\n",
      "on\n",
      "food\n",
      "basic\n",
      "goods\n",
      "as\n",
      "coronavirus\n",
      "panic\n",
      "hits\n",
      "httpstco6nGNFJmy89\r\n",
      "\r\n",
      "CoronaVirusSA\n",
      "\r\n",
      "Covid_19\n",
      "httpstcopzirO10avf\n",
      "\n",
      "Please\n",
      "Share\n",
      "\n",
      "Know\n",
      "someone\n",
      "who\n",
      "s\n",
      "65\n",
      "Living\n",
      "on\n",
      "their\n",
      "own\n",
      "struggling\n",
      "to\n",
      "get\n",
      "2\n",
      "their\n",
      "local\n",
      "supermarket\n",
      "due\n",
      "to\n",
      "issues\n",
      "around\n",
      "19\n",
      "We\n",
      "re\n",
      "offering\n",
      "FREE\n",
      "deliveries\n",
      "of\n",
      "our\n",
      "healthy\n",
      "soups\n",
      "NATIONWIDE\n",
      "to\n",
      "anyone\n",
      "65\n",
      "in\n",
      "need\n",
      "Plus\n",
      "their\n",
      "freezable\n",
      "People\n",
      "posting\n",
      "and\n",
      "sharing\n",
      "photos\n",
      "of\n",
      "of\n",
      "half\n",
      "to\n",
      "completely\n",
      "empty\n",
      "shelves\n",
      "calling\n",
      "those\n",
      "people\n",
      "dumb\n",
      "or\n",
      "idiots\n",
      "All\n",
      "while\n",
      "shopping\n",
      "at\n",
      "the\n",
      "grocery\n",
      "store\n",
      "lol\r\n",
      "\r\n",
      "coronavirus\n",
      "COVID19\n",
      "Never\n",
      "thought\n",
      "Id\n",
      "say\n",
      "this\n",
      "but\n",
      "2019\n",
      "Will\n",
      "you\n",
      "come\n",
      "back\n",
      "PLEASE\n",
      "coronavirus\n",
      "COVID19\n",
      "peoplearelosingtheirminds\n",
      "StopTheMadness\n",
      "stoppanicbuying\n",
      "COVID19\n",
      "restrictions\n",
      "sparking\n",
      "a\n",
      "run\n",
      "on\n",
      "cannabis\n",
      "stores\r\n",
      "\r\n",
      "Theyre\n",
      "not\n",
      "closed\n",
      "yet\n",
      "But\n",
      "Customers\n",
      "are\n",
      "stocking\n",
      "up\n",
      "on\n",
      "cannabis\n",
      "this\n",
      "weekend\n",
      "preparing\n",
      "for\n",
      "what\n",
      "could\n",
      "be\n",
      "more\n",
      "retail\n",
      "store\n",
      "restrictions\n",
      "in\n",
      "coming\n",
      "days\n",
      "httpstcoWMqR8QWoiG\n",
      "Everything\n",
      "weÂre\n",
      "seeing\n",
      "in\n",
      "the\n",
      "current\n",
      "COVID19\n",
      "outbreak\n",
      "has\n",
      "been\n",
      "seen\n",
      "before\n",
      "in\n",
      "previous\n",
      "epidemics\n",
      "and\n",
      "pandemics;\n",
      "the\n",
      "rise\n",
      "of\n",
      "fear\n",
      "racism\n",
      "panic\n",
      "buying\n",
      "of\n",
      "food\n",
      "and\n",
      "medicines\n",
      "conspiracy\n",
      "theories\n",
      "the\n",
      "proliferation\n",
      "of\n",
      "quack\n",
      "cures\n",
      "httpstcoPr8NpKX41A\n",
      "Everyone\n",
      "is\n",
      "closed\n",
      "but\n",
      "we\n",
      "remain\n",
      "open\n",
      "because\n",
      "we\n",
      "are\n",
      "an\n",
      "emergency\n",
      "store\n",
      "Thank\n",
      "your\n",
      "retail\n",
      "workers\r\n",
      "\r\n",
      "covid_19\n",
      "pandemic\n",
      "socialdistancing\n",
      "retail\n",
      "httpstcoWtB0B1AMON\n",
      "Why\n",
      "we\n",
      "stock\n",
      "up\n",
      "on\n",
      "water\n",
      "cause\n",
      "utility\n",
      "companies\n",
      "will\n",
      "shut\n",
      "you\n",
      "off\n",
      "in\n",
      "the\n",
      "middle\n",
      "of\n",
      "a\n",
      "pandemic\n",
      "the\n",
      "schools\n",
      "close\n",
      "thier\n",
      "doors\n",
      "you\n",
      "lose\n",
      "out\n",
      "on\n",
      "work\n",
      "cause\n",
      "your\n",
      "kid\n",
      "has\n",
      "no\n",
      "where\n",
      "to\n",
      "go\n",
      "and\n",
      "you\n",
      "canÂt\n",
      "afford\n",
      "months\n",
      "worth\n",
      "of\n",
      "food\n",
      "coronavirus\n",
      "SenatorRomney\n",
      "httpstco0CV0793olS\n",
      "Dear\n",
      "Coronavirus\n",
      "\r\n",
      "Ive\n",
      "been\n",
      "following\n",
      "social\n",
      "distancing\n",
      "rules\n",
      "and\n",
      "staying\n",
      "home\n",
      "to\n",
      "prevent\n",
      "the\n",
      "spread\n",
      "of\n",
      "you\n",
      "\n",
      "However\n",
      "now\n",
      "Ive\n",
      "spent\n",
      "an\n",
      "alarming\n",
      "amount\n",
      "of\n",
      "money\n",
      "shopping\n",
      "online\n",
      "\n",
      "Where\n",
      "can\n",
      "I\n",
      "submit\n",
      "my\n",
      "expenses\n",
      "to\n",
      "for\n",
      "reimbursement\n",
      "Let\n",
      "me\n",
      "know\r\n",
      "coronapocolypse\n",
      "coronavirus\n",
      "Global\n",
      "food\n",
      "prices\n",
      "before\n",
      "the\n",
      "spread\n",
      "of\n",
      "COVID\n",
      "19\n",
      "intensified\n",
      "across\n",
      "several\n",
      "geographies\n",
      "We\n",
      "could\n",
      "see\n",
      "further\n",
      "downward\n",
      "pressures\n",
      "in\n",
      "the\n",
      "coming\n",
      "months\n",
      "due\n",
      "to\n",
      "continued\n",
      "well\n",
      "supplied\n",
      "markets\n",
      "and\n",
      "the\n",
      "negative\n",
      "impact\n",
      "on\n",
      "demand\n",
      "resulting\n",
      "from\n",
      "the\n",
      "virus\n",
      "Morning\n",
      "everyone\n",
      "have\n",
      "a\n",
      "great\n",
      "and\n",
      "safe\n",
      "day\n",
      "\n",
      "coronavirus\n",
      "StopPanicBuying\n",
      "BeKind\n",
      "mufc\n",
      "MUFC_Family\n",
      "Of\n",
      "all\n",
      "the\n",
      "things\n",
      "to\n",
      "panic\n",
      "buy\n",
      "in\n",
      "an\n",
      "emergency\n",
      "I\n",
      "dont\n",
      "get\n",
      "why\n",
      "toilet\n",
      "paper\n",
      "is\n",
      "so\n",
      "important\n",
      "If\n",
      "youre\n",
      "afraid\n",
      "of\n",
      "the\n",
      "worst\n",
      "case\n",
      "scenario\n",
      "just\n",
      "wash\n",
      "up\n",
      "in\n",
      "the\n",
      "tub\n",
      "and\n",
      "use\n",
      "your\n",
      "money\n",
      "on\n",
      "food\n",
      "Yall\n",
      "crazy\n",
      "coronavirus\n",
      "THANK\n",
      "YOUR\n",
      "GROCERY\n",
      "CLERK\r\n",
      "Went\n",
      "to\n",
      "grocery\n",
      "store\n",
      "today\n",
      "and\n",
      "looked\n",
      "into\n",
      "the\n",
      "weary\n",
      "eyes\n",
      "of\n",
      "the\n",
      "clerk\r\n",
      "I\n",
      "thanked\n",
      "her\n",
      "and\n",
      "realized\n",
      "that\n",
      "she\n",
      "was\n",
      "thrust\n",
      "on\n",
      "the\n",
      "front\n",
      "line\n",
      "of\n",
      "this\n",
      "panick\n",
      "A\n",
      "new\n",
      "breed\n",
      "of\n",
      "first\n",
      "responders\n",
      "They\n",
      "are\n",
      "working\n",
      "hard\n",
      "to\n",
      "serve\n",
      "their\n",
      "communities\n",
      "coronavirus\n",
      "With\n",
      "the\n",
      "outbreak\n",
      "of\n",
      "Covid19\n",
      "in\n",
      "entire\n",
      "world\n",
      "the\n",
      "retail\n",
      "shops\n",
      "in\n",
      "Malaysia\n",
      "is\n",
      "facing\n",
      "a\n",
      "great\n",
      "challenges\n",
      "In\n",
      "the\n",
      "near\n",
      "future\n",
      "online\n",
      "shopping\n",
      "will\n",
      "be\n",
      "a\n",
      "surprise\n",
      "way\n",
      "for\n",
      "all\n",
      "the\n",
      "people\n",
      "while\n",
      "many\n",
      "will\n",
      "lost\n",
      "their\n",
      "jobs\n",
      "Malaysia2020\n",
      "Malaysia\n",
      "COVID19\n",
      "My\n",
      "thoughts\n",
      "on\n",
      "impacts\n",
      "of\n",
      "coronavirus\n",
      "on\n",
      "food\n",
      "markets\r\n",
      "httpstcobPodDdPRcE\n",
      "Consumer\n",
      "Corner\n",
      "Scammers\n",
      "Taking\n",
      "Advantage\n",
      "Of\n",
      "COVID19\n",
      "Fears\r\n",
      "\r\n",
      "coronavirus\n",
      "cdc\n",
      "flu\n",
      "trends\n",
      "alert\r\n",
      "\r\n",
      "httpstcosk9qCJsnYl\n",
      "httpstcoT7qejP3hys\n",
      "4\n",
      "Both\n",
      "the\n",
      "masks\n",
      "made\n",
      "for\n",
      "medical\n",
      "personnel\n",
      "and\n",
      "for\n",
      "consumer\n",
      "purchase\n",
      "require\n",
      "a\n",
      "onceobscure\n",
      "material\n",
      "called\n",
      "meltblown\n",
      "fabric\r\n",
      "\r\n",
      "httpstco3hCd9IiWoX\n",
      "My\n",
      "work\n",
      "is\n",
      "capitalizing\n",
      "on\n",
      "the\n",
      "\n",
      "demand\n",
      "for\n",
      "packaged\n",
      "food\n",
      "and\n",
      "making\n",
      "us\n",
      "stay\n",
      "open\n",
      "as\n",
      "opposed\n",
      "to\n",
      "closing\n",
      "for\n",
      "all\n",
      "our\n",
      "health\n",
      "and\n",
      "safety\n",
      "LockdownCanada\r\n",
      "coronavirus\n",
      "So\n",
      "are\n",
      "we\n",
      "feeling\n",
      "like\n",
      "its\n",
      "ethical\n",
      "to\n",
      "still\n",
      "do\n",
      "stuff\n",
      "like\n",
      "order\n",
      "deliveries\n",
      "food\n",
      "online\n",
      "shopping\n",
      "etc\n",
      "ship\n",
      "isolation\n",
      "care\n",
      "packages\n",
      "to\n",
      "loved\n",
      "ones\n",
      "etc\n",
      "COVID2019\n",
      "What\n",
      "2K\n",
      "Consumers\n",
      "Told\n",
      "PYMNTS\n",
      "About\n",
      "How\n",
      "COVID19\n",
      "Changed\n",
      "Their\n",
      "Daily\n",
      "Lives\n",
      "httpstcoYbg8Zupdf6\n",
      "via\n",
      "pymnts\n",
      "Bought\n",
      "a\n",
      "house\n",
      "during\n",
      "Covid19\n",
      "panic\n",
      "DidnÂt\n",
      "think\n",
      "to\n",
      "buy\n",
      "food\n",
      "for\n",
      "the\n",
      "house\n",
      "Tragic\n",
      "Seen\n",
      "in\n",
      "a\n",
      "Facebook\n",
      "group\n",
      "\n",
      "businesses\n",
      "need\n",
      "to\n",
      "stop\n",
      "increasing\n",
      "prices\n",
      "on\n",
      "essentials\n",
      "while\n",
      "we\n",
      "are\n",
      "in\n",
      "an\n",
      "emergency\n",
      "situation\n",
      "\n",
      "itÂs\n",
      "frankly\n",
      "despicable\n",
      "and\n",
      "is\n",
      "totally\n",
      "void\n",
      "community\n",
      "spirit\n",
      "nameandshame\n",
      "covid19uk\n",
      "coronavirus\n",
      "Liverpool\n",
      "httpstcoStTAkyqQiZ\n",
      "BobJLowe\n",
      "Sadly\n",
      "those\n",
      "are\n",
      "the\n",
      "misinformed\n",
      "thinking\n",
      "that\n",
      "COVID19\n",
      "gives\n",
      "diarrhoea\n",
      "therefore\n",
      "they\n",
      "had\n",
      "to\n",
      "stockpile\n",
      "toilet\n",
      "papers\n",
      "\n",
      "ATM\n",
      "hygiene\n",
      "and\n",
      "food\n",
      "are\n",
      "more\n",
      "important\n",
      "TinaMcCauley70\n",
      "Yeah\n",
      "my\n",
      "parents\n",
      "are\n",
      "risky\n",
      "people\n",
      "to\n",
      "the\n",
      "covid\n",
      "19\n",
      "thatÂs\n",
      "why\n",
      "we\n",
      "stay\n",
      "at\n",
      "home\n",
      "just\n",
      "go\n",
      "to\n",
      "the\n",
      "supermarket\n",
      "when\n",
      "really\n",
      "necessary\n",
      "stay\n",
      "safe\n",
      "too\n",
      "\n",
      "CN\n",
      "\n",
      "Coronavirus\n",
      "COVID19\n",
      "\r\n",
      "\r\n",
      "I\n",
      "will\n",
      "be\n",
      "in\n",
      "the\n",
      "group\n",
      "and\n",
      "so\n",
      "will\n",
      "my\n",
      "Mum\n",
      "who\n",
      "I\n",
      "live\n",
      "with\n",
      "in\n",
      "the\n",
      "group\n",
      "that\n",
      "needs\n",
      "to\n",
      "be\n",
      "shielded\n",
      "for\n",
      "12\n",
      "weeks\n",
      "3\n",
      "months\n",
      "This\n",
      "will\n",
      "mean\n",
      "staying\n",
      "in\n",
      "I\n",
      "hope\n",
      "I\n",
      "can\n",
      "still\n",
      "get\n",
      "the\n",
      "online\n",
      "shopping\n",
      "that\n",
      "I\n",
      "need\n",
      "ItÂs\n",
      "kind\n",
      "of\n",
      "like\n",
      "how\n",
      "saying\n",
      "a\n",
      "word\n",
      "over\n",
      "and\n",
      "over\n",
      "makes\n",
      "it\n",
      "not\n",
      "sound\n",
      "like\n",
      "a\n",
      "word\n",
      "anymore\r\n",
      "\r\n",
      "For\n",
      "many\n",
      "of\n",
      "the\n",
      "people\n",
      "who\n",
      "donÂt\n",
      "think\n",
      "the\n",
      "COVID19\n",
      "news\n",
      "is\n",
      "BS\n",
      "itÂs\n",
      "making\n",
      "them\n",
      "go\n",
      "to\n",
      "the\n",
      "stores\n",
      "and\n",
      "panic\n",
      "buy\n",
      "food\n",
      "and\n",
      "basic\n",
      "necessities\n",
      "until\n",
      "thereÂs\n",
      "nothing\n",
      "left\n",
      "Hi\n",
      "COVID19\n",
      "Thanks\n",
      "for\n",
      "making\n",
      "me\n",
      "do\n",
      "more\n",
      "online\n",
      "shopping\n",
      "Corona\n",
      "scare\n",
      "sends\n",
      "seafood\n",
      "prices\n",
      "skyrocketing\n",
      "in\n",
      "Mumbai\r\n",
      "\r\n",
      "gt;gt;\n",
      "httpstcoGB11EFBYIB\n",
      "\r\n",
      "\r\n",
      "seafood\n",
      "coronavirus\n",
      "CoronavirusOutbreak\n",
      "CoronavirusReachesDelhi\n",
      "Coronavid19\n",
      "CoronaVirusUpdates\n",
      "COVID2019\n",
      "COVID19\n",
      "JhalakBollywood\n",
      "JhalakKollywood\n",
      "JhalakTollywood\n",
      "httpstcoU5Dg3LoFYG\n",
      "Pausing\n",
      "student\n",
      "loan\n",
      "payments\n",
      "in\n",
      "addition\n",
      "to\n",
      "halting\n",
      "interest\n",
      "accumulation\n",
      "amp\n",
      "stopping\n",
      "punitive\n",
      "student\n",
      "loan\n",
      "collections\n",
      "would\n",
      "provide\n",
      "much\n",
      "needed\n",
      "immediate\n",
      "relief\n",
      "to\n",
      "those\n",
      "individuals\n",
      "unable\n",
      "to\n",
      "work\n",
      "amp\n",
      "are\n",
      "facing\n",
      "economic\n",
      "hardship\n",
      "balajis\n",
      "On\n",
      "the\n",
      "consumer\n",
      "side\n",
      "\n",
      "the\n",
      "tech\n",
      "is\n",
      "there\n",
      "some\n",
      "Chinese\n",
      "group\n",
      "already\n",
      "demostrated\n",
      "ELISA\n",
      "test\n",
      "strips\n",
      "for\n",
      "COVID19\n",
      "though\n",
      "details\n",
      "were\n",
      "lacking\n",
      "For\n",
      "consumer\n",
      "though\n",
      "US_FDA\n",
      "would\n",
      "have\n",
      "to\n",
      "deem\n",
      "it\n",
      "as\n",
      "a\n",
      "waived\n",
      "test\n",
      "which\n",
      "doesnÂt\n",
      "come\n",
      "that\n",
      "easily\n",
      "Lost\n",
      "wages\n",
      "either\n",
      "due\n",
      "to\n",
      "illness\n",
      "from\n",
      "19\n",
      "or\n",
      "to\n",
      "the\n",
      "virus\n",
      "\n",
      "economic\n",
      "impact\n",
      "will\n",
      "mean\n",
      "an\n",
      "increased\n",
      "demand\n",
      "We\n",
      "urge\n",
      "and\n",
      "to\n",
      "support\n",
      "a\n",
      "bill\n",
      "that\n",
      "includes\n",
      "support\n",
      "for\n",
      "food\n",
      "banks\n",
      "flexibility\n",
      "for\n",
      "and\n",
      "school\n",
      "meals\n",
      "and\n",
      "increased\n",
      "The\n",
      "actions\n",
      "of\n",
      "some\n",
      "are\n",
      "so\n",
      "selfish\n",
      "If\n",
      "I\n",
      "were\n",
      "CEO\n",
      "of\n",
      "a\n",
      "grocery\n",
      "store\n",
      "from\n",
      "79\n",
      "am\n",
      "would\n",
      "be\n",
      "a\n",
      "time\n",
      "for\n",
      "people\n",
      "over\n",
      "65\n",
      "to\n",
      "shop;\n",
      "show\n",
      "ID\n",
      "I\n",
      "just\n",
      "saw\n",
      "a\n",
      "young\n",
      "couple\n",
      "with\n",
      "300\n",
      "rolls\n",
      "of\n",
      "tp\n",
      "No\n",
      "one\n",
      "is\n",
      "that\n",
      "full\n",
      "of\n",
      "crap\n",
      "Well\n",
      "maybe\r\n",
      "\r\n",
      "CoronavirusOutbreak\n",
      "\r\n",
      "\r\n",
      "\n",
      "httpstcoHrbzmh95VQ\n",
      "Coronavirus\n",
      "poses\n",
      "a\n",
      "complex\n",
      "puzzle\n",
      "for\n",
      "fooddelivery\n",
      "companies\n",
      "\n",
      "their\n",
      "delivery\n",
      "capacity\n",
      "may\n",
      "buckle\n",
      "under\n",
      "surging\n",
      "demand\n",
      "httpstco1C1cMLmQii\n",
      "via\n",
      "WSJ\n",
      "services\n",
      "food\n",
      "delivery\n",
      "coronavirus\n",
      "TheJoshuaTurner\n",
      "Loreign83\n",
      "peanut_astro\n",
      "my_amigouk\n",
      "afneil\n",
      "BorisJohnson\n",
      "patel4witham\n",
      "This\n",
      "is\n",
      "both\n",
      "disgusting\n",
      "and\n",
      "disgraceful\n",
      "charging\n",
      "over\n",
      "inflated\n",
      "prices\n",
      "for\n",
      "items\n",
      "for\n",
      "stopping\n",
      "the\n",
      "spread\n",
      "of\n",
      "COVID19\n",
      "the\n",
      "government\n",
      "really\n",
      "needs\n",
      "to\n",
      "do\n",
      "something\n",
      "abou\n",
      "As\n",
      "more\n",
      "retailers\n",
      "close\n",
      "physical\n",
      "stores\n",
      "or\n",
      "curtail\n",
      "hours\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "Covid19\n",
      "it\n",
      "is\n",
      "agoing\n",
      "to\n",
      "put\n",
      "additional\n",
      "pressure\n",
      "on\n",
      "other\n",
      "omnichannel\n",
      "alternatives\n",
      "like\n",
      "grocery\n",
      "delivery\n",
      "and\n",
      "curbside\n",
      "pick\n",
      "up\n",
      "\n",
      "httpstcokgyDow3Nrz\n",
      "covid19\n",
      "ecommerce\n",
      "omnichannel\n",
      "retail\n",
      "digital\n",
      "Check\n",
      "out\n",
      "what\n",
      "these\n",
      "folks\n",
      "are\n",
      "up\n",
      "to\n",
      "here\n",
      "in\n",
      "So\n",
      "Cal\n",
      "\n",
      "I\n",
      "like\n",
      "this\n",
      "idea\n",
      "\r\n",
      "\r\n",
      "La\n",
      "Habra\n",
      "supermarket\n",
      "offers\n",
      "special\n",
      "hours\n",
      "for\n",
      "seniors\n",
      "amid\n",
      "COVID19\n",
      "crisis\n",
      "httpstconcTXF8TGyf\n",
      "Love\n",
      "it\n",
      "or\n",
      "hate\n",
      "it\n",
      "head\n",
      "advice\n",
      "10DowningStreet\n",
      "amp;\n",
      "BorisJohnson\n",
      "\r\n",
      "Blip\n",
      "in\n",
      "our\n",
      "lives\n",
      "but\n",
      "itÂs\n",
      "happening\r\n",
      "\n",
      "DonÂt\n",
      "whinge\n",
      "about\n",
      "what\n",
      "you\n",
      "canÂt\n",
      "do\n",
      "\r\n",
      "\n",
      "Dont\n",
      "panic\n",
      "buy\n",
      "as\n",
      "food\n",
      "wont\n",
      "run\n",
      "out\r\n",
      "\n",
      "DO\n",
      "spend\n",
      "time\n",
      "with\n",
      "the\n",
      "family\r\n",
      "\n",
      "DO\n",
      "use\n",
      "common\n",
      "sense\r\n",
      "coronavirus\n",
      "WorldHealthOrg2\n",
      "An\n",
      "open\n",
      "letter\n",
      "to\n",
      "consumerdebt\n",
      "holding\n",
      "organizations\n",
      "and\n",
      "others\n",
      "We\n",
      "are\n",
      "at\n",
      "the\n",
      "precipice\n",
      "of\n",
      "a\n",
      "crisis\n",
      "of\n",
      "household\n",
      "economy\n",
      "Please\n",
      "suspend\n",
      "debts\n",
      "and\n",
      "interestfees\n",
      "for\n",
      "sixty\n",
      "days\n",
      "in\n",
      "response\n",
      "to\n",
      "the\n",
      "COVID19\n",
      "crisis\r\n",
      "\r\n",
      "Feel\n",
      "free\n",
      "to\n",
      "sign\n",
      "here\r\n",
      "\r\n",
      "httpstcoJMZZJOmNT9\n",
      "httpstcoYR2tcPx1Ee\n",
      "COVID19\n",
      "COVID19Aus\n",
      "coronavirus\n",
      "Just\n",
      "wanted\n",
      "to\n",
      "spread\n",
      "this\n",
      "news\n",
      "to\n",
      "all\n",
      "older\n",
      "Australians\n",
      "particularly\n",
      "those\n",
      "still\n",
      "mobile\n",
      "but\n",
      "without\n",
      "family\n",
      "support\n",
      "httpstcoyDGX4lK8L0\n",
      "Sadly\n",
      "this\n",
      "does\n",
      "not\n",
      "surprise\n",
      "me\r\n",
      "Heard\n",
      "from\n",
      "one\n",
      "payer\n",
      "exec\n",
      "that\n",
      "they\n",
      "are\n",
      "laying\n",
      "low\n",
      "hoping\n",
      "all\n",
      "blows\n",
      "over\n",
      "\r\n",
      "\r\n",
      "Mind\n",
      "bogglingly\n",
      "stupid\n",
      "and\n",
      "this\n",
      "was\n",
      "a\n",
      "nonprofit\n",
      "Blues\n",
      "plan\n",
      "httpstcozr67d1u12Q\n",
      "I\n",
      "work\n",
      "in\n",
      "retail\n",
      "I\n",
      "keep\n",
      "stock\n",
      "back\n",
      "for\n",
      "our\n",
      "older\n",
      "customers\n",
      "so\n",
      "when\n",
      "such\n",
      "as\n",
      "frank\n",
      "comes\n",
      "in\n",
      "store\n",
      "for\n",
      "his\n",
      "bread\n",
      "and\n",
      "he\n",
      "sees\n",
      "a\n",
      "empty\n",
      "shelve\n",
      "I\n",
      "say\n",
      "donÂt\n",
      "worry\n",
      "pal\n",
      "IÂve\n",
      "saved\n",
      "you\n",
      "1\n",
      "Same\n",
      "as\n",
      "pat\n",
      "n\n",
      "her\n",
      "beans\n",
      "Could\n",
      "I\n",
      "get\n",
      "disciplined\n",
      "Yes\n",
      "do\n",
      "I\n",
      "care\n",
      "\n",
      "No\n",
      "IÂve\n",
      "got\n",
      "a\n",
      "\n",
      "coronavirus\n",
      "In\n",
      "attempts\n",
      "to\n",
      "lengthen\n",
      "runways\n",
      "marketing\n",
      "budgets\n",
      "are\n",
      "being\n",
      "slashed\n",
      "hiring\n",
      "is\n",
      "being\n",
      "frozen\n",
      "and\n",
      "staffing\n",
      "matrices\n",
      "are\n",
      "being\n",
      "redrawn\n",
      "and\n",
      "dive\n",
      "deep\n",
      "into\n",
      "how\n",
      "consumer\n",
      "startups\n",
      "are\n",
      "battling\n",
      "the\n",
      "impact\n",
      "of\n",
      "on\n",
      "their\n",
      "business\n",
      "Âat\n",
      "this\n",
      "time\n",
      "our\n",
      "distillery\n",
      "remains\n",
      "in\n",
      "operation\n",
      "but\n",
      "we\n",
      "will\n",
      "not\n",
      "be\n",
      "offering\n",
      "public\n",
      "tours\n",
      "or\n",
      "hosting\n",
      "functions\n",
      "or\n",
      "events\n",
      "Our\n",
      "retail\n",
      "store\n",
      "is\n",
      "also\n",
      "closed\r\n",
      "httpstcolYZg2kfsm0\n",
      "Please\n",
      "dont\n",
      "hoard\n",
      "food\n",
      "and\n",
      "water\n",
      "Theres\n",
      "absolutely\n",
      "no\n",
      "need\n",
      "to\n",
      "panic\n",
      "buy;\n",
      "the\n",
      "supply\n",
      "chain\n",
      "is\n",
      "completely\n",
      "interrupted\n",
      "And\n",
      "above\n",
      "all\n",
      "please\n",
      "dont\n",
      "hoard\n",
      "sanitizing\n",
      "products;\n",
      "there\n",
      "are\n",
      "people\n",
      "out\n",
      "there\n",
      "who\n",
      "really\n",
      "need\n",
      "them\n",
      "probably\n",
      "more\n",
      "than\n",
      "you\n",
      "DontPanicBuy\n",
      "coronavirus\n",
      "The\n",
      "fact\n",
      "that\n",
      "canned\n",
      "food\n",
      "toxic\n",
      "chemicals\n",
      "and\n",
      "store\n",
      "bought\n",
      "hand\n",
      "sanitizers\n",
      "are\n",
      "out\n",
      "of\n",
      "stock\n",
      "yet\n",
      "fresh\n",
      "fruit\n",
      "vegetables\n",
      "and\n",
      "herbs\n",
      "are\n",
      "FULLY\n",
      "stocked\n",
      "shows\n",
      "that\n",
      "humans\n",
      "have\n",
      "no\n",
      "idea\n",
      "how\n",
      "the\n",
      "immune\n",
      "system\n",
      "works\r\n",
      "QuarantineLife\n",
      "COVID2019\n",
      "Just\n",
      "called\n",
      "mum\n",
      "and\n",
      "dad\n",
      "in\n",
      "UK\n",
      "over\n",
      "70\n",
      "They\n",
      "are\n",
      "great\n",
      "but\n",
      "I\n",
      "offered\n",
      "help\n",
      "with\n",
      "online\n",
      "shopping\n",
      "etc\n",
      "We\n",
      "might\n",
      "sometimes\n",
      "forget\n",
      "that\n",
      "this\n",
      "is\n",
      "not\n",
      "always\n",
      "easy\r\n",
      "\r\n",
      "Do\n",
      "the\n",
      "same\n",
      "if\n",
      "you\n",
      "can\n",
      "\r\n",
      "If\n",
      "you\n",
      "are\n",
      "far\n",
      "from\n",
      "your\n",
      "parents\n",
      "like\n",
      "me\n",
      "Tech\n",
      "can\n",
      "be\n",
      "really\n",
      "useful\n",
      "COVID19\n",
      "\n",
      "Coronavirus\n",
      "People\n",
      "seen\n",
      "stocking\n",
      "up\n",
      "on\n",
      "goods\n",
      "into\n",
      "trolleys\n",
      "after\n",
      "the\n",
      "panic\n",
      "buying\n",
      "rumours\n",
      "spread\n",
      "today\n",
      "at\n",
      "hypermarket\n",
      "in\n",
      "Kajang\n",
      "March\n",
      "16\n",
      "2020\n",
      "Picture\n",
      "by\n",
      "Shafwan\n",
      "Zaidon\n",
      "As\n",
      "we\n",
      "often\n",
      "see\n",
      "during\n",
      "major\n",
      "news\n",
      "events\n",
      "criminals\n",
      "will\n",
      "try\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "any\n",
      "situation\n",
      "The\n",
      "Coronavirus\n",
      "or\n",
      "COVID19\n",
      "is\n",
      "no\n",
      "exception\n",
      "Here\n",
      "is\n",
      "some\n",
      "guidance\n",
      "from\n",
      "the\n",
      "Attorney\n",
      "Generals\n",
      "office\n",
      "httpstcoKT5J4QqCwS\n",
      "Pretty\n",
      "sure\n",
      "within\n",
      "a\n",
      "week\n",
      "or\n",
      "two\n",
      "supermarket\n",
      "supply\n",
      "chains\n",
      "will\n",
      "dry\n",
      "up\n",
      "as\n",
      "more\n",
      "counties\n",
      "are\n",
      "effected\n",
      "by\n",
      "Covid19\n",
      "and\n",
      "possibly\n",
      "go\n",
      "into\n",
      "lockdown\n",
      "If\n",
      "so\n",
      "would\n",
      "the\n",
      "government\n",
      "introduce\n",
      "a\n",
      "form\n",
      "of\n",
      "rationing\n",
      "so\n",
      "that\n",
      "people\n",
      "can\n",
      "eat\n",
      "Somehow\n",
      "I\n",
      "dont\n",
      "think\n",
      "so\n",
      "Supermarket\n",
      "workers\n",
      "are\n",
      "at\n",
      "the\n",
      "frontline\n",
      "of\n",
      "COVID19\r\n",
      "\r\n",
      "These\n",
      "are\n",
      "extraordinary\n",
      "times\n",
      "and\n",
      "retail\n",
      "is\n",
      "under\n",
      "extreme\n",
      "pressure\r\n",
      "\r\n",
      "When\n",
      "shopping\n",
      "please\n",
      "remain\n",
      "calm\n",
      "and\n",
      "thank\n",
      "the\n",
      "workers\n",
      "that\n",
      "are\n",
      "doing\n",
      "everything\n",
      "they\n",
      "can\n",
      "to\n",
      "keep\n",
      "the\n",
      "shelves\n",
      "stocked\n",
      "and\n",
      "the\n",
      "checkouts\n",
      "moving\n",
      "httpstco0uHGM8gsp8\n",
      "Worried\n",
      "about\n",
      "COVID19\n",
      "\r\n",
      "\r\n",
      "I\n",
      "more\n",
      "worried\n",
      "about\n",
      "people\n",
      "panicking\r\n",
      "\r\n",
      "Having\n",
      "a\n",
      "plan\r\n",
      "\r\n",
      "gt;\n",
      "Youre\n",
      "not\n",
      "panic\n",
      "buying\n",
      "food\r\n",
      "gt;\n",
      "You\n",
      "can\n",
      "focus\n",
      "on\n",
      "the\n",
      "important\n",
      "issues\n",
      "\r\n",
      "gt;\n",
      "You\n",
      "have\n",
      "the\n",
      "best\n",
      "opportunity\n",
      "for\n",
      "a\n",
      "positive\n",
      "outcome\r\n",
      "\r\n",
      "Create\n",
      "structure\n",
      "reduce\n",
      "key\n",
      "decisions\n",
      "Flourish\r\n",
      "\r\n",
      "Stay\n",
      "safe\n",
      "kroger\n",
      "is\n",
      "the\n",
      "biggest\n",
      "supermarket\n",
      "chain\n",
      "in\n",
      "the\n",
      "United\n",
      "States\r\n",
      "\r\n",
      "It\n",
      "has\n",
      "453000\n",
      "employees\n",
      "and\n",
      "many\n",
      "receive\n",
      "no\n",
      "sick\n",
      "leave\r\n",
      "\r\n",
      "Even\n",
      "after\n",
      "2\n",
      "employees\n",
      "tested\n",
      "positive\n",
      "for\n",
      "COVID19\n",
      "kroger\n",
      "still\n",
      "wont\n",
      "provide\n",
      "paid\n",
      "sick\n",
      "leave\n",
      "to\n",
      "everyone\r\n",
      "\r\n",
      "httpstco19uNybttHl\n",
      "kroger\n",
      "Instead\n",
      "of\n",
      "paid\n",
      "sick\n",
      "leave\n",
      "kroger\n",
      "is\n",
      "providing\n",
      "2\n",
      "weeks\n",
      "paid\n",
      "leave\n",
      "ONLY\n",
      "to\n",
      "people\n",
      "who\n",
      "test\n",
      "positive\n",
      "for\n",
      "COVID19\n",
      "or\n",
      "are\n",
      "placed\n",
      "under\n",
      "mandatory\n",
      "quarantine\r\n",
      "\r\n",
      "This\n",
      "is\n",
      "insufficient\n",
      "to\n",
      "protect\n",
      "staff\n",
      "and\n",
      "the\n",
      "public\n",
      "especially\n",
      "with\n",
      "little\n",
      "testing\n",
      "av\n",
      "I\n",
      "followed\n",
      "this\n",
      "when\n",
      "I\n",
      "went\n",
      "shopping\n",
      "a\n",
      "few\n",
      "days\n",
      "ago\n",
      "Its\n",
      "a\n",
      "pain\n",
      "but\n",
      "necessary\n",
      "Protect\n",
      "Yourself\n",
      "From\n",
      "Grocery\n",
      "Shopping\n",
      "\n",
      "Consumer\n",
      "Reports\n",
      "COVID2019\n",
      "StayHealthy\n",
      "httpstco48nG14me6E\n",
      "joncoopertweets\n",
      "I\n",
      "took\n",
      "these\n",
      "pictures\n",
      "today\n",
      "at\n",
      "my\n",
      "home\n",
      "grocery\n",
      "store\n",
      "in\n",
      "Montgomery\n",
      "County\n",
      "MD\n",
      "No\n",
      "flour\n",
      "sugar\n",
      "sweet\n",
      "potatoes\n",
      "potatoes\n",
      "orange\n",
      "juice\n",
      "paper\n",
      "towels\n",
      "or\n",
      "toilet\n",
      "paper\n",
      "Low\n",
      "on\n",
      "meat\n",
      "mac\n",
      "amp;\n",
      "cheese\n",
      "coronapocolypse\n",
      "Covid_19\n",
      "panicbuying\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjdal\\AppData\\Local\\Temp/ipykernel_17924/90718866.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['OriginalTweet'][i] = temp\n"
     ]
    }
   ],
   "source": [
    "# word encoding\n",
    "\n",
    "for i in range(len(data['OriginalTweet'][:100])):\n",
    "    temp = []\n",
    "    for word in data['OriginalTweet'][i].split(' '):\n",
    "        print(word)\n",
    "        if word in word_to_index:\n",
    "            temp.append(word_to_index[word])\n",
    "        else:\n",
    "            temp.append(word_to_index['OOV'])\n",
    "    data['OriginalTweet'][i] = temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "       UserName  ScreenName                      Location     TweetAt  \\\n0          3799       48751                        London  16-03-2020   \n1          3800       48752                            UK  16-03-2020   \n2          3801       48753                     Vagabonds  16-03-2020   \n3          3802       48754                           NaN  16-03-2020   \n4          3803       48755                           NaN  16-03-2020   \n...         ...         ...                           ...         ...   \n41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n41153     44952       89904                           NaN  14-04-2020   \n41154     44953       89905                           NaN  14-04-2020   \n41155     44954       89906                           NaN  14-04-2020   \n41156     44955       89907  i love you so much || he/him  14-04-2020   \n\n                                           OriginalTweet  Sentiment  \n0                   [418, 419, 420, 421, 2, 422, 2, 423]          3  \n1      [208, 424, 1, 47, 209, 138, 1, 425, 139, 210, ...          4  \n2      [42, 437, 438, 1, 439, 214, 440, 441, 15, 102,...          4  \n3      [141, 11, 54, 8, 34, 0, 216, 104, 217, 8, 1417...          4  \n4      [224, 453, 1, 62, 27, 37, 71, 0, 6, 1417, 88, ...          0  \n...                                                  ...        ...  \n41152  Airline pilots offering to stock supermarket s...          3  \n41153  Response to complaint not provided citing COVI...          0  \n41154  You know itÂs getting tough when KameronWilds...          4  \n41155  Is it wrong that the smell of hand sanitizer i...          3  \n41156  TartiiCat Well newused Rift S are going for 70...          2  \n\n[41157 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>[418, 419, 420, 421, 2, 422, 2, 423]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>[208, 424, 1, 47, 209, 138, 1, 425, 139, 210, ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>[42, 437, 438, 1, 439, 214, 440, 441, 15, 102,...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>[141, 11, 54, 8, 34, 0, 216, 104, 217, 8, 1417...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>[224, 453, 1, 62, 27, 37, 71, 0, 6, 1417, 88, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41152</th>\n      <td>44951</td>\n      <td>89903</td>\n      <td>Wellington City, New Zealand</td>\n      <td>14-04-2020</td>\n      <td>Airline pilots offering to stock supermarket s...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>41153</th>\n      <td>44952</td>\n      <td>89904</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>Response to complaint not provided citing COVI...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41154</th>\n      <td>44953</td>\n      <td>89905</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>You know itÂs getting tough when KameronWilds...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>41155</th>\n      <td>44954</td>\n      <td>89906</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>Is it wrong that the smell of hand sanitizer i...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>41156</th>\n      <td>44955</td>\n      <td>89907</td>\n      <td>i love you so much || he/him</td>\n      <td>14-04-2020</td>\n      <td>TartiiCat Well newused Rift S are going for 70...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>41157 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample =data[['OriginalTweet','Sentiment']][:100]\n",
    "\n",
    "\n",
    "\n",
    "sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "train_text,val_text,train_label,val_label=train_test_split(sample.OriginalTweet,sample.Sentiment,\n",
    "                                                             test_size=0.3,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1442: FutureWarning: Dropping invalid columns in DataFrameGroupBy.max is deprecated. In a future version, a TypeError will be raised. Before calling .max, select only columns which should be valid for the function.\n",
      "  result = getattr(self, func)(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17924/471414147.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;31m# tensorflow pycharm 다시시작하고 실행하니 설치완료 다른 폴더가 켜져있었거나의 원인이 있었는듯\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m \u001B[0msample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'OriginalTweet'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001B[0m in \u001B[0;36mtransform\u001B[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1355\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mAppender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_transform_template\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1356\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine_kwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1357\u001B[1;33m         return self._transform(\n\u001B[0m\u001B[0;32m   1358\u001B[0m             \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine_kwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mengine_kwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1359\u001B[0m         )\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001B[0m in \u001B[0;36m_transform\u001B[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1440\u001B[0m             \u001B[1;31m# Temporarily set observed for dealing with categoricals.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1441\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtemp_setattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"observed\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1442\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1443\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1444\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_use_transform_fast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001B[0m in \u001B[0;36mmax\u001B[1;34m(self, numeric_only, min_count)\u001B[0m\n\u001B[0;32m   1855\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mdoc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_groupby_agg_method_template\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"max\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mno\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmc\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1856\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumeric_only\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_count\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1857\u001B[1;33m         return self._agg_general(\n\u001B[0m\u001B[0;32m   1858\u001B[0m             \u001B[0mnumeric_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnumeric_only\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_count\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmin_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"max\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnpfunc\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1859\u001B[0m         )\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001B[0m in \u001B[0;36m_agg_general\u001B[1;34m(self, numeric_only, min_count, alias, npfunc)\u001B[0m\n\u001B[0;32m   1340\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mgroup_selection_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1341\u001B[0m             \u001B[1;31m# try a cython aggregation if we can\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1342\u001B[1;33m             result = self._cython_agg_general(\n\u001B[0m\u001B[0;32m   1343\u001B[0m                 \u001B[0mhow\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0malias\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1344\u001B[0m                 \u001B[0malt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnpfunc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001B[0m in \u001B[0;36m_cython_agg_general\u001B[1;34m(self, how, alt, numeric_only, min_count)\u001B[0m\n\u001B[0;32m   1092\u001B[0m             )\n\u001B[0;32m   1093\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1094\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_wrap_agged_manager\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_mgr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1095\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1096\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_aggregate_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001B[0m in \u001B[0;36m_wrap_agged_manager\u001B[1;34m(self, mgr)\u001B[0m\n\u001B[0;32m   1686\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_consolidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1687\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1688\u001B[1;33m             \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrouper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult_index\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1689\u001B[0m             \u001B[0mmgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1690\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmgr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001B[0m in \u001B[0;36mresult_index\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    930\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mresult_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mIndex\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    931\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroupings\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 932\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroupings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult_index\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnames\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    933\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m         \u001B[0mcodes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreconstructed_codes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001B[0m in \u001B[0;36mresult_index\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m             \u001B[1;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgroup_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCategoricalIndex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    628\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mrecode_from_groupby\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_all_grouper\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sort\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup_idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 629\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup_index\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    630\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    631\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mcache_readonly\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001B[0m in \u001B[0;36mgroup_index\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    634\u001B[0m             \u001B[1;31m# _group_index is set in __init__ for MultiIndex cases\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    635\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_group_index\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 636\u001B[1;33m         \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup_arraylike\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    637\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mIndex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001B[0m in \u001B[0;36mgroup_arraylike\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    618\u001B[0m         \u001B[0mwe\u001B[0m \u001B[0mcan\u001B[0m \u001B[0mcan\u001B[0m \u001B[0mretain\u001B[0m \u001B[0mExtensionDtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    619\u001B[0m         \"\"\"\n\u001B[1;32m--> 620\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_codes_and_uniques\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    621\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    622\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mcache_readonly\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001B[0m in \u001B[0;36m_codes_and_uniques\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    668\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    669\u001B[0m                 \u001B[0mna_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 670\u001B[1;33m             codes, uniques = algorithms.factorize(\n\u001B[0m\u001B[0;32m    671\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrouping_vector\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msort\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sort\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mna_sentinel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mna_sentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    672\u001B[0m             )\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\algorithms.py\u001B[0m in \u001B[0;36mfactorize\u001B[1;34m(values, sort, na_sentinel, size_hint)\u001B[0m\n\u001B[0;32m    758\u001B[0m             \u001B[0mna_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    759\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 760\u001B[1;33m         codes, uniques = factorize_array(\n\u001B[0m\u001B[0;32m    761\u001B[0m             \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mna_sentinel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mna_sentinel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize_hint\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msize_hint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mna_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mna_value\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    762\u001B[0m         )\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\core\\algorithms.py\u001B[0m in \u001B[0;36mfactorize_array\u001B[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001B[0m\n\u001B[0;32m    560\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    561\u001B[0m     \u001B[0mtable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhash_klass\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_hint\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 562\u001B[1;33m     uniques, codes = table.factorize(\n\u001B[0m\u001B[0;32m    563\u001B[0m         \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mna_sentinel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mna_sentinel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mna_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mna_value\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    564\u001B[0m     )\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# lemma 추출 정수 인코딩 하지 않았을 때 사용\n",
    "\n",
    "\"\"\"\n",
    "class Lemmatizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, sentence):\n",
    "        sentence=re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)',' ',sentence)\n",
    "        sentence=re.sub('[^0-9a-z]',' ',sentence)\n",
    "        return [self.lemmatizer.lemmatize(word) for word in sentence.split() if len(word)>1]\n",
    "\n",
    "tokenizer=CountVectorizer(max_features=5000,stop_words='english',lowercase=True,tokenizer=Lemmatizer())\n",
    "\n",
    "\n",
    "train_x=tokenizer.fit_transform(train_text).toarray()\n",
    "\n",
    "tokenizer.get_params()\n",
    "feature_names=tokenizer.get_feature_names()\n",
    "val_x=tokenizer.transform(val_text).toarray()\n",
    "test_x=test.OriginalTweet\n",
    "test_label=label_encoder.transform(test['Sentiment'])\n",
    "test_x_1=tokenizer.transform(test_x).toarray()\n",
    "\n",
    "\"\"\"\n",
    "#%\n",
    "# tensorflow 필요한듯 소스 보면\n",
    "# keras가 이제 tf로 이어져있다\n",
    "# tensorflow pycharm 다시시작하고 실행하니 설치완료 다른 폴더가 켜져있었거나의 원인이 있었는듯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "60"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['max_len'] = sample['OriginalTweet'].apply(lambda x: len(x))\n",
    "\n",
    "max(sample['max_len'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Embedding,Dense,LSTM ,GlobalMaxPool1D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "{'the': 0,\n 'to': 1,\n 'and': 2,\n 'of': 3,\n 'a': 4,\n 'in': 5,\n 'COVID19': 6,\n 'for': 7,\n 'is': 8,\n 'I': 9,\n 'coronavirus': 10,\n 'food': 11,\n 'on': 12,\n 'are': 13,\n 'you': 14,\n 'shopping': 15,\n 'store': 16,\n 'this': 17,\n 'people': 18,\n 'will': 19,\n 'be': 20,\n 'with': 21,\n 'or': 22,\n ';': 23,\n 'that': 24,\n 'online': 25,\n 'panic': 26,\n 'at': 27,\n 'our': 28,\n 'as': 29,\n 'more': 30,\n 'we': 31,\n 'have': 32,\n 'but': 33,\n 'not': 34,\n 'up': 35,\n 'do': 36,\n 'supermarket': 37,\n 'The': 38,\n 'out': 39,\n 'retail': 40,\n 'can': 41,\n 'Coronavirus': 42,\n 'so': 43,\n 'We': 44,\n 'all': 45,\n 'COVID2019': 46,\n 'your': 47,\n 'need': 48,\n 'grocery': 49,\n 'buy': 50,\n 'from': 51,\n 'their': 52,\n 'who': 53,\n 'stock': 54,\n 'demand': 55,\n 'being': 56,\n 'due': 57,\n 'CoronavirusOutbreak': 58,\n 'like': 59,\n 'over': 60,\n 'dont': 61,\n 'go': 62,\n 'my': 63,\n 'about': 64,\n 'spread': 65,\n '19': 66,\n 'Covid19': 67,\n 'has': 68,\n 'consumer': 69,\n 'safe': 70,\n 'during': 71,\n 'toilet': 72,\n 'paper': 73,\n 'what': 74,\n 'home': 75,\n 'time': 76,\n 'been': 77,\n 'they': 78,\n 'impact': 79,\n 'those': 80,\n 'buying': 81,\n 'here': 82,\n 'no': 83,\n 'get': 84,\n 'if': 85,\n 'empty': 86,\n 'stay': 87,\n 'because': 88,\n 'open': 89,\n 'help': 90,\n 'just': 91,\n 'Consumer': 92,\n 'pandemic': 93,\n 'This': 94,\n 'No': 95,\n 'into': 96,\n 'amp': 97,\n 'think': 98,\n 'an': 99,\n 'it': 100,\n 'gt': 101,\n 'hours': 102,\n 'outbreak': 103,\n 'one': 104,\n 'Stay': 105,\n 'please': 106,\n 'news': 107,\n 'stores': 108,\n 'was': 109,\n 'today': 110,\n 'For': 111,\n 'should': 112,\n 'use': 113,\n 'there': 114,\n 'everyone': 115,\n 'these': 116,\n 'Just': 117,\n 'months': 118,\n 'positive': 119,\n 'virus': 120,\n 'how': 121,\n 'see': 122,\n 'could': 123,\n 'They': 124,\n 'etc': 125,\n 'some': 126,\n 'sick': 127,\n 'work': 128,\n 'me': 129,\n 'prices': 130,\n 'If': 131,\n 'still': 132,\n 'group': 133,\n 'really': 134,\n 'would': 135,\n 'kroger': 136,\n 'leave': 137,\n 'family': 138,\n 'phone': 139,\n 'supplies': 140,\n 'My': 141,\n 'FOR': 142,\n 'Im': 143,\n 'It': 144,\n 'As': 145,\n 'case': 146,\n 'purchase': 147,\n 'other': 148,\n 'goods': 149,\n 'his': 150,\n 'Covid_19': 151,\n 'weeks': 152,\n 'March': 153,\n 'orders': 154,\n 'All': 155,\n 'now': 156,\n 'situation': 157,\n 'increased': 158,\n 'products': 159,\n 'may': 160,\n 'community': 161,\n 'after': 162,\n 'healthy': 163,\n 'Amazon': 164,\n 'Travel': 165,\n 'covid19': 166,\n 'seen': 167,\n 'increase': 168,\n 'new': 169,\n 'And': 170,\n 'Adult': 171,\n 'staff': 172,\n 'In': 173,\n 'keep': 174,\n 'them': 175,\n 'shelves': 176,\n 'via': 177,\n 'say': 178,\n 'cause': 179,\n 'parents': 180,\n 'needs': 181,\n 'money': 182,\n 'her': 183,\n 'were': 184,\n 'provide': 185,\n 'customers': 186,\n 'coronapocolypse': 187,\n 'Please': 188,\n '65': 189,\n '2': 190,\n 'while': 191,\n 'closed': 192,\n 'days': 193,\n 'emergency': 194,\n 'workers': 195,\n 'great': 196,\n 'important': 197,\n 'many': 198,\n 'making': 199,\n 'itÂ\\x92s': 200,\n 'when': 201,\n 'test': 202,\n 'support': 203,\n 'delivery': 204,\n 'under': 205,\n 'crisis': 206,\n 'paid': 207,\n 'advice': 208,\n 'neighbours': 209,\n 'numbers': 210,\n 'schools': 211,\n 'set': 212,\n 'order': 213,\n 'elderly': 214,\n 'amid': 215,\n 'only': 216,\n 'which': 217,\n 'PLEASE': 218,\n 'take': 219,\n 'than': 220,\n 'calm': 221,\n 'COVID_19': 222,\n 'confinement': 223,\n 'Me': 224,\n 'Not': 225,\n 'shortage': 226,\n 'first': 227,\n 'came': 228,\n 'County': 229,\n 'last': 230,\n 'week': 231,\n 'hand': 232,\n 'sharing': 233,\n 'To': 234,\n 'he': 235,\n 'know': 236,\n 'covid_19': 237,\n 'Due': 238,\n 'business': 239,\n 'next': 240,\n 'two': 241,\n '16': 242,\n 'Thank': 243,\n 'corona': 244,\n 'stop': 245,\n 'things': 246,\n 'Its': 247,\n 'COVID': 248,\n 'supermarkets': 249,\n 'restaurants': 250,\n 'closing': 251,\n 'same': 252,\n 'lockdown': 253,\n 'wait': 254,\n 'particularly': 255,\n 'thank': 256,\n 'ensure': 257,\n 'doors': 258,\n 'isolation': 259,\n 'symptoms': 260,\n 'Brands': 261,\n '_': 262,\n 'where': 263,\n 'Foods': 264,\n 'Grocery': 265,\n 'struggling': 266,\n 'nonprofit': 267,\n 'services': 268,\n 'impacts': 269,\n 'jobs': 270,\n 'way': 271,\n 'life': 272,\n '100': 273,\n 'covid': 274,\n 'world': 275,\n 'must': 276,\n 'china': 277,\n 'decisions': 278,\n 'AMAZING': 279,\n 'CHEAP': 280,\n 'DEALS': 281,\n 'THE': 282,\n 'going': 283,\n 'Trials': 284,\n 'Monthly': 285,\n 'Yearly': 286,\n 'Resonable': 287,\n 'Prices': 288,\n 'Subscriptions': 289,\n 'DM': 290,\n 'US': 291,\n 'bestiptv': 292,\n 'iptv': 293,\n 'Service': 294,\n 'Iptv': 295,\n 'iptvdeals': 296,\n 'Cheap': 297,\n 'ipTV': 298,\n 'Football': 299,\n 'HD': 300,\n 'Movies': 301,\n 'Cinema': 302,\n 'hotmovies': 303,\n '10DowningStreet': 304,\n 'left': 305,\n 'actions': 306,\n 'selfish': 307,\n 'UK': 308,\n 'expect': 309,\n '12': 310,\n 'full': 311,\n 'morning': 312,\n 'tested': 313,\n 'far': 314,\n 'doing': 315,\n 'Do': 316,\n 'NYC': 317,\n 'file': 318,\n 'complaint': 319,\n 'United': 320,\n 'States': 321,\n 'Breaking': 322,\n 'fact': 323,\n 'Were': 324,\n 'health': 325,\n 'any': 326,\n 'Went': 327,\n 'yesterday': 328,\n 'Corona': 329,\n 'Yes': 330,\n 'But': 331,\n 'posting': 332,\n 'photos': 333,\n 'stuff': 334,\n 'themselves': 335,\n 'everything': 336,\n 'Worried': 337,\n 'current': 338,\n 'times': 339,\n 'works': 340,\n 'saying': 341,\n 'deep': 342,\n 'clean': 343,\n 'gon': 344,\n 'na': 345,\n 'without': 346,\n 'Online': 347,\n 'placed': 348,\n 'unable': 349,\n 'too': 350,\n 'economy': 351,\n 'clothes': 352,\n 'QuarantineLife': 353,\n 'line': 354,\n 'basic': 355,\n 'issues': 356,\n 'offering': 357,\n 'deliveries': 358,\n 'People': 359,\n 'completely': 360,\n 'come': 361,\n 'back': 362,\n 'restrictions': 363,\n 'run': 364,\n 'cannabis': 365,\n 'yet': 366,\n 'stocking': 367,\n 'coming': 368,\n 'before': 369,\n 'remain': 370,\n 'water': 371,\n 'companies': 372,\n 'close': 373,\n 'canÂ\\x92t': 374,\n 'Ive': 375,\n 'staying': 376,\n 'markets': 377,\n 'Of': 378,\n 'why': 379,\n 'Malaysia': 380,\n 'facing': 381,\n 'surprise': 382,\n 'called': 383,\n 'So': 384,\n 'care': 385,\n 'house': 386,\n 'Sadly': 387,\n 'necessary': 388,\n 'mean': 389,\n 'word': 390,\n 'donÂ\\x92t': 391,\n 'seafood': 392,\n 'student': 393,\n 'loan': 394,\n 'stopping': 395,\n 'economic': 396,\n 'though': 397,\n 'BorisJohnson': 398,\n 'government': 399,\n 'pressure': 400,\n 'omnichannel': 401,\n 'idea': 402,\n 'wont': 403,\n 'DO': 404,\n 'older': 405,\n 'plan': 406,\n 'IÂ\\x92ve': 407,\n 'public': 408,\n 'events': 409,\n 'hoard': 410,\n 'supply': 411,\n 'chain': 412,\n 'stocked': 413,\n 'by': 414,\n 'You': 415,\n 'employees': 416,\n 'potatoes': 417,\n 'MeNyrbie': 418,\n 'Phil_Gahan': 419,\n 'Chrisitv': 420,\n 'httpstcoiFz9FAn2Pa': 421,\n 'httpstcoxX6ghGFzCC': 422,\n 'httpstcoI2NlzdxNo8': 423,\n 'Talk': 424,\n 'exchange': 425,\n 'create': 426,\n 'contact': 427,\n 'list': 428,\n 'employer': 429,\n 'chemist': 430,\n 'GP': 431,\n 'accounts': 432,\n 'poss': 433,\n 'adequate': 434,\n 'regular': 435,\n 'meds': 436,\n 'Australia': 437,\n 'Woolworths': 438,\n 'give': 439,\n 'disabled': 440,\n 'dedicated': 441,\n 'httpstcobInCA9Vp8P': 442,\n 'THERE': 443,\n 'WILL': 444,\n 'BE': 445,\n 'ENOUGH': 446,\n 'FOOD': 447,\n 'EVERYONE': 448,\n 'COVID19france': 449,\n 'Confinementotal': 450,\n 'ConfinementGeneral': 451,\n 'httpstcozrlG0Z520j': 452,\n 'ready': 453,\n 'paranoid': 454,\n 'litteraly': 455,\n 'serious': 456,\n 'thing': 457,\n 'causes': 458,\n 'CoronavirusFrance': 459,\n 'restezchezvous': 460,\n 'StayAtHome': 461,\n 'httpstcousmuaLq72n': 462,\n 'regionÂ\\x92s': 463,\n 'confirmed': 464,\n 'Sullivan': 465,\n 'flocked': 466,\n 'area': 467,\n 'cleaning': 468,\n 'sanitizer': 469,\n 'Tim_Dodson': 470,\n 'reports': 471,\n 'httpstcocfXch7a2lU': 472,\n 'Cashier': 473,\n 'insights': 474,\n 'prove': 475,\n 'credibility': 476,\n 'commented': 477,\n 'Civics': 478,\n 'class': 479,\n 'talking': 480,\n 'httpstcoieFDNeHgDO': 481,\n 'Was': 482,\n 'Didnt': 483,\n 'Rebel': 484,\n 'toiletpapercrisis': 485,\n 'httpstcoeVXkQLIdAZ': 486,\n 'classroom': 487,\n 'Atlanta': 488,\n 'walkin': 489,\n 'classes': 490,\n 'beginning': 491,\n 'Monday': 492,\n 'continue': 493,\n 'process': 494,\n 'normal': 495,\n 'understanding': 496,\n 'httpstcokw91zJ5O5i': 497,\n 'preventionwe': 498,\n 'cash': 499,\n 'payment': 500,\n 'methods': 501,\n 'through': 502,\n 'notes': 503,\n 'Also': 504,\n 'prefer': 505,\n 'fight': 506,\n 'against': 507,\n 'govindia': 508,\n 'IndiaFightsCorona': 509,\n 'month': 510,\n 'hasnt': 511,\n 'crowding': 512,\n 'however': 513,\n 'reducing': 514,\n 'malls': 515,\n 'means': 516,\n 'using': 517,\n 'entrance': 518,\n 'dependent': 519,\n 'single': 520,\n 'manila': 521,\n 'covid2019': 522,\n 'Philippines': 523,\n 'httpstcoHxWs9LAnF9': 524,\n 'longer': 525,\n 'beef': 526,\n 'share': 527,\n 'freezer': 528,\n 'packs': 529,\n 'patience': 530,\n 'horningsea': 531,\n 'caring': 532,\n 'LetÂ\\x92s': 533,\n 'ALL': 534,\n 'look': 535,\n 'less': 536,\n 'capable': 537,\n 'village': 538,\n 'Bringing': 539,\n 'self': 540,\n 'exposed': 541,\n 'somebody': 542,\n 'httpstcolsGrXXhjhh': 543,\n 'Ill': 544,\n 'deliver': 545,\n 'whatever': 546,\n 'CoronaVirus': 547,\n 'httpstco8YWaKFjExC': 548,\n 'ADARA': 549,\n 'Releases': 550,\n 'Resource': 551,\n 'Center': 552,\n 'Insights': 553,\n 'Help': 554,\n 'UpToDate': 555,\n 'Behavior': 556,\n 'Trends': 557,\n 'httpstcoPnA797jDKV': 558,\n 'httpstcodQox6uSihz': 559,\n 'Lines': 560,\n 'unpredictable': 561,\n 'eating': 562,\n 'alternative': 563,\n 'Find': 564,\n 'whether': 565,\n 'avoiding': 566,\n 'right': 567,\n 'httpstco9idZSis5oQ': 568,\n 'httpstcoZHbh898lf6': 569,\n '13': 570,\n 'httpstco51bL8P6vZh': 571,\n 'eyeonthearctic': 572,\n '16MAR20': 573,\n 'Russia': 574,\n 'surveillance': 575,\n 'watchdog': 576,\n 'reported': 577,\n 'high': 578,\n 'Arctic': 579,\n 'man': 580,\n 'traveled': 581,\n 'Iran': 582,\n '101': 583,\n 'observed': 584,\n 'httpstco4WnrrK9oKC': 585,\n 'httpstcold05k5Eyns': 586,\n 'Glitch': 587,\n 'Stymies': 588,\n 'Whole': 589,\n 'Fresh': 590,\n 'Deliveries': 591,\n 'Â\\x93As': 592,\n 'weÂ\\x92ve': 593,\n 'significant': 594,\n 'groceriesÂ\\x94': 595,\n 'spokeswoman': 596,\n 'said': 597,\n 'statement': 598,\n 'Â\\x93Today': 599,\n 'resulted': 600,\n 'systems': 601,\n 'affecting': 602,\n 'httpstcoTbzZ2MC3b3': 603,\n 'arent': 604,\n 'consider': 605,\n 'donating': 606,\n 'bank': 607,\n 'peoples': 608,\n 'nations': 609,\n 'inficted': 610,\n 'play': 611,\n 'fair': 612,\n 'goverments': 613,\n 'adopts': 614,\n 'guilde': 615,\n 'lines': 616,\n 'safty': 617,\n 'chinese': 618,\n 'goverment': 619,\n 'guilty': 620,\n 'irosponcible': 621,\n 'global': 622,\n 'scale': 623,\n 'httpstcoAVKrR9syff': 624,\n 'impacting': 625,\n 'behavior': 626,\n 'sales': 627,\n 'according': 628,\n 'First': 629,\n 'Insight': 630,\n 'study': 631,\n 'iptvnew': 632,\n 'iptv2020': 633,\n 'ipTv': 634,\n 'IPTVLinks': 635,\n '18Movies': 636,\n 'grantshapps': 637,\n 'done': 638,\n 'essential': 639,\n 'restocked': 640,\n 'actively': 641,\n 'discouraged': 642,\n 'checkout': 643,\n 'police': 644,\n 'profiteer': 645,\n 'poll': 646,\n 'indicates': 647,\n 'majority': 648,\n 'covid19s': 649,\n '412': 650,\n 'tracker': 651,\n 'See': 652,\n 'results': 653,\n 'RetailX': 654,\n 'Confidence': 655,\n 'Tracker': 656,\n 'httpstcoK3uJlcjqDB': 657,\n 'httpstco9G3kgqIXJ8': 658,\n 'preparation': 659,\n 'higher': 660,\n 'potential': 661,\n 'Hunger': 662,\n 'Coalition': 663,\n 'purchased': 664,\n '10': 665,\n 'percent': 666,\n 'implemented': 667,\n 'protocols': 668,\n 'httpstco5CecYtLnYn': 669,\n 'Covid': 670,\n 'feel': 671,\n 'ok': 672,\n 'isolated': 673,\n 'since': 674,\n 'found': 675,\n 'possible': 676,\n 'exposure': 677,\n 'pragmatic': 678,\n 'updated': 679,\n 'IÂ\\x92m': 680,\n 'httpstcoLg7HVMZglZ': 681,\n 'malicious': 682,\n 'price': 683,\n 'increases': 684,\n 'Department': 685,\n 'Worker': 686,\n 'Protection': 687,\n 'DCWP': 688,\n 'page': 689,\n 'digitally': 690,\n 'Click': 691,\n 'httpstcooEx6Y8mm2K': 692,\n 'wordOvercharge': 693,\n 'httpstcoMdMmoBttOP': 694,\n 'CovidNYC': 695,\n '7SealsOfTheEnd': 696,\n 'Soon': 697,\n 'dwindling': 698,\n 'unlawful': 699,\n 'Panicky': 700,\n 'breaking': 701,\n 'Closed': 702,\n 'Stores': 703,\n 'Supermarkets': 704,\n 'Raid': 705,\n 'normally': 706,\n 'Crisis': 707,\n 'massive': 708,\n 'StockUpamp': 709,\n 'LockUp': 710,\n 'There': 711,\n 'Is': 712,\n 'Country': 713,\n 'ensues': 714,\n 'Hole': 715,\n 'images': 716,\n 'nicest': 717,\n 'richest': 718,\n 'neighborhoods': 719,\n 'httpstcoWnQSoMtkVI': 720,\n 'BreakingNews': 721,\n 'Collapse': 722,\n 'Retail': 723,\n 'closures': 724,\n 'explode': 725,\n 'CNBC': 726,\n 'BrickAndMortar': 727,\n 'httpstcohQrYRNXFhv': 728,\n 'httpstcog5UZn06gb6': 729,\n 'fun': 730,\n 'cough': 731,\n 'whole': 732,\n 'aisle': 733,\n 'yourself': 734,\n 'pretty': 735,\n 'quickly': 736,\n 'sorry': 737,\n 'FinFabUK': 738,\n 'event': 739,\n 'cancelled': 740,\n 'wellbeing': 741,\n 'attendees': 742,\n 'speakers': 743,\n 'top': 744,\n 'priority': 745,\n 'Apologies': 746,\n 'disappointment': 747,\n 'FAQs': 748,\n 'answered': 749,\n 'link': 750,\n 'below': 751,\n 'httpstcoGDDPTudCvj': 752,\n 'gone': 753,\n 'Has': 754,\n 'anything': 755,\n 'whats': 756,\n 'point': 757,\n 'load': 758,\n 'kids': 759,\n 'siblings': 760,\n 'cant': 761,\n 'viral': 762,\n 'alr': 763,\n 'finances': 764,\n 'WeÂ\\x92ve': 765,\n 'published': 766,\n 'tips': 767,\n 'manage': 768,\n 'challenging': 769,\n 'httpstco3jKK3CqXfQ': 770,\n 'httpstcoEbEnURmmJS': 771,\n 'wife': 772,\n 'retailamp': 773,\n 'customer': 774,\n 'coughing': 775,\n 'everywhere': 776,\n 'CoVid19': 777,\n 'requested': 778,\n 'company': 779,\n 'objected': 780,\n 'cost': 781,\n 'recommending': 782,\n 'team': 783,\n 'spray': 784,\n 'disinfectantamp': 785,\n 'dieget': 786,\n 'capitalism': 787,\n 'Now': 788,\n 'judged': 789,\n 'httpstcokrTCGiUHQS': 790,\n 'experience': 791,\n 'environment': 792,\n 'associates': 793,\n 'httpstcodCSXHUj3U0': 794,\n 'jlmco': 795,\n 'jlmcobrand': 796,\n 'shoponline': 797,\n 'httpstcoriNKwskeRS': 798,\n 'Curious': 799,\n 'shoppers': 800,\n 'lot': 801,\n 'bc': 802,\n 'theyre': 803,\n 'spooked': 804,\n 'extra': 805,\n 'pair': 806,\n 'shoes': 807,\n 'onlineshopping': 808,\n 'stayhome': 809,\n 'CHECK': 810,\n 'VIDEO': 811,\n 'httpstco1ksn9Brl02': 812,\n 'USA': 813,\n 'market': 814,\n 'die': 815,\n 'starvation': 816,\n 'houston': 817,\n 'nofood': 818,\n 'Notoiletpaper': 819,\n 'NoHandShakes': 820,\n 'nohandsanitizer': 821,\n 'totallockdown': 822,\n 'COVID2019usa': 823,\n 'walmart': 824,\n 'httpstcoztN3iMkgpD': 825,\n 'Story': 826,\n 'rises': 827,\n 'find': 828,\n 'mysterious': 829,\n 'white': 830,\n 'patches': 831,\n 'forming': 832,\n 'IMadeThisUp': 833,\n 'FakeNews': 834,\n 'httpstco5Z24hptT9M': 835,\n 'outside': 836,\n 'Target': 837,\n 'South': 838,\n 'Africans': 839,\n 'hits': 840,\n 'httpstco6nGNFJmy89': 841,\n 'CoronaVirusSA': 842,\n 'httpstcopzirO10avf': 843,\n 'Share': 844,\n 'Know': 845,\n 'someone': 846,\n 's': 847,\n 'Living': 848,\n 'own': 849,\n 'local': 850,\n 'around': 851,\n 're': 852,\n 'FREE': 853,\n 'soups': 854,\n 'NATIONWIDE': 855,\n 'anyone': 856,\n 'Plus': 857,\n 'freezable': 858,\n 'half': 859,\n 'calling': 860,\n 'dumb': 861,\n 'idiots': 862,\n 'lol': 863,\n 'Never': 864,\n 'thought': 865,\n 'Id': 866,\n '2019': 867,\n 'Will': 868,\n 'peoplearelosingtheirminds': 869,\n 'StopTheMadness': 870,\n 'stoppanicbuying': 871,\n 'sparking': 872,\n 'Theyre': 873,\n 'Customers': 874,\n 'weekend': 875,\n 'preparing': 876,\n 'httpstcoWMqR8QWoiG': 877,\n 'Everything': 878,\n 'weÂ\\x92re': 879,\n 'seeing': 880,\n 'previous': 881,\n 'epidemics': 882,\n 'pandemics': 883,\n 'rise': 884,\n 'fear': 885,\n 'racism': 886,\n 'medicines': 887,\n 'conspiracy': 888,\n 'theories': 889,\n 'proliferation': 890,\n 'quack': 891,\n 'cures': 892,\n 'httpstcoPr8NpKX41A': 893,\n 'Everyone': 894,\n 'socialdistancing': 895,\n 'httpstcoWtB0B1AMON': 896,\n 'Why': 897,\n 'utility': 898,\n 'shut': 899,\n 'off': 900,\n 'middle': 901,\n 'thier': 902,\n 'lose': 903,\n 'kid': 904,\n 'afford': 905,\n 'worth': 906,\n 'SenatorRomney': 907,\n 'httpstco0CV0793olS': 908,\n 'Dear': 909,\n 'following': 910,\n 'social': 911,\n 'distancing': 912,\n 'rules': 913,\n 'prevent': 914,\n 'However': 915,\n 'spent': 916,\n 'alarming': 917,\n 'amount': 918,\n 'Where': 919,\n 'submit': 920,\n 'expenses': 921,\n 'reimbursement': 922,\n 'Let': 923,\n 'Global': 924,\n 'intensified': 925,\n 'across': 926,\n 'several': 927,\n 'geographies': 928,\n 'further': 929,\n 'downward': 930,\n 'pressures': 931,\n 'continued': 932,\n 'well': 933,\n 'supplied': 934,\n 'negative': 935,\n 'resulting': 936,\n 'Morning': 937,\n 'day': 938,\n 'StopPanicBuying': 939,\n 'BeKind': 940,\n 'mufc': 941,\n 'MUFC_Family': 942,\n 'youre': 943,\n 'afraid': 944,\n 'worst': 945,\n 'scenario': 946,\n 'wash': 947,\n 'tub': 948,\n 'Yall': 949,\n 'crazy': 950,\n 'THANK': 951,\n 'YOUR': 952,\n 'GROCERY': 953,\n 'CLERK': 954,\n 'looked': 955,\n 'weary': 956,\n 'eyes': 957,\n 'clerk': 958,\n 'thanked': 959,\n 'realized': 960,\n 'she': 961,\n 'thrust': 962,\n 'front': 963,\n 'panick': 964,\n 'A': 965,\n 'breed': 966,\n 'responders': 967,\n 'working': 968,\n 'hard': 969,\n 'serve': 970,\n 'communities': 971,\n 'With': 972,\n 'entire': 973,\n 'shops': 974,\n 'challenges': 975,\n 'near': 976,\n 'future': 977,\n 'lost': 978,\n 'Malaysia2020': 979,\n 'thoughts': 980,\n 'httpstcobPodDdPRcE': 981,\n 'Corner': 982,\n 'Scammers': 983,\n 'Taking': 984,\n 'Advantage': 985,\n 'Fears': 986,\n 'cdc': 987,\n 'flu': 988,\n 'trends': 989,\n 'alert': 990,\n 'httpstcosk9qCJsnYl': 991,\n 'httpstcoT7qejP3hys': 992,\n '4': 993,\n 'Both': 994,\n 'masks': 995,\n 'made': 996,\n 'medical': 997,\n 'personnel': 998,\n 'require': 999,\n ...}"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_accuracy', patience=3)\n",
    "# local minimum에 갇혔을 때 빠져나오는방법\n",
    "reduceLR = ReduceLROnPlateau(monitor= 'val_accuracy', patience=  2)\n",
    "\n",
    "\n",
    "\n",
    "train_text_2 = pad_sequences(train_text, maxlen=max(sample['max_len']) , padding='post', truncating='post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "val_text_2 =  pad_sequences(val_text , maxlen=max(sample['max_len']), padding='post', truncating= 'post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "embedding_dim = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "1417"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = len(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "1417"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "11    1\n47    4\n85    4\n28    2\n93    1\n     ..\n60    2\n71    4\n14    4\n92    2\n51    3\nName: Sentiment, Length: 70, dtype: int32"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "##\n",
    "# layer stack\n",
    "# 왜 v+1일까?\n",
    "# Embedding layer를 쌓을때마다 1차원이 늘어난다 쪼개서 입력하거나 하나씩 입력한다 이전의 embedding를 두번 쌓으면\n",
    "# 3차원(60,32,32) 에서 (60,32,32,32)로 늘어나는 것\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "# 계층의 단일 LSTM 셀에 대한 각 입력 시간 단계에 대해 하나의 숨겨진 상태 출력인 3개의 값 시퀀스가 반환된다\n",
    "# 1time step에서 문장 시퀀스가 3이라면 출력도 3 이고 그대로 들어간다\n",
    "# 다음 레이어가 동일한 출력을 받도록 return_sequences 를 true로 설정해주는 것 return_states는 셀 상태를 의미한다 장기기억\n",
    "\n",
    "# return states 이번 배치의 마지막 상태가 다음 배치의 입력으로 가중치가 입력된다\n",
    "# many to many 문제이거나 lstm 여러개라면 return sequence true 옵션 필요\n",
    "\n",
    "# 행별 최댓값 reshape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# 이 옵션은 중요한 게 return_sequence true 시 마지막 셀에서만 output 을 주는 것이 아니라 각 셀에서 output을 준다\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=max(sample['max_len'],)))\n",
    "## 전체 인풋길이는 V+1 로 유지하되 이 EMEDDDING ayer 를 쌓는다면 출력이 32 차원이므로 마지막 차원 하나당 32차원으로 게속 임베딩 되는것이다 (30 ,2) 이라면 2 를 가각 32차원으로 늘려 (30,2,32) 가된다\n",
    "model.add(Embedding(v+1, embedding_dim))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "# down sampling by taking steps max feature over the time dimension\n",
    "\n",
    "\n",
    "# 차원을 건너뛰어 최대 max feature 만 갖는다 왜 이걸 쓰냐면 input_len 문장 길이가 모두 60 길이는 아니기 때문이고\n",
    "# 각 문장의 단어가 임베딩된 값의 최댓값과 레이블을 가지고 트레이닝 하면 되기때문에 그런듯하다\n",
    "# 추정과 추론의 근거를 이루는 사실이 데이터니까\n",
    "\"\"\"\n",
    "class GlobalMaxPooling1D(_GlobalPooling1D):\n",
    "    Global max pooling operation for temporal data.\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    \"\"\"\"\"\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# 원 핫 인코딩을 사용해야함 하나의 값을 내서 트레이닝 하려면 sigmoid함수를 써야하나 오히려 정확도가 떨어진다 이런 식으로 만들면\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# model compile\n",
    "# 늘 모델은 파라미터가 쉽지않다\n",
    "# sparse_categorical_crossentropy 는 [0,3)까지 허용하고 이래서 s33333parse_categorical 을 사용 한 것이고 나는 감정을 축소 하지 않았기 때문에 sparse는 쓰지 않는다\n",
    "\"\"\"\n",
    "InvalidArgumentError:  Received a label value of 4 which is outside the valid range of [0, 3).  Label values: 0 1 4 0 4 4 1 4 4 3\n",
    "\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at c:\\\\users\\\\tjdal\\pycharmprojects\\\\kaggle\\\\venv\\\\lib\\\\site-packages\\\\keras\\\\backend.py:4944) ]] [Op:__inference_train_function_6101]\n",
    "\n",
    "Errors may have originated from an input operation.\n",
    "Input Source operations connected to node sparse_categorical3_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\n",
    " sparse_categorical_crossentropy/Reshape (defined at c:\\\\users\\\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\keras\\backend.py:3400)\n",
    " sparse_categorical_crossentropy/Reshape_1 (defined at c:\\\\users\\\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\keras\\backend.py:4940)\n",
    "\n",
    "Function call stack:\n",
    "train_function\n",
    "\"\"\"\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  출력레이어를 softmax를 사용할거면 레이블을 차원수만큼 임베딩 해서 출력에 주고 softmaxm를 사용해야한다\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 60, 32)            45376     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 60, 64)            24832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 74,433\n",
      "Trainable params: 74,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 5s 199ms/step - loss: 0.0000e+00 - accuracy: 0.2049 - val_loss: 0.0000e+00 - val_accuracy: 0.2667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.2022 - val_loss: 0.0000e+00 - val_accuracy: 0.2667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - accuracy: 0.1726 - val_loss: 0.0000e+00 - val_accuracy: 0.2667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - accuracy: 0.1593 - val_loss: 0.0000e+00 - val_accuracy: 0.2667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "r = model.fit(train_text_2, train_label, validation_data=(val_text_2, val_label), epochs=50,batch_size=10,callbacks=[reduceLR,early_stop])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding(input_dim(입력 단어 길이), output_dim 벡터 차원)\n",
    "#### 총평 corona nlp for ginner code 를 참조했는데 나는 감정을 3개로 축소하지않고  모델 인풋이 너무 적기에 모델 정확도가 낮았다\n",
    "# 적절히 튜닝할땐 근거를 알고 튜닝해서 다음엔 더 잘 적용하기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}