{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# regression)model ridge, lasso, elastic_net 을 키로 하여 구현되는 모델\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#Set the different values of alpha to be tested\n",
    "#alpha_ridge = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#각각은 alpha , l1_ratio , pred, cofficients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./data/data_train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./data/data_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(alphas=)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0      410.0\n1      100.0\n2       50.0\n3       80.0\n4      400.0\n       ...  \n329    290.0\n330    220.0\n331     80.0\n332     50.0\n333    120.0\nName: price, Length: 334, dtype: float64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['price']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def regression(data_train, data_test):\n",
    "\n",
    "\n",
    "    return {'ridge' : , 'lasso', 'elastic_net'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 등위 접속사 해석을 못해서 제대로 해석을 못하는건가\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def elastic_regression(data, alpha):\n",
    "    # Fit the model\n",
    "    x = data.iloc[:,:-1].values\n",
    "    y = data['price'].values\n",
    "    elasticreg = ElasticNetCV(normalize=True,alphas=alpha,l1_ratio=np.arange(0.6,1,0.1))\n",
    "    elasticreg.fit(x,y)\n",
    "    # y_pred = ridgereg.predict(x)\n",
    "    return elasticreg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def ridge_regression(data,  alpha ):\n",
    "    # Fit the model\n",
    "    x = data.iloc[:,:-1].values\n",
    "    y = data['price'].values\n",
    "    ridgereg = RidgeCV(normalize=True,alphas=alpha)\n",
    "    ridgereg.fit(x,y)\n",
    "    # y_pred = ridgereg.predict(x)\n",
    "\n",
    "    return ridgereg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def lasso_regression(data,  alpha ):\n",
    "    # Fit the model\n",
    "    x = data.iloc[:,:-1].values\n",
    "    y = data['price'].values\n",
    "    lassoreg = LassoCV(normalize=True,alphas=alpha)\n",
    "    lassoreg.fit(x,y)\n",
    "    # y_pred = ridgereg.predict(x)\n",
    "    return lassoreg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "alpha_ridge = np.logspace(-4,-1,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198315.15686030837, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105453.80449045866, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186254.02668569091, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 108976.6744332173, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 225917.99674557685, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 112683.03888285451, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 208746.61960185342, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 111862.2140757098, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186052.43405523675, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80718.29858736406, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165640.98551562973, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97031.12697599179, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156777.29213695222, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100970.78479471242, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187549.6679947928, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101934.9921458477, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171846.41707443967, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102182.00281173046, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157306.53071633348, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73495.4730679543, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 130656.3462087859, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88633.61705882236, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120174.4509297774, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93444.71363124711, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 160110.78099303914, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92680.69452124367, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 150002.87000241037, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93601.74491552268, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 126826.00285137034, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63697.243963486966, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14801.797376414179, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109238.56498147766, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78289.40729262054, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9123.569663161645, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101284.61997509871, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84240.73645340445, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6960.685121116985, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 113139.31907228786, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79598.87596338413, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13521.51293984917, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109175.1844336639, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82853.8787719844, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12910.218630666786, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89154.60994248315, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53224.355523195365, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
      "  warnings.warn(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+05, tolerance: 8.886e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elasticreg = elastic_regression(data_train,alpha=alpha_ridge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7999999999999999"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticreg.l1_ratio_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False, False, False,  True,\n        True,  True, False,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True, False, False, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True, False,  True,  True, False, False, False,  True,\n        True,  True,  True, False,  True,  True, False, False,  True,\n        True,  True,  True,  True,  True,  True, False, False])"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coef 가 0.001 이상인 값으로 획득하기\n",
    "abs(ridgereg.coef_) > 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "array([False,  True,  True,  True,  True,  True,  True, False, False,\n       False,  True, False, False, False,  True, False,  True,  True,\n        True,  True, False, False, False, False, False, False, False,\n       False,  True, False,  True, False, False,  True,  True, False,\n       False, False, False, False, False,  True,  True, False, False,\n       False, False,  True, False,  True, False, False,  True, False,\n       False, False, False, False, False, False, False, False,  True,\n       False,  True,  True, False, False, False, False,  True,  True,\n       False,  True, False, False, False, False, False, False,  True,\n       False, False,  True, False, False,  True, False, False, False,\n        True,  True,  True, False, False,  True, False, False])"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg.coef_ != 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "array([False,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True, False,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True, False, False, False,  True,  True,\n        True,  True, False,  True,  True,  True, False,  True,  True,\n        True, False,  True,  True,  True,  True, False, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True, False,  True,  True,  True, False, False, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True, False,  True,  True, False, False, False, False,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True,  True,  True, False,  True, False, False])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(elasticreg.coef_) > 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0001"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticreg.alpha_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elasticreg.predict(data_test.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1616.469873095397, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35242.89355912154, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57584.45969396205, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 789.6773670561088, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31329.40611276988, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63388.14101777748, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1815.7463086435164, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39977.35244375332, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55227.16547413227, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3005.7803418171825, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27616.607383577866, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63327.80517233668, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3231.9559207887796, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21876.32187050739, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35208.51529324755, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lassoreg = lasso_regression(data_train,alpha = alpha_ridge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "0.01"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg.alpha_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LassoCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([  6.221456  , 531.2477246 , 377.34692385, 134.60559544,\n       154.2094413 , 102.41442172, 362.96832198, 263.10240957,\n       334.38451313, 167.28959366])"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg.predict(data_test.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def ridge_regression(data,  alpha ):\n",
    "    # Fit the model\n",
    "    x = data.iloc[:,:-1].values\n",
    "    y = data['price'].values\n",
    "    ridgereg = RidgeCV(normalize=True,alphas=alpha)\n",
    "    ridgereg.fit(x,y)\n",
    "    # y_pred = ridgereg.predict(x)\n",
    "\n",
    "    return ridgereg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ridgereg = ridge_regression(data_train,alpha=alpha_ridge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RidgeCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([  1.27222324, 536.34987359, 384.69842927, 131.76890028,\n       166.2896877 , 104.64339239, 350.55107093, 262.11499878,\n       338.08007058, 169.28671441])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.predict(data_test.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "elasticreg = elastic_regression(data_train,alpha=alpha_ridge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0001"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticreg.alpha_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but ElasticNetCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([ 66.29125608, 365.64890598, 325.90450627, 216.66741267,\n       149.64502922, 145.7556738 , 317.45152104, 226.45545466,\n       395.70382563, 176.98036106])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticreg.predict(data_test.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ElasticNetCV(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LassoCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([ 14.73166115, 516.87584599, 373.68631222, 143.31667929,\n       148.05117858, 107.00180673, 371.41469042, 251.7472754 ,\n       330.5699473 , 168.58368161])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg.predict(data_test.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ridgereg = ridge_regression(data_train,alpha=alpha_ridge)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RidgeCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([  5.80772084, 472.81535392, 381.16598691, 160.51305898,\n       197.5619631 , 115.12161272, 367.46426979, 245.96148448,\n       353.50640771, 166.91465556])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조금 비슷한데 ridge\n",
    "# test 값과 그래도 많이 비슷하게 나오긴 했다 이렇게하면되는거엿나\n",
    "ridgereg.predict(data_test.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 410.,  100.,   50.,   80.,  400.,  160.,   60.,  130.,  450.,\n        700.,  700.,  490.,  240.,  430.,  310.,  120.,   70.,  290.,\n        370.,   30.,  270.,  410.,  470.,   20.,  340.,  270.,  230.,\n        340.,   70.,  200.,   90.,  150.,  400.,   70.,  190.,  140.,\n         40.,   50.,   70.,   80.,  220.,  590.,  290.,  270.,  600.,\n        240.,  110.,  400.,  110.,   50.,   60.,   30.,  220.,  450.,\n        420.,   40.,  140.,  500.,   70.,  630.,  170.,  370.,  170.,\n        160.,  170.,  280.,  180.,  300.,  220.,  150.,   50.,  100.,\n        300.,  250.,  140.,  450.,  240.,  260.,  300.,  650.,  100.,\n        170.,   20.,  140.,   60.,  145.,  230.,  100.,   90.,  100.,\n        390.,  200.,  330.,  180.,  130.,  150.,  110.,  900.,  150.,\n        190.,  150.,  310.,  120.,  370.,  210.,  360.,   30.,  270.,\n        160.,  260.,  100.,  180.,  200.,   90.,   30.,  370.,  140.,\n        130.,  390.,   90.,   90.,  380.,  170.,  300.,   90.,  400.,\n         90.,  100.,  430.,  360.,  430.,  460.,  220.,  650.,  260.,\n        150.,  110.,   90.,   60.,   70.,  330.,   70.,  130.,  320.,\n        190.,  190.,   80.,  390.,  340.,  110.,  250.,   30.,   30.,\n        310.,  450.,  320.,  160.,  300.,  400.,  140.,   60.,  190.,\n        140.,  240.,  300.,  170.,  110.,  440.,   50.,  210.,   90.,\n         90.,  150.,   90.,  220.,  100.,  140.,  330.,  180.,  140.,\n        240.,  430.,   90.,  230.,  120.,  110.,  210.,   30.,   60.,\n        330.,  230.,  510.,  470.,  110.,  300.,  130.,  480.,  440.,\n        200.,  110.,  220.,  380.,  300.,   70.,  200.,  420.,   80.,\n        460.,  350.,  310.,  390.,  100.,  350.,  210.,  450.,  110.,\n        330.,   90.,  210.,  100.,  120.,  700.,  270.,  420.,  350.,\n        110.,  160.,  110.,  140.,  130.,   80.,  650.,  210.,  600.,\n        210.,  420.,  310.,  160.,  190.,   60.,  320.,   90.,   70.,\n        400.,  700.,   90.,  420.,  110.,  180.,  520.,  110.,  440.,\n        300.,  300.,  410.,   60.,  250.,   80.,  170.,   60.,  350.,\n        300.,  120.,  190.,  350.,  240.,  260.,  250.,  160.,   80.,\n        300.,  160.,  230.,  110.,  140., 1000.,  450.,  430.,  260.,\n         40.,  430.,  200.,  300.,   70.,  110.,  450.,  330.,  250.,\n         80.,  120.,  420.,  200.,  110.,  160.,   50.,   50.,  100.,\n        190.,  160.,   50.,  160.,  220.,  140.,  110.,  900.,  120.,\n        120.,   80.,  120.,  360.,  210.,  440.,  370.,  350.,  350.,\n         50.,   20.,  270.,  180.,  140.,  220.,  440.,  320.,   50.,\n        100.,   70.,   50.,  300.,  170.,  290.,  220.,   80.,   50.,\n        120.])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label = data_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 681.2812369135208, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 881.6959083313122, tolerance: 675.1469850187265\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3566.8699054764584, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14587.502878910862, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23459.64732733043, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29034.38473199401, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32768.070631376, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37225.3828955628, tolerance: 715.8360299625468\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1982.6433526026085, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3603.4141539344564, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4121.356909797993, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4265.3869297793135, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8584.482837763615, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14291.175257894676, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26386.01073239278, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37865.122646357864, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56460.9334001448, tolerance: 774.844063670412\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7569.553555373102, tolerance: 708.1831647940073\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1057.2625193723943, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3927.9245008963626, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4956.920810411917, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5054.073530152673, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5096.322031736374, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5129.641995883547, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5150.066177570261, tolerance: 677.3141324626868\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LassoCV()"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv.fit(data_train.iloc[:,:-1].values, y =data_train['price'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([108.13701704, 314.45676954, 256.61381562, 211.10609393,\n       114.04922629, 164.63046843, 259.43077865, 178.03032145,\n       469.31937275, 156.83631433])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv.predict(data_test.iloc[:,:-1].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[8.30000000e+02, 2.60000000e+02, 2.49000000e+01, 3.00000000e+01,\n        2.16220000e+02, 4.00000000e+00, 1.90000000e+02, 1.58000000e+03,\n        4.03000000e+01, 4.08400000e+01, 1.15000000e+00, 1.50266800e+05,\n        1.14950000e+03, 3.41000000e+01, 2.14350000e+02, 4.86683000e+03,\n        5.73726531e+02, 6.80290000e+02, 1.75500000e+03, 6.71400000e+03,\n        4.34000000e+01, 3.64500000e+01, 1.53516000e+03, 2.92995000e+04,\n        4.66212200e+05, 2.62800000e+03, 3.93000000e+01, 4.02100000e+01,\n        1.52000000e+00, 1.43737700e+05, 1.28450000e+03, 3.35000000e+01,\n        1.42900000e+02, 3.24455000e+03, 1.50000000e+01, 5.54081966e+02,\n        6.63970000e+02, 1.75500000e+03, 5.82700000e+03, 4.17900000e+01,\n        3.47600000e+01, 1.52755000e+03, 1.95330000e+04, 4.09677900e+05,\n        2.37400000e+03, 3.80000000e+01, 3.94300000e+01, 9.20000000e-01,\n        1.34548400e+05, 1.19110000e+03, 3.37000000e+01, 7.14500000e+01,\n        1.62228000e+03, 5.74600000e+02, 6.80500000e+02, 1.75500000e+03,\n        5.56500000e+03, 4.10300000e+01, 3.33700000e+01, 1.60179000e+03,\n        9.76650000e+03, 4.03875000e+05, 2.69300000e+03, 3.62000000e+01,\n        3.76400000e+01, 1.55000000e+00, 1.34312500e+05, 1.52900000e+03,\n        3.14300000e+01, 1.75700000e+02, 3.99470000e+03, 5.89500000e+02,\n        7.65800000e+02, 1.75500000e+03, 4.93000000e+03, 3.87000000e+01,\n        3.20400000e+01, 1.65306000e+03, 3.79330000e+04, 3.77828600e+05,\n        2.79000000e+03, 3.57000000e+01, 3.74200000e+01, 1.28000000e+00,\n        1.24042200e+05, 1.08390000e+03, 3.04900000e+01, 1.31780000e+02,\n        2.99603000e+03, 5.44000000e+02, 6.52800000e+02, 1.75500000e+03,\n        4.71800000e+03, 3.64000000e+01, 3.03200000e+01, 1.62598000e+03,\n        2.84497500e+04, 3.77633300e+05],\n       [8.20000000e+02, 2.50000000e+02, 3.03400000e+02, 3.70000000e+02,\n        9.28270000e+02, 7.00000000e+00, 2.40000000e+03, 3.05200000e+03,\n        1.24400000e+02, 1.08420000e+02, 2.75000000e+00, 9.21019400e+05,\n        4.60210000e+03, 1.10300000e+02, 2.99400000e+02, 4.34468000e+04,\n        1.82160000e+03, 1.96370000e+03, 9.11422000e+03, 9.13100000e+03,\n        1.16560000e+02, 1.19130000e+02, 9.45940000e+03, 4.70960000e+04,\n        1.39175710e+06, 2.91800000e+03, 1.20200000e+02, 1.07200000e+02,\n        2.29000000e+00, 8.32123700e+05, 5.13610000e+03, 1.09600000e+02,\n        2.24550000e+02, 3.25851000e+04, 1.50000000e+01, 1.75770000e+03,\n        1.81760000e+03, 9.06361000e+03, 9.07800000e+03, 1.12150000e+02,\n        1.15700000e+02, 1.03042000e+04, 3.53220000e+04, 1.18185620e+06,\n        2.26400000e+03, 1.16300000e+02, 1.04710000e+02, 2.47000000e+00,\n        7.84948500e+05, 4.85810000e+03, 1.09100000e+02, 1.49700000e+02,\n        2.17234000e+04, 1.53460000e+03, 1.79530000e+03, 9.00091000e+03,\n        9.02200000e+03, 1.09020000e+02, 1.12000000e+02, 1.04114500e+04,\n        2.35480000e+04, 1.16769740e+06, 2.85900000e+03, 1.11400000e+02,\n        1.04330000e+02, 2.50000000e+00, 7.04586300e+05, 6.62260000e+03,\n        1.07500000e+02, 7.48500000e+01, 1.08617000e+04, 1.83660000e+03,\n        1.93250000e+03, 8.92004000e+03, 8.93800000e+03, 1.10510000e+02,\n        1.08510000e+02, 1.24238600e+04, 1.17740000e+04, 1.18157260e+06,\n        3.15200000e+03, 1.06000000e+02, 1.03030000e+02, 3.15000000e+00,\n        6.85697500e+05, 3.52610000e+03, 1.05500000e+02, 2.08800000e+02,\n        1.75843000e+04, 1.40840000e+03, 1.47350000e+03, 8.84218000e+03,\n        8.86400000e+03, 1.05520000e+02, 1.05320000e+02, 1.21130100e+04,\n        4.59660000e+04, 1.18899580e+06],\n       [1.86000000e+03, 4.80000000e+02, 5.39400000e+02, 2.90000000e+02,\n        8.36280000e+02, 4.00000000e+00, 3.30000000e+03, 2.85900000e+03,\n        1.11400000e+02, 1.04330000e+02, 2.50000000e+00, 7.04586300e+05,\n        6.62260000e+03, 1.07500000e+02, 7.48500000e+01, 1.08617000e+04,\n        1.83660000e+03, 1.93250000e+03, 8.92004000e+03, 8.93800000e+03,\n        1.10510000e+02, 1.08510000e+02, 1.24238600e+04, 1.17740000e+04,\n        1.18157260e+06, 3.15200000e+03, 1.06000000e+02, 1.03030000e+02,\n        3.15000000e+00, 6.85697500e+05, 3.52610000e+03, 1.05500000e+02,\n        2.08800000e+02, 1.75843000e+04, 1.50000000e+01, 1.40840000e+03,\n        1.47350000e+03, 8.84218000e+03, 8.86400000e+03, 1.05520000e+02,\n        1.05320000e+02, 1.21130100e+04, 4.59660000e+04, 1.18899580e+06,\n        2.70000000e+03, 1.03000000e+02, 1.01840000e+02, 2.65000000e+00,\n        6.25829200e+05, 4.38690000e+03, 1.00400000e+02, 1.56600000e+02,\n        1.31882300e+04, 1.42410000e+03, 1.58430000e+03, 8.77671000e+03,\n        8.79900000e+03, 1.01000000e+02, 1.01890000e+02, 1.35718000e+04,\n        3.44745000e+04, 1.06777200e+06, 3.56100000e+03, 9.82000000e+01,\n        9.86400000e+01, 2.76000000e+00, 6.02224700e+05, 3.81900000e+03,\n        9.72000000e+01, 1.04400000e+02, 8.79215000e+03, 1.29880000e+03,\n        1.38960000e+03, 8.69973000e+03, 8.73500000e+03, 9.81200000e+01,\n        9.84500000e+01, 1.35963700e+04, 2.29830000e+04, 9.73523700e+05,\n        3.15700000e+03, 9.28000000e+01, 9.64900000e+01, 3.05000000e+00,\n        5.52124400e+05, 3.89670000e+03, 9.69000000e+01, 5.22000000e+01,\n        4.39608000e+03, 1.29420000e+03, 1.28800000e+03, 8.55554000e+03,\n        8.58500000e+03, 9.53500000e+01, 9.43400000e+01, 1.20635000e+04,\n        1.14915000e+04, 9.54628600e+05],\n       [1.23000000e+03, 2.70000000e+02, 1.23000000e+02, 1.00000000e+02,\n        3.41940000e+02, 6.00000000e+00, 6.30000000e+02, 3.67800000e+03,\n        8.62000000e+01, 8.32100000e+01, 3.25000000e+00, 5.26596400e+05,\n        2.79060000e+03, 9.41000000e+01, 3.34800000e+02, 1.44886000e+04,\n        1.14380000e+03, 1.31630000e+03, 8.36478000e+03, 8.39300000e+03,\n        9.09500000e+01, 8.97900000e+01, 1.13793700e+04, 4.48350000e+04,\n        9.29027100e+05, 2.73400000e+03, 8.19000000e+01, 8.10500000e+01,\n        2.44000000e+00, 4.86347800e+05, 3.15730000e+03, 9.04000000e+01,\n        2.51100000e+02, 1.08664500e+04, 1.50000000e+01, 1.08250000e+03,\n        1.17650000e+03, 8.34360000e+03, 8.38200000e+03, 8.72700000e+01,\n        8.55600000e+01, 1.05554700e+04, 3.36262500e+04, 8.65878900e+05,\n        2.24700000e+03, 7.69000000e+01, 7.99300000e+01, 2.04000000e+00,\n        4.63829000e+05, 4.10740000e+03, 8.82000000e+01, 1.67400000e+02,\n        7.24430000e+03, 1.03250000e+03, 1.20330000e+03, 8.27146000e+03,\n        8.32500000e+03, 8.53700000e+01, 8.28900000e+01, 8.99300000e+03,\n        2.24175000e+04, 8.33494600e+05, 2.21700000e+03, 7.29000000e+01,\n        7.86300000e+01, 1.81000000e+00, 4.27087700e+05, 4.52130000e+03,\n        8.59000000e+01, 8.37000000e+01, 3.62215000e+03, 1.01490000e+03,\n        1.10470000e+03, 8.14833000e+03, 8.18600000e+03, 8.35500000e+01,\n        8.00500000e+01, 6.70306000e+03, 1.12087500e+04, 8.17526900e+05,\n        3.25500000e+03, 6.94000000e+01, 7.62900000e+01, 2.84000000e+00,\n        4.17524000e+05, 5.14630000e+03, 8.17000000e+01, 3.72000000e+02,\n        1.57488000e+04, 1.00500000e+03, 1.27050000e+03, 8.00221000e+03,\n        8.05800000e+03, 7.96500000e+01, 7.69200000e+01, 5.06276000e+03,\n        4.37100000e+04, 7.88018300e+05],\n       [2.10000000e+03, 5.00000000e+02, 1.26000000e+02, 6.00000000e+01,\n        1.15847000e+03, 1.10000000e+01, 3.00000000e+02, 3.32100000e+03,\n        3.14000000e+01, 3.30000000e+01, 2.69000000e+00, 1.16552600e+05,\n        1.43080000e+03, 2.76800000e+01, 1.47900000e+02, 2.88280000e+03,\n        7.63200000e+02, 5.82800000e+02, 1.75500000e+03, 4.69500000e+03,\n        3.28300000e+01, 2.56200000e+01, 1.93675000e+03, 3.68180000e+04,\n        4.15431100e+05, 2.89800000e+03, 3.09000000e+01, 3.14700000e+01,\n        2.68000000e+00, 9.80429000e+04, 1.57110000e+03, 2.67400000e+01,\n        1.10930000e+02, 2.16210000e+03, 1.50000000e+01, 4.12000000e+02,\n        7.68000000e+02, 1.75500000e+03, 4.63000000e+03, 3.13000000e+01,\n        2.38700000e+01, 1.99143000e+03, 2.76135000e+04, 4.13834500e+05,\n        3.30200000e+03, 2.95000000e+01, 2.99300000e+01, 3.56000000e+00,\n        9.23542000e+04, 1.66890000e+03, 2.58000000e+01, 7.39500000e+01,\n        1.44140000e+03, 4.31100000e+02, 5.50400000e+02, 1.75500000e+03,\n        4.25200000e+03, 3.01300000e+01, 2.15400000e+01, 2.13449000e+03,\n        1.84090000e+04, 4.02158100e+05, 2.50700000e+03, 2.69000000e+01,\n        2.84000000e+01, 3.31000000e+00, 8.53476000e+04, 1.16330000e+03,\n        2.48600000e+01, 3.69800000e+01, 7.20700000e+02, 3.31300000e+02,\n        4.67100000e+02, 1.75167000e+03, 4.19800000e+03, 2.99500000e+01,\n        1.97000000e+01, 2.00042000e+03, 9.20450000e+03, 4.20359600e+05,\n        2.30900000e+03, 2.43000000e+01, 2.68700000e+01, 3.51000000e+00,\n        8.50722000e+04, 8.67400000e+02, 2.39200000e+01, 1.34300000e+02,\n        1.87260000e+03, 2.25700000e+02, 4.09300000e+02, 1.75000000e+03,\n        4.06300000e+03, 2.78400000e+01, 1.83700000e+01, 1.54944000e+03,\n        3.57630000e+04, 4.20700500e+05],\n       [1.23000000e+03, 2.70000000e+02, 9.84000000e+01, 8.00000000e+01,\n        4.74060000e+02, 6.00000000e+00, 6.80000000e+02, 7.19600000e+03,\n        5.13000000e+01, 5.61300000e+01, 5.97000000e+00, 2.49110700e+05,\n        2.56230000e+03, 5.28000000e+01, 2.17000000e+02, 1.04456000e+04,\n        7.33800000e+02, 8.15500000e+02, 1.75500000e+03, 8.00200000e+03,\n        6.07400000e+01, 5.42600000e+01, 2.97826000e+03, 4.14070000e+04,\n        6.01988100e+05, 5.27500000e+03, 5.09000000e+01, 5.76200000e+01,\n        4.30000000e+00, 2.25500900e+05, 2.68430000e+03, 5.03000000e+01,\n        1.62750000e+02, 7.83420000e+03, 1.50000000e+01, 7.42700000e+02,\n        8.12700000e+02, 1.75500000e+03, 8.10200000e+03, 5.86600000e+01,\n        5.18600000e+01, 2.85020000e+03, 3.10552500e+04, 5.88020500e+05,\n        4.69100000e+03, 4.91000000e+01, 5.92900000e+01, 3.53000000e+00,\n        2.12073300e+05, 2.10350000e+03, 4.75000000e+01, 1.08500000e+02,\n        5.22280000e+03, 7.69600000e+02, 7.17900000e+02, 1.75500000e+03,\n        8.23100000e+03, 5.69900000e+01, 4.84000000e+01, 2.55696000e+03,\n        2.07035000e+04, 6.05688700e+05, 4.07200000e+03, 4.78000000e+01,\n        5.78800000e+01, 3.39000000e+00, 1.98459600e+05, 2.03480000e+03,\n        4.50000000e+01, 5.42500000e+01, 2.61140000e+03, 6.45900000e+02,\n        7.44500000e+02, 1.75500000e+03, 8.41800000e+03, 5.63700000e+01,\n        4.64500000e+01, 2.42437000e+03, 1.03517500e+04, 6.26960300e+05,\n        3.67000000e+03, 4.63000000e+01, 5.22600000e+01, 3.25000000e+00,\n        1.92689200e+05, 1.97900000e+03, 4.01000000e+01, 2.58200000e+02,\n        9.45270000e+03, 6.29900000e+02, 7.64500000e+02, 1.75500000e+03,\n        8.42000000e+03, 5.46200000e+01, 4.47900000e+01, 2.20619000e+03,\n        4.02340000e+04, 6.29797200e+05],\n       [2.12000000e+03, 4.70000000e+02, 5.72400000e+02, 2.70000000e+02,\n        6.50570000e+02, 6.00000000e+00, 2.90000000e+03, 3.15200000e+03,\n        1.06000000e+02, 1.03030000e+02, 3.15000000e+00, 6.85697500e+05,\n        3.52610000e+03, 1.05500000e+02, 2.08800000e+02, 1.75843000e+04,\n        1.40840000e+03, 1.47350000e+03, 8.84218000e+03, 8.86400000e+03,\n        1.05520000e+02, 1.05320000e+02, 1.21130100e+04, 4.59660000e+04,\n        1.18899580e+06, 2.70000000e+03, 1.03000000e+02, 1.01840000e+02,\n        2.65000000e+00, 6.25829200e+05, 4.38690000e+03, 1.00400000e+02,\n        1.56600000e+02, 1.31882300e+04, 1.50000000e+01, 1.42410000e+03,\n        1.58430000e+03, 8.77671000e+03, 8.79900000e+03, 1.01000000e+02,\n        1.01890000e+02, 1.35718000e+04, 3.44745000e+04, 1.06777200e+06,\n        3.56100000e+03, 9.82000000e+01, 9.86400000e+01, 2.76000000e+00,\n        6.02224700e+05, 3.81900000e+03, 9.72000000e+01, 1.04400000e+02,\n        8.79215000e+03, 1.29880000e+03, 1.38960000e+03, 8.69973000e+03,\n        8.73500000e+03, 9.81200000e+01, 9.84500000e+01, 1.35963700e+04,\n        2.29830000e+04, 9.73523700e+05, 3.15700000e+03, 9.28000000e+01,\n        9.64900000e+01, 3.05000000e+00, 5.52124400e+05, 3.89670000e+03,\n        9.69000000e+01, 5.22000000e+01, 4.39608000e+03, 1.29420000e+03,\n        1.28800000e+03, 8.55554000e+03, 8.58500000e+03, 9.53500000e+01,\n        9.43400000e+01, 1.20635000e+04, 1.14915000e+04, 9.54628600e+05,\n        3.67800000e+03, 8.62000000e+01, 8.32100000e+01, 3.25000000e+00,\n        5.26596400e+05, 2.79060000e+03, 9.41000000e+01, 3.34800000e+02,\n        1.44886000e+04, 1.14380000e+03, 1.31630000e+03, 8.36478000e+03,\n        8.39300000e+03, 9.09500000e+01, 8.97900000e+01, 1.13793700e+04,\n        4.48350000e+04, 9.29027100e+05],\n       [2.01000000e+03, 5.20000000e+02, 3.81900000e+02, 1.90000000e+02,\n        8.14350000e+02, 4.00000000e+00, 1.20000000e+03, 2.21700000e+03,\n        7.29000000e+01, 7.86300000e+01, 1.81000000e+00, 4.27087700e+05,\n        4.52130000e+03, 8.59000000e+01, 8.37000000e+01, 3.62215000e+03,\n        1.01490000e+03, 1.10470000e+03, 8.14833000e+03, 8.18600000e+03,\n        8.35500000e+01, 8.00500000e+01, 6.70306000e+03, 1.12087500e+04,\n        8.17526900e+05, 3.25500000e+03, 6.94000000e+01, 7.62900000e+01,\n        2.84000000e+00, 4.17524000e+05, 5.14630000e+03, 8.17000000e+01,\n        3.72000000e+02, 1.57488000e+04, 1.40000000e+01, 1.00500000e+03,\n        1.27050000e+03, 8.00221000e+03, 8.05800000e+03, 7.96500000e+01,\n        7.69200000e+01, 5.06276000e+03, 4.37100000e+04, 7.88018300e+05,\n        3.71300000e+03, 6.62000000e+01, 7.31300000e+01, 3.06000000e+00,\n        3.82101500e+05, 5.13140000e+03, 7.69000000e+01, 2.79000000e+02,\n        1.18116000e+04, 9.07100000e+02, 1.00460000e+03, 7.97688000e+03,\n        8.02000000e+03, 7.54200000e+01, 7.36600000e+01, 5.09697000e+03,\n        3.27825000e+04, 6.92600000e+05, 6.79600000e+03, 6.26000000e+01,\n        7.07500000e+01, 3.72000000e+00, 3.65186200e+05, 4.73080000e+03,\n        7.43000000e+01, 1.86000000e+02, 7.87440000e+03, 8.86400000e+02,\n        9.09200000e+02, 7.93066000e+03, 8.00400000e+03, 7.35700000e+01,\n        6.92600000e+01, 4.75668000e+03, 2.18550000e+04, 6.69640300e+05,\n        6.71300000e+03, 5.91000000e+01, 6.56100000e+01, 5.65000000e+00,\n        3.39325900e+05, 3.87840000e+03, 7.02000000e+01, 9.30000000e+01,\n        3.93720000e+03, 8.31800000e+02, 9.38400000e+02, 7.92448000e+03,\n        7.99400000e+03, 7.15600000e+01, 6.56500000e+01, 4.29406000e+03,\n        1.09275000e+04, 6.48845600e+05],\n       [1.12000000e+03, 2.50000000e+02, 2.46400000e+02, 2.20000000e+02,\n        3.39070000e+02, 7.00000000e+00, 1.20000000e+03, 6.79000000e+03,\n        2.03800000e+02, 1.62840000e+02, 6.46000000e+00, 1.64029300e+06,\n        1.08553000e+04, 2.29300000e+02, 3.93300000e+02, 6.94448000e+04,\n        2.73880000e+03, 3.14800000e+03, 9.24840000e+03, 9.38000000e+03,\n        1.58630000e+02, 1.69500000e+02, 1.00820000e+04, 4.95720000e+04,\n        2.31839700e+06, 6.37000000e+03, 1.90300000e+02, 1.54360000e+02,\n        5.33000000e+00, 1.52316660e+06, 1.29300000e+04, 2.10700000e+02,\n        2.94980000e+02, 5.20836000e+04, 1.10000000e+01, 2.59520000e+03,\n        3.00000000e+03, 9.32964000e+03, 9.39600000e+03, 1.48760000e+02,\n        1.59000000e+02, 9.70000000e+03, 3.71790000e+04, 1.90897570e+06,\n        5.90900000e+03, 1.77600000e+02, 1.47440000e+02, 6.88000000e+00,\n        1.45117590e+06, 8.14610000e+03, 1.88900000e+02, 1.96650000e+02,\n        3.47224000e+04, 2.28440000e+03, 2.62750000e+03, 9.29706000e+03,\n        9.34700000e+03, 1.40900000e+02, 1.46200000e+02, 1.01490000e+04,\n        2.47860000e+04, 1.68184930e+06, 7.04500000e+03, 1.60000000e+02,\n        1.41340000e+02, 4.72000000e+00, 1.34107280e+06, 8.24500000e+03,\n        1.73800000e+02, 9.83300000e+01, 1.73612000e+04, 2.45120000e+03,\n        2.52640000e+03, 9.25428000e+03, 9.30600000e+03, 1.36560000e+02,\n        1.38800000e+02, 9.29100000e+03, 1.23930000e+04, 1.73293750e+06,\n        5.60600000e+03, 1.49100000e+02, 1.34800000e+02, 4.09000000e+00,\n        1.28419940e+06, 6.62250000e+03, 1.47600000e+02, 4.32400000e+02,\n        7.31435000e+04, 2.22060000e+03, 2.24410000e+03, 9.23176000e+03,\n        9.28600000e+03, 1.36600000e+02, 1.40200000e+02, 9.82100000e+03,\n        4.82600000e+04, 1.73497350e+06],\n       [2.63000000e+03, 5.80000000e+02, 3.15600000e+02, 1.20000000e+02,\n        5.99100000e+02, 6.00000000e+00, 8.50000000e+02, 6.71300000e+03,\n        5.91000000e+01, 6.56100000e+01, 5.65000000e+00, 3.39325900e+05,\n        3.87840000e+03, 7.02000000e+01, 9.30000000e+01, 3.93720000e+03,\n        8.31800000e+02, 9.38400000e+02, 7.92448000e+03, 7.99400000e+03,\n        7.15600000e+01, 6.56500000e+01, 4.29406000e+03, 1.09275000e+04,\n        6.48845600e+05, 6.71300000e+03, 5.62000000e+01, 6.15200000e+01,\n        6.11000000e+00, 3.20957300e+05, 3.48580000e+03, 6.45000000e+01,\n        2.39500000e+02, 1.24566000e+04, 1.50000000e+01, 7.97300000e+02,\n        8.09800000e+02, 1.75500000e+03, 8.00300000e+03, 6.78100000e+01,\n        6.32500000e+01, 3.75877000e+03, 4.25870000e+04, 6.28132900e+05,\n        4.98600000e+03, 5.55000000e+01, 6.07800000e+01, 3.94000000e+00,\n        2.97210100e+05, 3.66350000e+03, 6.15000000e+01, 1.79630000e+02,\n        9.34245000e+03, 7.57800000e+02, 8.61800000e+02, 1.75500000e+03,\n        8.01800000e+03, 6.50000000e+01, 6.05300000e+01, 3.53871000e+03,\n        3.19402500e+04, 6.10502700e+05, 6.78800000e+03, 5.42000000e+01,\n        5.94000000e+01, 5.41000000e+00, 2.80451700e+05, 3.75580000e+03,\n        5.81000000e+01, 1.19750000e+02, 6.22830000e+03, 7.95000000e+02,\n        8.18500000e+02, 1.75500000e+03, 8.00100000e+03, 6.36900000e+01,\n        5.85500000e+01, 3.34772000e+03, 2.12935000e+04, 5.89389600e+05,\n        5.72800000e+03, 5.24000000e+01, 5.76500000e+01, 5.40000000e+00,\n        2.62789000e+05, 2.93140000e+03, 5.42000000e+01, 5.98800000e+01,\n        3.11415000e+03, 7.46800000e+02, 8.15500000e+02, 1.75500000e+03,\n        8.01300000e+03, 6.27800000e+01, 5.64500000e+01, 3.38772000e+03,\n        1.06467500e+04, 6.06524200e+05]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "        S_0    S_1    S_2    S_3     S_4   S_5     S_6     S_7    S_8     S_9  \\\n0    1450.0  320.0  377.0  260.0  443.35   7.0  3100.0  5909.0  177.6  147.44   \n1     360.0   80.0   21.6   60.0  644.47  11.0   330.0  3302.0   29.5   29.93   \n2     920.0  290.0   36.8   40.0  325.39   4.0   370.0  4638.0   34.6   37.16   \n3    1670.0  370.0   83.5   50.0  291.99   7.0   410.0  6788.0   54.2   59.40   \n4    2600.0  560.0  598.0  230.0  415.24  10.0  2100.0  5606.0  149.1  134.80   \n..      ...    ...    ...    ...     ...   ...     ...     ...    ...     ...   \n329  3240.0  630.0  680.4  210.0  715.52   7.0  2300.0  3157.0   92.8   96.49   \n330   390.0  100.0   62.4  160.0  547.10   8.0  1000.0  3678.0   86.2   83.21   \n331   750.0  200.0   45.0   60.0  423.07   6.0   360.0  3213.0   44.5   49.80   \n332   560.0  220.0   22.4   40.0  319.47   3.0   350.0  2374.0   38.0   39.43   \n333  1430.0  440.0   57.2   40.0  772.31   4.0   280.0  3321.0   31.4   33.00   \n\n     ...         S_89     S_90     S_91    S_92    S_93    S_94     S_95  \\\n0    ...  1994.600000  2025.00  9185.48  9208.0  123.37  127.33  9501.30   \n1    ...   284.100000   346.10  1750.00  3739.0   24.05   16.21  1013.40   \n2    ...   431.100000   550.40  1755.00  4252.0   30.13   21.54  2134.49   \n3    ...   769.600000   717.90  1755.00  8231.0   56.99   48.40  2556.96   \n4    ...  1821.600000  1963.70  9114.22  9131.0  116.56  119.13  9459.40   \n..   ...          ...      ...      ...     ...     ...     ...      ...   \n329  ...  1014.900000  1104.70  8148.33  8186.0   83.55   80.05  6703.06   \n330  ...  1005.000000  1270.50  8002.21  8058.0   79.65   76.92  5062.76   \n331  ...   554.081966   663.97  1755.00  5827.0   41.79   34.76  1527.55   \n332  ...   229.200000   582.90  1755.00  4758.0   34.98   27.13  1859.50   \n333  ...   225.700000   409.30  1750.00  4063.0   27.84   18.37  1549.44   \n\n         S_96       S_97  price  \n0    24130.00  1660444.0  410.0  \n1    17881.50   428725.0  100.0  \n2    18409.00   402158.1   50.0  \n3    20703.50   605688.7   80.0  \n4    47096.00  1391757.1  400.0  \n..        ...        ...    ...  \n329  11208.75   817526.9  290.0  \n330  43710.00   788018.3  220.0  \n331  19533.00   409677.9   80.0  \n332   9483.25   408321.5   50.0  \n333  35763.00   420700.5  120.0  \n\n[334 rows x 99 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S_0</th>\n      <th>S_1</th>\n      <th>S_2</th>\n      <th>S_3</th>\n      <th>S_4</th>\n      <th>S_5</th>\n      <th>S_6</th>\n      <th>S_7</th>\n      <th>S_8</th>\n      <th>S_9</th>\n      <th>...</th>\n      <th>S_89</th>\n      <th>S_90</th>\n      <th>S_91</th>\n      <th>S_92</th>\n      <th>S_93</th>\n      <th>S_94</th>\n      <th>S_95</th>\n      <th>S_96</th>\n      <th>S_97</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1450.0</td>\n      <td>320.0</td>\n      <td>377.0</td>\n      <td>260.0</td>\n      <td>443.35</td>\n      <td>7.0</td>\n      <td>3100.0</td>\n      <td>5909.0</td>\n      <td>177.6</td>\n      <td>147.44</td>\n      <td>...</td>\n      <td>1994.600000</td>\n      <td>2025.00</td>\n      <td>9185.48</td>\n      <td>9208.0</td>\n      <td>123.37</td>\n      <td>127.33</td>\n      <td>9501.30</td>\n      <td>24130.00</td>\n      <td>1660444.0</td>\n      <td>410.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>360.0</td>\n      <td>80.0</td>\n      <td>21.6</td>\n      <td>60.0</td>\n      <td>644.47</td>\n      <td>11.0</td>\n      <td>330.0</td>\n      <td>3302.0</td>\n      <td>29.5</td>\n      <td>29.93</td>\n      <td>...</td>\n      <td>284.100000</td>\n      <td>346.10</td>\n      <td>1750.00</td>\n      <td>3739.0</td>\n      <td>24.05</td>\n      <td>16.21</td>\n      <td>1013.40</td>\n      <td>17881.50</td>\n      <td>428725.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>920.0</td>\n      <td>290.0</td>\n      <td>36.8</td>\n      <td>40.0</td>\n      <td>325.39</td>\n      <td>4.0</td>\n      <td>370.0</td>\n      <td>4638.0</td>\n      <td>34.6</td>\n      <td>37.16</td>\n      <td>...</td>\n      <td>431.100000</td>\n      <td>550.40</td>\n      <td>1755.00</td>\n      <td>4252.0</td>\n      <td>30.13</td>\n      <td>21.54</td>\n      <td>2134.49</td>\n      <td>18409.00</td>\n      <td>402158.1</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1670.0</td>\n      <td>370.0</td>\n      <td>83.5</td>\n      <td>50.0</td>\n      <td>291.99</td>\n      <td>7.0</td>\n      <td>410.0</td>\n      <td>6788.0</td>\n      <td>54.2</td>\n      <td>59.40</td>\n      <td>...</td>\n      <td>769.600000</td>\n      <td>717.90</td>\n      <td>1755.00</td>\n      <td>8231.0</td>\n      <td>56.99</td>\n      <td>48.40</td>\n      <td>2556.96</td>\n      <td>20703.50</td>\n      <td>605688.7</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2600.0</td>\n      <td>560.0</td>\n      <td>598.0</td>\n      <td>230.0</td>\n      <td>415.24</td>\n      <td>10.0</td>\n      <td>2100.0</td>\n      <td>5606.0</td>\n      <td>149.1</td>\n      <td>134.80</td>\n      <td>...</td>\n      <td>1821.600000</td>\n      <td>1963.70</td>\n      <td>9114.22</td>\n      <td>9131.0</td>\n      <td>116.56</td>\n      <td>119.13</td>\n      <td>9459.40</td>\n      <td>47096.00</td>\n      <td>1391757.1</td>\n      <td>400.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>3240.0</td>\n      <td>630.0</td>\n      <td>680.4</td>\n      <td>210.0</td>\n      <td>715.52</td>\n      <td>7.0</td>\n      <td>2300.0</td>\n      <td>3157.0</td>\n      <td>92.8</td>\n      <td>96.49</td>\n      <td>...</td>\n      <td>1014.900000</td>\n      <td>1104.70</td>\n      <td>8148.33</td>\n      <td>8186.0</td>\n      <td>83.55</td>\n      <td>80.05</td>\n      <td>6703.06</td>\n      <td>11208.75</td>\n      <td>817526.9</td>\n      <td>290.0</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>390.0</td>\n      <td>100.0</td>\n      <td>62.4</td>\n      <td>160.0</td>\n      <td>547.10</td>\n      <td>8.0</td>\n      <td>1000.0</td>\n      <td>3678.0</td>\n      <td>86.2</td>\n      <td>83.21</td>\n      <td>...</td>\n      <td>1005.000000</td>\n      <td>1270.50</td>\n      <td>8002.21</td>\n      <td>8058.0</td>\n      <td>79.65</td>\n      <td>76.92</td>\n      <td>5062.76</td>\n      <td>43710.00</td>\n      <td>788018.3</td>\n      <td>220.0</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>750.0</td>\n      <td>200.0</td>\n      <td>45.0</td>\n      <td>60.0</td>\n      <td>423.07</td>\n      <td>6.0</td>\n      <td>360.0</td>\n      <td>3213.0</td>\n      <td>44.5</td>\n      <td>49.80</td>\n      <td>...</td>\n      <td>554.081966</td>\n      <td>663.97</td>\n      <td>1755.00</td>\n      <td>5827.0</td>\n      <td>41.79</td>\n      <td>34.76</td>\n      <td>1527.55</td>\n      <td>19533.00</td>\n      <td>409677.9</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>560.0</td>\n      <td>220.0</td>\n      <td>22.4</td>\n      <td>40.0</td>\n      <td>319.47</td>\n      <td>3.0</td>\n      <td>350.0</td>\n      <td>2374.0</td>\n      <td>38.0</td>\n      <td>39.43</td>\n      <td>...</td>\n      <td>229.200000</td>\n      <td>582.90</td>\n      <td>1755.00</td>\n      <td>4758.0</td>\n      <td>34.98</td>\n      <td>27.13</td>\n      <td>1859.50</td>\n      <td>9483.25</td>\n      <td>408321.5</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>1430.0</td>\n      <td>440.0</td>\n      <td>57.2</td>\n      <td>40.0</td>\n      <td>772.31</td>\n      <td>4.0</td>\n      <td>280.0</td>\n      <td>3321.0</td>\n      <td>31.4</td>\n      <td>33.00</td>\n      <td>...</td>\n      <td>225.700000</td>\n      <td>409.30</td>\n      <td>1750.00</td>\n      <td>4063.0</td>\n      <td>27.84</td>\n      <td>18.37</td>\n      <td>1549.44</td>\n      <td>35763.00</td>\n      <td>420700.5</td>\n      <td>120.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>334 rows × 99 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}