{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14076/428867298.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../input/train.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;31m#!pip install jupyterthemes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\tjdal\\pycharmprojects\\kaggle\\venv\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    699\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    700\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 701\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    702\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    703\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../input/train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# matplotlib style search go\n",
    "#https://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html\n",
    "plt.style.use('fivethirtyeight')\n",
    "#!pip install seaborn\n",
    "# 빨갛게 경고뜨지만 실행에 문제 없는 출력을 무시한다\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "#!pip install jupyterthemes\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.isnull().sum()\n",
    "# 메서드도 한번에 치지말고 하나씩 나눠서 쳐서 배우기\n",
    "#data.isnull().sum(axis=1) 행방향 null\n",
    "\n",
    "# jupyter 실행창 테마변경\n",
    "# https://github.com/dunovank/jupyter-themes\n",
    "#jtplot.style(theme='grade3')\n",
    "\n",
    "\n",
    "# 1 행 2열의 같은 figsize의 ax 를 만든다\n",
    "# f는 잘 쓰지를 않네\n",
    "f,ax = plt.subplots(1,2, figsize=(18,8))\n",
    "data['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct = '%1.10f%%' , ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "#sns.countplot('컬럼' , data=data, ax=ax[1])\n",
    "# matplot ax 에 사용할 수 있다 sns countplot\n",
    "sns.countplot('Survived' , data=data, ax=ax[1])\n",
    "ax[1].set_title('Survived')\n",
    "plt.show()\n",
    "\n",
    "# 2.2 Analysis on Sex\n",
    "\n",
    "data.groupby(['Sex','Survived'])['Survived'].count()\n",
    "\n",
    "\n",
    "\n",
    "f,ax = plt.subplots(1,2,figsize=(18,8))\n",
    "# matplotlib 를 먼저 그려야 dataframe 에 plot을 적용해서 띄울 수 있다\n",
    "# 이런 거가 그냥 복붙하면 코드만 이해하게 되는데 쉐도우 코딩하면서 알게 되는 점 하나하나 분석해서\n",
    "\n",
    "data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Survived vs Sex')\n",
    "sns.countplot('Sex', hue='Survived', data=data,ax=ax[1])\n",
    "ax[1].set_title('Sex:Survived vs Dead')\n",
    "plt.show()\n",
    "# 0.742038  = 233 / (81+233)\n",
    "\n",
    "data.Pclass\n",
    "\n",
    "pd.crosstab(data.Pclass, data.Survived , margins =True).style.background_gradient(cmap='summer_r')\n",
    "\n",
    "#### plcass가 1이고 여자인 사람이 살 확률이 높았다\n",
    "\n",
    "f, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "data['Pclass'].value_counts().plot.bar(color=['#CD7F32', '#FFDF00', '#D3D3D3'] , ax=ax[0])\n",
    "ax[0].set_title('Number of Passengers By Pclass')\n",
    "ax[0].set_ylabel('Count')\n",
    "sns.countplot('Pclass', hue='Survived' , data=data, ax=ax[1])\n",
    "ax[1].set_title('Pclass:Survived vs Dead')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pd.crosstab([data.Sex, data.Survived], data.Pclass, margins=True).style.background_gradient(cmap='summer_r')\n",
    "\n",
    "sns.factorplot('Pclass' , 'Survived' , hue='Sex' , data=data )\n",
    "plt.show()\n",
    "\n",
    "# col or hue 옵션\n",
    "sns.factorplot(x='Sex', y='Survived',col ='Pclass',data=data, saturation=.5, size= 9 , aspect=1)\n",
    "\n",
    "#### female strong survive power\n",
    "#### money can brings survival\n",
    "\n",
    "\n",
    "\n",
    "data\n",
    "\n",
    "for col in data.columns:\n",
    "    # python format 문 >  오른쪽으로 정렬  < 왼쪽으로 정렬 {:10} 컬럼을 넘겨주면 컬럼을 10개까지 표시해준다는 뜻이 아니라 간격을 뜻함\n",
    "    # : 직접 변수 이름으로 대입 :>50은 50자리를 확보하고 col을 대입한다 \\t 은 탭\n",
    "    #{0:<10} 이 뜻하는 것은 {0}(번째) 값을 \":<10\" 10자리로 표현할건데 왼쪽 정렬을 할 것이다. 라는 뜻 이고\n",
    "    #{1:>5} 가 뜻하는 것은 {1}(번째) 값을 \":>5\" 5자리로 표현할건데 오른쪽 정렬을 할 것이다. 입니다.\n",
    "    msg = 'column: {:>50}\\t Percent of NaN values: {:.2f}%'.format(col, 100 *(data[col].isnull().sum() / data[col].shape[0]))\n",
    "    print(msg)\n",
    "\n",
    "#좀 더 시각화 하자면 빈칸이 null 값!\n",
    "msno.matrix(df=data.iloc[:,:] , figsize=(8,8) , color= (0.8 ,0.5, 0.2))\n",
    "\n",
    "#좀 더 시각화 하자면 빈칸이 null 값! 전체개수와 비율\n",
    "msno.bar(df=data.iloc[:,:] , figsize=(8,8) , color= (0.8 ,0.5, 0.2))\n",
    "\n",
    "f , ax = plt.subplots(1,2, figsize=(18,8))\n",
    "# 도화지 그리고 pie의 인자로 ax를 준다 파라미터에 # series에 plot 메서드 적용하기 위해 plot 먼저 사용 str 사용하듯이\n",
    "# data['Survived'].value_counts().plot == plt.plot(data['Survived'].value_counts())\n",
    "# exploded : 폭파시킨다 짼다\n",
    "data['Survived'].value_counts().plot.pie(explode=[0,0.1] , autopct = '%1.1f%%' , ax= ax[0] ,shadow=True)\n",
    "ax[0].set_title('Pie plot - Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived' , data= data, ax=ax[1])\n",
    "ax[1].set_title('Count plot - Survived')\n",
    "ax[1].set_xlabel('Survived')\n",
    "plt.show()\n",
    "\n",
    "### 2.1 PClass\n",
    "\n",
    "data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).count()\n",
    "\n",
    "pd.crosstab(data['Pclass'], data['Survived'], margins=True).style.background_gradient(cmap='cool')\n",
    "\n",
    "# as_index groupby 한 것을 인덱스로\n",
    "data[['Pclass','Survived']].groupby(['Pclass'], as_index=True ).mean().sort_values(by='Survived', ascending=False).plot.bar()\n",
    "\n",
    "y_position = 1.02\n",
    "f , ax = plt.subplots(1,2,figsize=(18,8))\n",
    "data['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'] , ax= ax[0])\n",
    "ax[0].set_title('Number of Passenger by Pclass ' , y=y_position)\n",
    "ax[0].set_ylabel('Count')\n",
    "# hue 는 색깔별로 구분할 수 있도록하는 옵션 , 컬럼을 매개변수로 준다\n",
    "sns.countplot('Pclass' , hue = 'Survived' , data=data, ax=ax[1])\n",
    "ax[1].set_title('Pclass: Survived vs Dead' ,y= y_position)\n",
    "plt.show()\n",
    "\n",
    "### 2.3 age\n",
    "\n",
    "print('제일 나이 많은 탑승객 {:.1f} years'.format(data['Age'].max()))\n",
    "print('제일 나이 어린 탑승객 {:.1f} years'.format(data['Age'].min()))\n",
    "print('탑승객 평균 나이  {:.1f} years'.format(data['Age'].mean()))\n",
    "\n",
    "foo = data['Age']\n",
    "\n",
    "\n",
    "\n",
    "# . tab click 시 메서드 많다\n",
    "# sns의 kdeplot 는 계급별 도수분포인 hist()을 밀도함수로 유연하게 표현해준다\n",
    "fig , ax = plt.subplots(1,1, figsize=(9,5))\n",
    "sns.kdeplot(data[data['Survived'] == 1]['Age'], ax=ax)\n",
    "sns.kdeplot(data[data['Survived'] == 0]['Age'], ax= ax )\n",
    "plt.legend(['Survived == 1', 'Survived ==0'])\n",
    "plt.show()\n",
    "\n",
    "data[data['Survived'] == 1 ]['Age'].hist()\n",
    "\n",
    "#도화지 그리는 3가지 방법\n",
    "f = plt.figure(figsize=(10,10))\n",
    "f, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "f = plt.subplots(1,1, figsize=(10,10))\n",
    "a = np.arange(100)\n",
    "b = np.sin(a)\n",
    "plt.plot(b)\n",
    "\n",
    "f, ax  = plt.subplots(1,1, figsize=(5,5))\n",
    "a= np.arange(100)\n",
    "b= np.sin(a)\n",
    "\n",
    "ax.plot(b)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "a= np.arange(100)\n",
    "b = np.sin(a)\n",
    "\n",
    "plt.plot(b)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "data['Age'][data['Pclass']==1].plot(kind='kde')\n",
    "data['Age'][data['Pclass']==2].plot(kind='kde')\n",
    "data['Age'][data['Pclass']==3].plot(kind='kde')\n",
    "#ax xlabel은 set_xlabel 로 사용\n",
    "plt.xlabel('Age')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 나이가 많아질수록 클래스가 높다\n",
    "\n",
    "# . tab click 시 메서드 많다\n",
    "# sns의 kdeplot 는 계급별 도수분포인 hist()을 밀도함수로 유연하게 표현해준다\n",
    "fig , ax = plt.subplots(1,1, figsize=(9,5))\n",
    "sns.kdeplot(data[(data['Survived'] == 1 )& (data['Pclass'] ==1)]['Age'], ax=ax)\n",
    "sns.kdeplot(data[(data['Survived'] == 0 )& (data['Pclass'] ==1)]['Age'], ax= ax )\n",
    "plt.legend(['Survived == 1', 'Survived ==0'])\n",
    "plt.title('Distribution age within classes')\n",
    "plt.show()\n",
    "\n",
    "# . tab click 시 메서드 많다\n",
    "# sns의 kdeplot 는 계급별 도수분포인 hist()을 밀도함수로 유연하게 표현해준다\n",
    "fig , ax = plt.subplots(1,1, figsize=(9,5))\n",
    "sns.kdeplot(data[(data['Survived'] == 1 )& (data['Pclass'] ==2)]['Age'], ax=ax)\n",
    "sns.kdeplot(data[(data['Survived'] == 0 )& (data['Pclass'] ==2)]['Age'], ax= ax )\n",
    "plt.legend(['Survived == 1', 'Survived ==0'])\n",
    "plt.title('Distribution age within classes')\n",
    "plt.show()\n",
    "\n",
    "# . tab click 시 메서드 많다\n",
    "# sns의 kdeplot 는 계급별 도수분포인 hist()을 밀도함수로 유연하게 표현해준다\n",
    "fig , ax = plt.subplots(1,1, figsize=(9,5))\n",
    "sns.kdeplot(data[(data['Survived'] == 1 )& (data['Pclass'] ==3)]['Age'], ax=ax)\n",
    "sns.kdeplot(data[(data['Survived'] == 0 )& (data['Pclass'] ==3)]['Age'], ax= ax )\n",
    "plt.legend(['Survived == 1', 'Survived ==0'])\n",
    "plt.title('Distribution age within classes')\n",
    "plt.show()\n",
    "\n",
    "i = 10\n",
    "data[data['Age'] > i]['Survived'].sum() / len(data[data['Age'] <i]['Survived'])\n",
    "\n",
    "\n",
    "data[data['Age'] < i]['Survived'].sum() / len(data[data['Age'] < i ]['Survived'])\n",
    "\n",
    "#### 나이 듦에 따라 해당 나이 이하의 총 사람수로 얼마나 Survived한 (True ==1) 한 sum 이 많은 지로 판단하는 건데\n",
    "#### 이것은 해당 나이대마다 얼마만큼의 인구 수가 있는 지 파악할 수 없으므로 썩 정확하지는 않다\n",
    "\n",
    "cummulate_survival_ratio = []\n",
    "for i in range(1, 80):\n",
    "    cummulate_survival_ratio.append(data[data['Age'] < i]['Survived'].sum() / len(data[data['Age'] < i]['Survived']))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(cummulate_survival_ratio)\n",
    "plt.title('Survival rate change depending on range of Age')\n",
    "plt.ylabel('Survival rate')\n",
    "plt.xlabel('Range of Age(0~x)')\n",
    "plt.show()\n",
    "\n",
    "data[(data['Age'] <1)]\n",
    "\n",
    "# 0번 째값\n",
    "': {1} {0}'.format('test','test2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "sns.violinplot('Pclass', 'Age' , hue='Survived' , data = data, scale= 'count' ,split=True,ax=ax[0])\n",
    "ax[0].set_title('Pclass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10))\n",
    "\n",
    "sns.violinplot('Sex','Age', hue='Survived' , data= data, scale='count', split=True, ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 딸린 식구가 많을 수록 죽을 확률이 높다\n",
    "f, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "sns.violinplot('SibSp','Age', hue='Survived' , data= data, scale='count', split=True, ax=ax[0])\n",
    "ax[0].set_title('Sex and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10))\n",
    "\n",
    "sns.violinplot('Embarked','Age', hue='Survived' , data= data, scale='count', split=True, ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "plt.show()\n",
    "\n",
    "# 캐비넷 위치에 따라 죽을 확률이 올라갈 수도 있을 듯 하다\n",
    "# 바이올린은 적합하지 않음\n",
    "# plt.figure(figsize=(18,8))\n",
    "# sns.violinplot('Cabin','Age', hue='Survived' , data= data, scale='count', split=True)\n",
    "# plt.title('Sex and Age vs Survived')\n",
    "# plt.yticks(range(0,110,10))\n",
    "# plt.show()\n",
    "\n",
    "# mr or mrs , miss 등으로 비어있는 null age에 대해 평균값을 그냥 내지 않고 추측해서 낸다\n",
    "df_train = data\n",
    "\n",
    "df_train['Initial'] = 0\n",
    "\n",
    "for i in df_train:\n",
    "    df_train['Initial'] = df_train.Name.str.extract('([A-Za-z]+)\\.')\n",
    "\n",
    "df_train['Initial']\n",
    "\n",
    "# 컬럼별 카운트를 나타낸다\n",
    "pd.crosstab(df_train.Initial,df_train.Sex).T.style.background_gradient(cmap='summer_r')\n",
    "\n",
    "# 스펠링을 바꿔준다 misspeling , 올바른 의미 혹은 다른 값으로\n",
    "df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'], \\\n",
    "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "# 와 이거를 그룹바이하는구나, 진짜 잘쓴다\n",
    "# 호칭 그룹별 평균 나이 계산\n",
    "# Mr 는 master의 축약어이지만 master는 도련님 정도의 호칭\n",
    "# NaN 값을 그냥 지우지 않고 활용한다\n",
    "df_train.groupby('Initial')['Age'].mean()\n",
    "\n",
    "# mean 계산하여 나온 값을 반올림하여 적용\n",
    "df_train.loc[(df_train.Age.isnull()) & (df_train.Initial =='Mr'),'Age'] = 33\n",
    "df_train.loc[(df_train.Age.isnull()) & (df_train.Initial =='Mrs'),'Age'] = 36\n",
    "df_train.loc[(df_train.Age.isnull()) & (df_train.Initial =='Master'),'Age'] = 5\n",
    "df_train.loc[(df_train.Age.isnull()) & (df_train.Initial =='Miss'),'Age'] = 22\n",
    "df_train.loc[(df_train.Age.isnull()) & (df_train.Initial =='Other'),'Age'] = 46\n",
    "\n",
    "\n",
    "df_train.Age.isnull().any()\n",
    "\n",
    "df_train.loc[df_train.Age.isnull(),:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f,ax=plt.subplots(2,2,figsize=(20,15))\n",
    "sns.countplot('Embarked' , data=data,ax=ax[0,0])\n",
    "\n",
    "ax[0,0].set_title('No. Of Passengers Boarded')\n",
    "# x축을 Embarked로 하고 그에 따른 비교하고자 하는 결과 컬럼을 넣으면 막대기가 2개로 비교되어 표시된다\n",
    "sns.countplot('Embarked' , hue='Sex' , data=data,ax=ax[0,1])\n",
    "\n",
    "ax[0,1].set_title('Male-Female Split for Embarked')\n",
    "sns.countplot('Embarked' , hue='Survived' , data=data, ax=ax[1,0])\n",
    "\n",
    "ax[1,0].set_title('Embarked vs Survived')\n",
    "sns.countplot('Embarked' , hue='Pclass' , data=data , ax=ax[1,1])\n",
    "ax[1,1].set_title('Embarked vs Pclass')\n",
    "# plot 간의 간격을 조절한다\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Family - SibSp + Parch\n",
    "\n",
    "df_train\n",
    "\n",
    "\n",
    "\n",
    "df_train['FamilySize'] = 0\n",
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] # familysize\n",
    "df_train['Alone'] = 0\n",
    "df_train.loc[df_train.FamilySize==0,'Alone']=1\n",
    "\n",
    "print('Maximum size of Family: ', df_train['FamilySize'].max())\n",
    "print('Maximum size of Family:', df_train['FamilySize'].min())\n",
    "\n",
    "f, ax = plt.subplots(1,2,figsize=(18,6))\n",
    "sns.factorplot('FamilySize' , 'Survived', data=df_train , ax=ax[0])\n",
    "ax[0].set_title('FamilySize vs Survived')\n",
    "sns.factorplot('Alone', 'Survived' , data=df_train, ax=ax[1])\n",
    "ax[1].set_title('Alone vs Survived')\n",
    "plt.show()\n",
    "\n",
    "sns.factorplot('Alone', 'Survived' , data=df_train , hue='Sex' , col='Pclass')\n",
    "plt.show()\n",
    "\n",
    "df_train['Fare_Range']= pd.qcut(df_train['Fare'], 4 )\n",
    "\n",
    "df_train.groupby(['Fare_Range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')\n",
    "\n",
    "df_train['Fare_cat'] = 0\n",
    "df_train.loc[df_train['Fare']<=7.91, 'Fare_cat'] = 0\n",
    "df_train.loc[(df_train['Fare']> 7.91) & (df_train['Fare']<=14.454), 'Fare_cat'] = 1\n",
    "df_train.loc[(df_train['Fare']> 14.454) & (df_train['Fare']<=31), 'Fare_cat'] = 2\n",
    "df_train.loc[(df_train['Fare']> 31) & (df_train['Fare'] <=513 ) ,'Fare_cat'] =3\n",
    "\n",
    "sns.factorplot('Fare_cat', 'Survived' , data=df_train , hue='Sex')\n",
    "plt.show()\n",
    "\n",
    "df_train['Sex'].replace(['male','female'],[0,1], inplace=True)\n",
    "df_train['Embarked'].replace(['S','C','Q'],[0,1,2], inplace=True)\n",
    "df_train['Initial'].replace(['Mr','Mrs','Miss','Master','Other'], [0,1,2,3,4],inplace=True)\n",
    "\n",
    "# Dropping UnNeeded Features\n",
    "# 버린 컬럼과 그 이유\n",
    "# Name--> We don't need name feature as it cannot be converted into any categorical value.\n",
    "\n",
    "# Age--> We have the Age_band feature, so no need of this.\n",
    "\n",
    "# Ticket--> It is any random string that cannot be categorised.\n",
    "\n",
    "# Fare--> We have the Fare_cat feature, so unneeded\n",
    "\n",
    "# Cabin--> A lot of NaN values and also many passengers have multiple cabins. So this is a useless feature.\n",
    "\n",
    "# Fare_Range--> We have the fare_cat feature.\n",
    "\n",
    "# PassengerId--> Cannot be categorised.\n",
    "\n",
    "df_train.drop(['Name','Age','Ticket','Fare','Cabin' ,'Fare_Range', 'PassengerId'],axis=1, inplace=True)\n",
    "\n",
    "sns.heatmap(df_train.corr(),annot=True , cmap='RdYlGn', linewidths = 0.2,annot_kws={'size': 20})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "df_train\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "g = sns.distplot(df_train['Fare'], color= 'b', label ='Swkewness: {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\n",
    "g = g.legend(loc='best')\n",
    "\n",
    "# feature engineering\n",
    "\n",
    "df_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0 )\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "g = sns.distplot(df_train['Fare'], color= 'b', label ='Swkewness: {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\n",
    "g = g.legend(loc='best')\n",
    "\n",
    "df_train\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3 , random_state=0 , stratify = data['Survived'])\n",
    "\n",
    "train_X = train[train.columns[1:]]\n",
    "\n",
    "train_Y = train[train.columns[:1]]\n",
    "test_X =test[test.columns[1:]]\n",
    "\n",
    "test_Y = test[test.columns[:1]]\n",
    "X=data[data.columns[1:]]\n",
    "Y=data['Survived']\n",
    "\n",
    "train_Y.isnull().sum()\n",
    "\n",
    "train_X.isnull().sum()\n",
    "\n",
    "train_X.fillna(0, inplace=True)\n",
    "\n",
    "train_X.isnull().sum()\n",
    "\n",
    "train_X\n",
    "\n",
    "test_X.isnull().sum()\n",
    "\n",
    "model= svm.SVC(kernel='rbf', C=1,gamma=0.1)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction1= model.predict(test_X)\n",
    "print('Accuracy for rbf SVM is ', metrics.accuracy_score(prediction1, test_Y))\n",
    "\n",
    "# SVM 알고리즘은 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적 이진 선형 분류 모델을 만든다\n",
    "# - 나무위키 ^^\n",
    "\n",
    "\n",
    "train_X.dropna(inplace=True)\n",
    "\n",
    "train_Y.dropna(inplace=True)\n",
    "\n",
    "train_Y.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "train_X.isnull().sum()\n",
    "\n",
    "\n",
    "model = svm.SVC(kernel='linear' , C=0.1, gamma=0.1)\n",
    "\n",
    "model.fit(train_X, train_Y)\n",
    "prediction2= model.predict(test_X)\n",
    "print(\"Accuraccy for linear SVM is\" , metrics.accuracy_score(prediction2 , test_Y))\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction3 = model.predict(test_X)\n",
    "print('The accuracy of the Logistic Regression is ', metrics.accuracy_score(prediction3,test_Y))\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction4 = model.predict(test_X)\n",
    "print('The accuracy of the Decision Tree is' , metrics.accuracy_score(prediction4, test_Y))\n",
    "\n",
    "#K-nearest Neighbors(KNN)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction5= model.predict(test_X)\n",
    "print('The accuracy of the KNN is ', metrics.accuracy_score(prediction5, test_Y))\n",
    "\n",
    "\n",
    "a_index=list(range(1,11))\n",
    "\n",
    "\n",
    "a= pd.Series()\n",
    "\n",
    "x= [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "Now the accuracy for the KNN model changes as we change the values for n_neighbours attribute. The default value is 5. Lets check the accuracies over various values of n_neighbours.\n",
    "\n",
    "for i in list(range(1,11)):\n",
    "    model=KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(train_X,train_Y)\n",
    "    prediction = model.predict(test_X)\n",
    "    a=a.append(pd.Series(metrics.accuracy_score(prediction, test_Y)))\n",
    "\n",
    "\n",
    "plt.plot(a_index, a)\n",
    "plt.xticks(x)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,6)\n",
    "plt.show()\n",
    "\n",
    "print('Accuracies for different values of n are: ' , a.values , 'with the max value as', a.values.max())\n",
    "\n",
    "train_X\n",
    "\n",
    "train_Y\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB #\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction6 =model.predict(test_X)\n",
    "print(\"The accuracy of the NaiveBayes i s \", metrics.accuracy_score(prediction6,test_Y))\n",
    "\n",
    "\n",
    "model =RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "model.fit(train_X,train_Y)\n",
    "prediction7=model.predict(test_X)\n",
    "\n",
    "print('The accuracy of the Random Forests is' , metrics.accuracy_score(prediction7, test_Y))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "classifiers\n",
    "\n",
    "\n",
    "cross_val_score(model,X,Y , cv= kfold, scoring  = \"accuracy\")\n",
    "\n",
    "kfold = KFold(n_splits=10 ,random_state=22, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "scorers = ['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2', 'accuracy']\n",
    "\n",
    "results = cross_validate(model, X, Y, cv=5, scoring=scorers, return_estimator=True)\n",
    "results\n",
    "\n",
    "X['Fare'] = X['Fare'].astype('int64')\n",
    "\n",
    "X['Embarked'] = X['Embarked'].astype('int64')\n",
    "\n",
    "X['Embarked']\n",
    "\n",
    "\n",
    "\n",
    "xyz =[]\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "std= []\n",
    "\n",
    "classifiers= ['Linear Svm', 'Radial Svm' , 'Logistic Regression' , 'KNN', 'Desicion Tree' , 'Navie Bayes' , 'Random Forest']\n",
    "\n",
    "models= [svm.SVC(kernel='linear'), svm.SVC(kernel='rbf'), LogisticRegression(), KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(), GaussianNB(),RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "for i in models:\n",
    "    model = i\n",
    "    cv_result = cross_val_score(model,X,Y , cv= kfold, scoring  = \"accuracy\")\n",
    "    cv_result = cv_result\n",
    "    xyz.append(cv_result.mean())\n",
    "    std.append(cv_result.std())\n",
    "    accuracy.append(cv_result)\n",
    "new_models_dataframe2 = pd.DataFrame({'CV Mean' : xyz, 'Std': std}, index=classifiers)\n",
    "new_models_dataframe2\n",
    "\n",
    "box.T\n",
    "\n",
    "accuracy\n",
    "\n",
    "plt.subplots(figsize=(12,6))\n",
    "box=pd.DataFrame(accuracy , index=[classifiers])\n",
    "# 데이터 범위와 중앙 값 이상치 확인\n",
    "box.T.boxplot()\n",
    "\n",
    "new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\n",
    "plt.title('Average CV Mean Accuracy')\n",
    "# get_current_figure\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,5)\n",
    "plt.show()\n",
    "\n",
    "f,ax = plt.subplots(3,3,figsize=(12,10))\n",
    "y_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y , cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred), ax =ax[0,0] , annot=True, fmt='2.0f')\n",
    "ax[0,0].set_title('Matrix for rbf-SVM')\n",
    "y_pred = cross_val_predict(svm.SVC(kernel='linear') , X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y, y_pred), ax=ax[0,1] , annot =True , fmt = '2.0f')\n",
    "ax[0,1].set_title('Matrix for Linear-SVM')\n",
    "y_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9), X,Y , cv=10)\n",
    "sns.heatmap(confusion_matrix(Y, y_pred) , ax=ax[0,2] , annot=True, fmt='2.0f')\n",
    "ax[0,2].set_title('Matrix for KNN')\n",
    "y_pred = cross_val_predict(RandomForestClassifier(n_estimators=100), X,Y , cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred), ax=ax[1,0], annot= True , fmt='2.0f')\n",
    "ax[1,0].set_title('Matrix for Random-Forests')\n",
    "y_pred = cross_val_predict(LogisticRegression(), X ,Y, cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred) , ax =ax[1,1] , annot=True , fmt='2.0f')\n",
    "ax[1,1].set_title('Logistic Regression')\n",
    "y_pred = cross_val_predict(DecisionTreeClassifier(), X,Y , cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred) , ax=ax[1,2] , annot=True, fmt='2.0f')\n",
    "ax[1,2].set_title('Matrix for Decision Tree')\n",
    "y_pred = cross_val_predict(GaussianNB(),X,Y, cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred) , ax=ax[2,0], annot=True, fmt='2.0f')\n",
    "ax[2,0].set_title('Matrix for Naive Bayes')\n",
    "plt.subplots_adjust(hspace=0.2,wspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(12,6))\n",
    "box=pd.DataFrame(accuracy , index=[classifiers])\n",
    "box.T.boxplot()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}