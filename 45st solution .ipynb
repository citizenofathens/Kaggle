{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T14:22:25.247819Z","iopub.execute_input":"2022-05-10T14:22:25.248131Z","iopub.status.idle":"2022-05-10T14:22:25.255303Z","shell.execute_reply.started":"2022-05-10T14:22:25.248103Z","shell.execute_reply":"2022-05-10T14:22:25.254248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U lightgbm==3.3.2","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:22:37.686386Z","iopub.execute_input":"2022-05-10T14:22:37.686671Z","iopub.status.idle":"2022-05-10T14:22:52.50358Z","shell.execute_reply.started":"2022-05-10T14:22:37.686642Z","shell.execute_reply":"2022-05-10T14:22:52.502186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install implicit","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:22:52.505932Z","iopub.execute_input":"2022-05-10T14:22:52.506859Z","iopub.status.idle":"2022-05-10T14:23:03.202423Z","shell.execute_reply.started":"2022-05-10T14:22:52.506802Z","shell.execute_reply":"2022-05-10T14:23:03.201137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas.api.types import CategoricalDtype\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nimport pickle\nfrom tqdm import tqdm\nimport gc\nfrom pathlib import Path\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:23:44.00966Z","iopub.execute_input":"2022-05-10T14:23:44.010004Z","iopub.status.idle":"2022-05-10T14:23:46.537643Z","shell.execute_reply.started":"2022-05-10T14:23:44.009969Z","shell.execute_reply":"2022-05-10T14:23:46.536966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport sys\nfrom IPython.core.interactiveshell import InteractiveShell\n\nwarnings.filterwarnings(\"ignore\")\nInteractiveShell.ast_node_interactivity = \"all\"\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:24:46.500264Z","iopub.execute_input":"2022-05-10T14:24:46.500612Z","iopub.status.idle":"2022-05-10T14:24:46.50713Z","shell.execute_reply.started":"2022-05-10T14:24:46.500579Z","shell.execute_reply":"2022-05-10T14:24:46.505847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# * Note: the src module can be found at https://github.com/Wp-Zhang/H-M-Fashion-RecSys/tree/main/src.\n\nfrom src.data import DataHelper","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:25:06.912864Z","iopub.execute_input":"2022-05-10T14:25:06.913179Z","iopub.status.idle":"2022-05-10T14:25:07.054749Z","shell.execute_reply.started":"2022-05-10T14:25:06.913145Z","shell.execute_reply":"2022-05-10T14:25:07.053555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataHelper:\n    \"\"\" Helper class for loading , preprocessing and saving data.\"\"\"\n    \n    def __init__(self, data_dir: str, raw_dir : str = \"raw\"):\n        \"\"\"Initialzie DataHelper\n        \n        Parameters\n        \n        ------\n        data_dir : str\n            Data directory\n            \n        raw_dir : str\n            Subdirectory to store raw data.\n        \n        \"\"\"\n        self.base = Path(data_dir) # data directory\n        self.raw_dir = self.base / raw_dir # raw data directory\n        \n    def _load_raw_data(self) -> dict:\n        \"\"\"Load original raw data\n        \n        \n        Returns\n        -------\n        dict\n            Data dictionary , keys : 'item' , 'user' , 'inter'\n        \n        \"\"\"\n        \n        \n        articles = pd.read_csv(self.raw_dir / \"articles.csv\")\n        customers = pd.read_csv(self.raw_dir / \"customers.csv\")\n        inter = pd.read_csv(self.raw_dir / \"transcations_train.csv\")\n        \n        \n        return {\"item\" : articles , \"user\" : customers , \"inter\" : inter}\n        \n    \n    def _encode_id(self, data: dict , map_dir : str) -> dict:\n        \"\"\"Encode user and item id as integers\n        \n        Parameters\n        ---------\n        \n        data : dict\n            Raw data dictionary , keys : \"item\" , \"user\" , \"inter\".\n        map_dir : str\n            Relative directory to store index-id-maps.\n            \n          \n        Returns\n        --------\n        \n        dict \n            Encoded data dictionary , keys : 'item' , 'user' , 'inter'\n        \n    \n        \"\"\"\n        if not os.path.isdir(self.base / map_idr):\n            os.mkdir(self.base / map_idr)\n            \n        user = data[\"user\"]\n        item = data[\"item\"]\n        inter = data[\"inter\"]\n        \n        user_id2index_path = self.base / map_dir / \"user_id2index.pkl\"\n        user_index2id_path = self.base / map_dir / \"user_index2id.pkl\"\n        item_id2index_path = self.base / map_dir / \"item_id2index.pkl\"\n        item_index2id_path = self.base / map_dir / \"item_index2id.pkl\"\n        \n        if not os.path.exists(user_id2index_path):\n            user_id2index_dict = dict(zip(user[\"customer_id\"], user.index +1))\n            pickle.dump(user_id2index_dict , open(user_id2index_path, \"wb\"))\n        else:\n            user_id2index_dict = pickle.load(open(user_id2index_path , \"rb\"))\n        \n        \n        if not os.path.exists(user_index2id_path):\n            user_index2id_dict = dict(zip(user.index +1, user[\"customer_id\"]))\n            pickle.dump(user_index2id_dict, open(user_index2id_path, \"wb\"))\n        \n        else:\n            user_index2id_dict = pickle.load(open(user_index2id_path , \"rb\"))\n        \n        if not os.path.exists(item_id2index_path):\n            item_id2index_dict = dict(zip(item[\"article_id\"] , item.index +1))\n            pickle.dump(item_id2index_dict,  open(item_id2index_path , \"wb\"))\n        \n        else:\n            item_id2index_dict = pickle.load(open(item_id2index_path , \"rb\"))\n            \n        if not os.path.exists(item_index2id_path):\n            item_index2id_dict = dict(zip(item.index+1 , item[\"article_id\"]))\n            pickle.dump(item_index2id_dict , open(item_index2id_path , \"wb\"))\n        else:\n            item_index2id_dict = pickle.load(open(item_index2ip_path), \"rb\")\n        \n        # map 에 dict 적용\n        inter[\"customer_id\"] = inter[\"customer_id\"].map(user_id2index_dict)\n        inter[\"article_id\"] = inter[\"article_id\"].map(item_id2index_dict)\n        user[\"customer_id\"] = user[\"customer_id\"].map(user_id2index_dict)\n        item[\"article_id\"] = item[\"article_id\"].map(item_id2index_dict)\n        \n        \n        \n        data[\"user\"] = user\n        data[\"item\"] = item\n        data[\"inter\"] =  inter\n        \n        \n        return data\n    \n    def _base_features(self, data: dict) -> dict:\n        \"\"\"Extract base features from data dictionary\n        \n        \n        Parameters\n        ----------\n        data : dict\n            Data dictionary , keys: 'item' , 'user' , 'inter'.\n            \n        Returns\n        ----------\n        \n        dict\n            Data dictionary , keys: 'item' , 'user' , 'inter'.\n        \n        \"\"\"\n        \n        \n        item = data[\"item\"]\n        user = data[\"user\"]\n        trans = data[\"inter\"]\n        \n        def set_gender_flg(x):\n            \n              female_pro_types = [\n                \"Bra\",\n                \"Underwear Tights\",\n                \"Leggings/Tights\",\n                \"Hair clip\",\n                \"Hair string\",\n                \"Hair/alice band\",\n                \"Bikini top\",\n                \"Skirt\",\n                \"Dress\",\n                \"Earring\",\n                \"Alice band\",\n                \"Straw hat\",\n                \"Necklace\",\n                \"Ballerinas\",\n                \"Blouse\",\n                \"Beanie\",\n                \"Giftbox\",\n                \"Pumps\",\n                \"Bootie\",\n                \"Heeled sandals\",\n                \"Nipple covers\",\n                \"Hair ties\",\n                \"Underwear corset\",\n                \"Bra extender\",\n                \"Underdress\",\n                \"Underwear set\",\n                \"Sarong\",\n                \"Leg warmers\",\n                \"Hairband\",\n                \"Tote bag\",\n                \"Earrings\",\n                \"Flat shoes\",\n                \"Heels\",\n                \"Cap\",\n                \"Shoulder bag\",\n                \"Headband\",\n                \"Baby Bib\",\n                \"Cross-body bag\",\n                \"Bumbag\",\n            ]\n                \n            x[\"article_gender\"] = 0 # * 0 for not divided, 1 for male , 2 for female\n            if x[\"index_group_name\"] == \"Ladieswear\":\n                x[\"article_gender\"] = 2\n            elif x[\"index_group_name\"] == \"Menswear\":\n                x[\"article_gender\"] = 1\n                \n            else:\n                if (\n                \n                    \"boy\" in x[\"department_name\"].lower()\n                    or \"men\" in x[\"department_name\"].lower()\n                \n                ):\n                    x[\"article_gender\"] = 1 \n                if (\n                \n                    \"girl\" in x[\"department_name\"].lower()\n                    or \"ladies\" in x[\"department_name\"].lower()\n                    or x[\"product_type_name\"] in female_pro_types\n                ):\n                    x[\"article_gender\"] = 2\n            return x\n        \n        # * Recognize article gender\n        item = item.apply(set_gender_flg, axis=1)\n        \n         # * Seasonal Articles\n        summer = [\n            \"Sunglasses\",\n            \"Hat/brim\",\n            \"Sandals\",\n            \"Flat shoe\",\n            \"Heeled sandals\",\n            \"Polo shirt\",\n            \"Dress\",\n            \"T-shirt\",\n            \"Skirt\",\n            \"Vest top\",\n            \"Swimwear top\",\n            \"Swimsuit\",\n            \"Swimwear bottom\",\n            \"Bikini top\",\n            \"Shorts\",\n        ]\n        winter = [\n            \"Beanie\",\n            \"Felt hat\",\n            \"Outdoor overall\",\n            \"Long John\",\n            \"Pyjama bottom\",\n            \"Hat/beanie\",\n            \"Leggings/Tights\",\n            \"Hoodie\",\n            \"Underwear Tights\",\n            \"Pyjama set\",\n            \"Boots\",\n            \"Cardigan\",\n            \"Sweater\",\n            \"Jacket\",\n            \"Scarf\",\n            \"Coat\",\n            \"Gloves\",\n            \"Outdoor Waistcoat\",\n        ]\n        \n        item[\"season_type\"] = 0\n        item.loc[item[\"product_type_name\"].isin(summer), \"season_type\"] =1\n        item.loc[item[\"product_type_name\"].isin(winter), \"season_type\"] = 2\n        \n        \n        # * Recognize user gender\n        \n        trans = pd.merge(\n            trans,\n            item[[\"article_id\",\"article_gender\", \"product_type_name\"]],\n            on =\"article_id\", \n            how=\"left\",\n            \n        )\n        \n        ttl_cnt = trans.groupby([\"customer_id\"]).size().reset_index(name=\"ttl_cnt\")\n        gender_sale = (\n            trans.groupby([\"customer_id\",\"article_gender\"])\n            .size()\n            .reset_index(name=\"cnt\")\n        \n        )\n        \n        gender_sale = gender_sale.merge(ttl_cnt , on=[\"customer_id\"], how=\"left\")\n        gender_sale[\"ratio\"] = gender_sale[\"cnt\"] / gender_sale[\"ttl_cnt\"]\n        gender_sale = pd.pivot_table(\n            gender_sale , values=\"ratio\" , index=\"customer_id\" , columns = [\"article_gender\"]\n        )\n        gender_sale = gender_sale.reset_index()\n        gender_sale[\"user_gender\"] = 0\n        gender_sale.loc[gender_sale[1] >= 0.8 , \"user_gender\"] = 1 # * male\n        gender_sale.loc[gender_sale[2] >= 0.8 , \"user_gender\"] = 2 # * female\n        user = user.merge(\n            gender_sale[[\"customer_id\" , \"user_gender\"]], on=\"customer_id\" , how=\"left\"\n        )\n        \n        user[\"user_gender\"] = user[\"user_gender\"].fillna(0)\n        \n        data[\"item\"] = item\n        date[\"user\"] = user\n        \n        return data\n    \n    def _transform_feats(self, data: dict) -> dict:\n        \"\"\"Transform features (label encode and change dtypes )\n        \n        Parameters\n        ----\n        data : dict\n            Data dictionary , keys: 'item' , 'user' , 'inter'\n        \n        \n        Returns\n        -----\n        dict\n        \n        \"\"\"\n        \n        inter = data[\"inter\"]\n        user = data[\"user\"]\n        item = data[\"item\"]\n        user[\"age\"] = user[\"age\"].fillna(0)\n        user = user.fillna(-1)\n        \n        # Transactions\n        inter[\"price\"] = inter[\"price\"].astype(\"float32\")\n        inter[\"sales_channel_id\"] = inter[\"sales_channel_id\"].astype(\"int8\")\n        \n        \n        # Customers\n        user_sparse_feats =  [x for x in user.columns if x not in [\"age\", \"user_gender\"]]\n        for feat in tqdm(\n            [x for x in user_sparse_feats if x != \"customer_id\"], \n            \"Encode User Sparse Feats\",\n        ):\n            \n            lbe = LabelEncoder()\n            user[feat] = lbe.fit_transform(user[feat].astype(str)) + 1\n            user[feat] = user[feat].astype(\"int32\")\n        user[\"age\"] = user[\"age\"].astype(\"int8\")\n        \n       # Articles\n        item_sparse_feats = [\n            \"article_id\",\n            \"product_code\",\n            \"product_type_no\",\n            \"product_group_name\",\n            \"graphical_appearance_no\",\n            \"colour_group_code\",\n            \"perceived_colour_value_id\",\n            \"perceived_colour_master_id\",\n            \"department_no\",\n            \"index_code\",\n            \"index_group_no\",\n            \"section_no\",\n            \"garment_group_no\",\n            \"article_gender\",\n            \"season_type\",\n        ]\n        \n        for feat in tqdm(\n            [\n                x\n                for x in item_sparse_feats\n                if x not in [\"article_id\", \"article_gender\", \"season_type\"]\n                \n            ],\n            \"Encode Item Sparse Feats\"\n        ):\n            lbe = LabelEncoder()\n            item[feat] = lbe.fit_transform(item[feat].astype(str))+1\n            item[feat] = item[feat].astype(\"int32\")\n            \n        data[\"inter\"] = inter\n        data[\"user\"] = user\n        data[\"item\"] = item[item_sparse_feats]\n        \n        return data\n    \n    def save_data(self, data:dict ,name:str):\n        \"\"\"Save data dictionary as parquet\n        \n        Parameters\n        ------\n        \n        data: dict\n            Data dictionary , keys: 'item' , 'user', 'inetr'.\n        name : str\n            Name of the dataset.\n        \"\"\"\n        \n        path = self.base / \"processed\" / name\n        \n        if not os.path.exists(path):\n            os.mkdir(path)\n        data[\"user\"].to_parquet(path / \"user.pqt\")\n        data[\"item\"].to_parquet(path / \"item.pqt\")\n        data[\"inter\"].to_parquet(path / \"inter.pqt\")\n        \n        \n    def load_data(self, name: str) -> dict:\n        \"\"\"Load data dictionary from parquet.\n        \n        \n        Parameters\n        \n        ----------\n        name : str\n            Name of the dataset \n        \n        \n        Returns\n        -------\n        dict\n            Data dictionary , keys : 'item' , 'user', 'inter'.\n            \n        \n        Raises\n        \n        ------\n        OSError\n        \n            If the directory does not exist.\n        \n        \"\"\"\n        \n        path = self.base / \"processed \"/ name \n        \n        if not os.path.exists(path):\n            raise OSError(f\"{path} does not exist.\")\n            \n        data = {}\n        data[\"user\"] = pd.read_parquet(path / \"user.pqt\")\n        data[\"item\"] = pd.read_parquet(path / \"item.pqt\")\n        data[\"inter\"] = pd.read_parquet(path / \"inter.pqt\")\n        \n        return data\n    \n    \n    def preprocess_data(self, save: bool =True , name: str = \"encoded_full\") -> dict:\n        \n        \"\"\"Preprocess raw data:\n            1. encode ids\n            2. label encode categorical features\n            3. impute\n            \n        Parameters\n        \n        --------\n        save : bool , optional\n            Whether to save the preprocessed data , by default ```True``.\n        name : str , optional\n            Version name of the data to be saved , by default ``\"encoded_full\"``.\n            \n            \n        Returns\n        \n        ------\n        dict\n        \n            Preprocessed data.\n        \n        \"\"\"\n        \n        data = self._load_raw_data()\n        data = self._encode_id(data, \"index_id_map\")\n        data = self._base_features(data)\n        data = self._transform_feats(data)\n        \n        \n        if save:\n            self.save_data(data, name)\n        return data\n    \n    def split_data(\n        self,\n        trans_data : pd.DataFrame,\n        train_end_data : str,\n        valid_end_data: str,\n        item_id : str = \"article_id\",\n    ) -> Tuple[pd.DataFrame]: \n        \"\"\"Split transaction data into train set and valid set\n        \n        \n        \n        Parameters\n        -------\n        \n        trans_data : pd.DataFrame\n            Transaction dataframe\n            \n        train_end_date : str\n            End date of train set , max(train_set.date) < train_end_date.\n        valid_end_date : str\n            End data of valid set , max(valid_set.date) < valid_end_date.\n        item_id : str, optional\n            Name of item id , can be `article_id` or `product_code` , etc. By default ``\"article_id\"``.\n        \n        Returns\n        ------\n        \n        Tuple[pd.DataFrame]\n            [train set, valid set]\n        \n        Raises\n        \n        -------\n        KeyError\n            If item_id is not in `trans_data` columns\n        \n    \n        \"\"\"\n        if item_id not in trans_data.columns:\n            raise KeyError(f\"{item_id} is not one of the columns\" )\n        train_set = trans_data.loc[trans_data[\"t_dat\"] < train_end_date]\n        valid_set = trasn_data.loc[\n            (train_end_date <= trans_data[\"t_dat\"])\n            & ( trans_data[\"t_dat\"] < valid_end_date)\n            \n        ]\n        valid_set =  (\n            valid_set.groupby([\"customer_id\"])[item_id].apply(list).reset_index()\n        )\n        \n        return train_set , valid_set\n    \n    \n        \n        \n        \n        \n        \n        \n                    ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:42:23.618012Z","iopub.execute_input":"2022-05-11T13:42:23.618719Z","iopub.status.idle":"2022-05-11T13:42:23.647647Z","shell.execute_reply.started":"2022-05-11T13:42:23.618584Z","shell.execute_reply":"2022-05-11T13:42:23.644918Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics.py\n\n\nfrom typing import Iterable\nimport numpy as np\n\n\n# apk 구현 \n# https://danthetech.netlify.app/DataScience/evaluation-metrics-for-recommendation-system\n\ndef _ap_at_k(actual , predicted, k =10):\n    if len(predicted) > k:\n        predicted = predicted[:k]\n        \n    score = 0.0\n    num_hits = 0.0\n    \n    for i , p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n            \n    if actual is None:\n        return 0.0\n    \n    return score / min(len(actual) ,k)\n\ndef _rk(actual , predicted, k=10)\n\n    if len(predicted) > k:\n        predicted = predicted[:k]\n        \n    score =num([1 for r in actual if r in predicted] ) / len(actual)\n    \n    return score\n\ndef map_at_k(actual: Iterable , predicted :Iterable , k:int = 12 ) -> float:\n    ","metadata":{},"execution_count":null,"outputs":[]}]}